# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

name: Gluten Unit Tests Suite

on:
  pull_request

concurrency:
  group: ${{ github.repository }}-${{ github.head_ref || github.sha }}-${{ github.workflow }}
  cancel-in-progress: true

jobs:

  arrow-backend-test:
    runs-on: velox-self-hosted
    steps:
      - uses: actions/checkout@v2
      - name: Setup docker container
        run: |
          EXTRA_DOCKER_OPTIONS="--name arrow-backend-test-$GITHUB_RUN_ID -v /mnt/tpcds:/mnt/tpcds -v /home/sparkuser:/home/sparkuser -v /tmp:/tmp --detach" NON_INTERACTIVE=ON MOUNT_MAVEN_CACHE=OFF tools/gluten-te/cbash.sh sleep 14400
      - name: Install Gluten Arrow-backend
        run: |
          docker exec arrow-backend-test-$GITHUB_RUN_ID bash -c "cd /opt/gluten/ep/build-arrow/src && \
          ./get_arrow.sh --arrow_branch=arrow-8.0.0-gluten-20220427a && \
          ./build_arrow_for_gazelle.sh && \
          cd /opt/gluten/cpp && \
          ./compile.sh --build_gazelle_cpp_backend=ON --build_protobuf=ON && \
          cd /opt/gluten && \
          mvn clean package -Pspark-3.2 -Pbackends-gazelle -DskipTests"
      # - name: Run unit tests
      #   run: |
      #     mvn test -Dcheckstyle.skip -Dexec.skip -Pbackends-gazelle -pl backends-gazelle -DwildcardSuites=io.glutenproject.execution.ArrowParquetWriteSuite -DfailIfNoTests=false
      - name: Run TPCDS q82,q85,q37,q60,q26
        run: |
          docker exec arrow-backend-test-$GITHUB_RUN_ID bash -c "cd /mnt/tpcds && \
          bash tpcds_spark.sh"
      - name: Exit docker container
        if: ${{ always() }}
        run: |
          docker stop arrow-backend-test-$GITHUB_RUN_ID || true

  velox-backend-test:
    runs-on: velox-self-hosted 
    steps:
      - uses: actions/checkout@v2
      - name: Setup docker container
        run: |
          EXTRA_DOCKER_OPTIONS="--name velox-backend-test-$GITHUB_RUN_ID -m 50GB --detach" NON_INTERACTIVE=ON MOUNT_MAVEN_CACHE=OFF tools/gluten-te/cbash.sh sleep 14400
      - name: Install Gluten Velox-backend spark3.2 and Run Unit test
        run: |
          docker exec velox-backend-test-$GITHUB_RUN_ID bash -c 'apt-get update && \
          cd /opt && \
          if [ -d "/opt/spark" ]
          then
            rm -rf /opt/spark
          fi
          git clone --depth 1 --branch v3.2.2 https://github.com/apache/spark.git && \
          cd /opt/gluten/ep/build-arrow/src && \
          ./get_arrow.sh  && \
          ./build_arrow_for_velox.sh --build_test=ON --build_benchmarks=ON && \
          cd /opt/gluten/ep/build-velox/src
          ./get_velox.sh && \
          ./build_velox.sh && \
          cd /opt/gluten/cpp && \
          ./compile.sh --build_velox_backend=ON --build_test=ON --build_benchmarks=ON && \
          cd /opt/gluten && \
          mvn clean install -Pspark-3.2 -Pspark-ut -Pbackends-velox -DargLine="-Dspark.test.home=/opt/spark"'
      - name: Run Cpp Unit test
        run: |
          docker exec velox-backend-test-$GITHUB_RUN_ID bash -c 'cd /opt/gluten/cpp/build && \
          ctest -V'
      # Cpp micro benchmarks will use generated files from unit test in backends-velox module.
      - name: Run micro benchmarks
        run: |
          docker exec velox-backend-test-$GITHUB_RUN_ID bash -c 'cd /opt/gluten/cpp/velox/benchmarks && \
          ./generic_benchmark --threads 1 --iterations 1'
      - name: Install Gluten Velox-backend spark3.3 and Run Unit test
        run: |
          docker exec velox-backend-test-$GITHUB_RUN_ID bash -c 'cd /opt/gluten && \
          mvn clean install -Pspark-3.3 -Pbackends-velox'
      - name: TPC-H SF1.0 && TPC-DS SF0.1 Parquet local spark3.2
        run: |
          docker exec velox-backend-test-$GITHUB_RUN_ID bash -c 'cd /opt/gluten/tools/gluten-it && \
          mvn clean package -Pspark-3.2 -Pgluten-velox -Darrow.version=10.0.0-SNAPSHOT \
          && java -Xmx5G -XX:ErrorFile=/var/log/java/hs_err_pid%p.log -cp target/gluten-it-1.0-SNAPSHOT-jar-with-dependencies.jar io.glutenproject.integration.tpc.Tpc \
            --backend-type=velox --benchmark-type=h --fixed-width-as-double --disable-aqe --off-heap-size=20g -s=1.0 --cpus=16 --iterations=1 \
          && java -Xmx5G -XX:ErrorFile=/var/log/java/hs_err_pid%p.log -cp target/gluten-it-1.0-SNAPSHOT-jar-with-dependencies.jar io.glutenproject.integration.tpc.Tpc \
            --backend-type=velox --benchmark-type=ds --fixed-width-as-double --off-heap-size=8g -s=0.1 --cpus=16 --iterations=1'
      - name: TPC-H SF1.0 && TPC-DS SF0.1 Parquet local spark3.3
        run: |
          docker exec velox-backend-test-$GITHUB_RUN_ID bash -c 'cd /opt/gluten/tools/gluten-it && \
          mvn clean package -Pspark-3.3 -Pgluten-velox -Darrow.version=10.0.0-SNAPSHOT \
          && java -Xmx5G -XX:ErrorFile=/var/log/java/hs_err_pid%p.log -cp target/gluten-it-1.0-SNAPSHOT-jar-with-dependencies.jar io.glutenproject.integration.tpc.Tpc \
            --backend-type=velox --benchmark-type=h --fixed-width-as-double --disable-aqe --off-heap-size=20g -s=1.0 --cpus=16 --iterations=1 --use-existing-data \
          && java -Xmx5G -XX:ErrorFile=/var/log/java/hs_err_pid%p.log -cp target/gluten-it-1.0-SNAPSHOT-jar-with-dependencies.jar io.glutenproject.integration.tpc.Tpc \
            --backend-type=velox --benchmark-type=ds --fixed-width-as-double --off-heap-size=8g -s=0.1 --cpus=16 --iterations=1 --use-existing-data'
      - name: Exit docker container
        if: ${{ always() }}
        run: |
          docker stop velox-backend-test-$GITHUB_RUN_ID || true
  ch-backend-test:
    runs-on: libch-self-hosted
    steps:
      - uses: actions/checkout@v2
      - name: Set up JDK 1.8
        uses: actions/setup-java@v2
        with:
          distribution: 'zulu'
          java-version: '8'
          java-package: jdk
          overwrite-settings: false
      - run: sudo swapoff -a
      - run: free
      - run: sudo apt-get update
      - run: sudo apt-get install -y maven
      - name: Install and Check ClickHouse Backend lib
        uses: liuneng1994/pull-request-comment-trigger@master
        id: ch_version
        with:
          trigger: 'test by CH\[\[(\S*)]]'
      - run: |
          wget -O /tmp/libch.so.new https://devopsnexus.kyligence.io/repository/raw-tars-hosted/io.kyligence.clickhouse/clickhouse_backend/latest/libch.so
          mv /tmp/libch.so.new /tmp/libch.so
        if: steps.ch_version.outputs.triggered == 'false'
      - run: |
          cd /home/qwe1398775315/code/ClickHouse
          gh pr checkout ${{ steps.ch_version.outputs.trigger_var }} --force
          sudo rm -f /tmp/ch_output/*
          sudo docker run  --rm --volume=/tmp/ch_output:/output --volume=/home/qwe1398775315/code/ClickHouse:/clickhouse --volume=/home/qwe1398775315/.cache:/ccache -e ENABLE_EMBEDDED_COMPILER=ON qwe1398775315/libchbuilder:0.1.0
          cp /tmp/ch_output/libch*.so /tmp/libch.so
        if: steps.ch_version.outputs.triggered == 'true'
      - name: Run Gluten + ClickHouse Backend unit tests with Spark 3.2
        run: |
          pushd /tmp
          if [ -d "/tmp/spark" ]
          then
            rm -rf /tmp/spark
          fi
          git clone --depth 1 --branch v3.2.2 https://github.com/apache/spark.git
          popd
          export MAVEN_OPTS="-Xmx5g -XX:ReservedCodeCacheSize=1g"
          mvn clean install -Pbackends-clickhouse -Pspark-3.2 -Pspark-ut -Dtpcds.data.path=/home/changchen/tpcds-sf1-data -Dclickhouse.lib.path=/tmp/libch.so -DargLine="-Dspark.test.home=/tmp/spark"

  formatting-check:
    name: Formatting Check
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Run clang-format style check for C/C++ programs.
      uses: jidicula/clang-format-action@v3.5.1
      with:
        clang-format-version: '10'
        check-path: 'gluten/cpp/src'
        fallback-style: 'Google' # optional
