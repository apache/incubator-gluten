# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

name: Velox backend Github Runner

on:
  pull_request:
    paths:
      - '.github/**'
      - 'pom.xml'
      - 'backends-velox/**'
      - 'gluten-celeborn/**'
      - 'gluten-core/**'
      - 'gluten-data/**'
      - 'gluten-delta/**'
      - 'gluten-iceberg/**'
      - 'gluten-ut/**'
      - 'shims/**'
      - 'tools/gluten-it/**'
      - 'tools/gluten-te/**'
      - 'ep/build-velox/**'
      - 'cpp/*'
      - 'cpp/CMake/**'
      - 'cpp/velox/**'
      - 'cpp/core/**'
      - 'dev/**'


concurrency:
  group: ${{ github.repository }}-${{ github.head_ref || github.sha }}-${{ github.workflow }}
  cancel-in-progress: true

jobs:
  build-native-lib:
    runs-on: ubuntu-20.04
    container: inteldpo/gluten-centos-packaging:latest # centos7 with depedencies installed
    steps:
      - uses: actions/checkout@v2
      - name: Build Gluten velox third party
        run: |
          yum install sudo patch java-1.8.0-openjdk-devel -y && \
          cd $GITHUB_WORKSPACE/ep/build-velox/src && \
          ./get_velox.sh && \
          source /opt/rh/devtoolset-9/enable && \
          source $GITHUB_WORKSPACE//dev/vcpkg/env.sh && \
          cd $GITHUB_WORKSPACE/ && \
          sed -i '/^headers/d' ep/build-velox/build/velox_ep/CMakeLists.txt && \
          ./dev/builddeps-veloxbe.sh --build_tests=OFF  --build_benchmarks=OFF --enable_s3=ON \
          --enable_gcs=ON --enable_hdfs=ON --enable_abfs=ON

      - uses: actions/upload-artifact@v2
        with:
          path: ./cpp/build/releases/
          name: velox-native-lib-${{github.sha}}

  run-tpc-test-ubuntu:
    needs: build-native-lib
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu:20.04", "ubuntu:22.04"]
        spark: ["spark-3.2", "spark-3.3", "spark-3.4", "spark-3.5"]
    runs-on: ubuntu-20.04
    container: ${{ matrix.os }}
    steps:
      - uses: actions/checkout@v2
      - name: Download All Artifacts
        uses: actions/download-artifact@v2
        with:
          name: velox-native-lib-${{github.sha}}
          path: ./cpp/build/releases
      - name: Setup java and maven
        run: |
          apt-get update && \
          apt-get install -y openjdk-8-jdk maven && \
          apt remove openjdk-11* -y
      - name: Build for Spark ${{ matrix.spark }}
        run: |
          cd $GITHUB_WORKSPACE/ && \
          mvn clean install -P${{ matrix.spark }} -Pbackends-velox -DskipTests
      - name: Build and run TPCH/DS ${{ matrix.spark }}
        run: |
          cd $GITHUB_WORKSPACE/tools/gluten-it && \
          mvn clean install -P${{ matrix.spark }} \
          && GLUTEN_IT_JVM_ARGS=-Xmx5G sbin/gluten-it.sh queries-compare \
            --local --preset=velox --benchmark-type=h --error-on-memleak --off-heap-size=10g -s=1.0 --threads=16 --iterations=1 \
          && GLUTEN_IT_JVM_ARGS=-Xmx5G sbin/gluten-it.sh queries-compare \
            --local --preset=velox --benchmark-type=ds --error-on-memleak --off-heap-size=10g -s=1.0 --threads=16 --iterations=1


  run-tpc-test-centos7:
    needs: build-native-lib
    strategy:
      fail-fast: false
      matrix:
        spark: ["spark-3.2", "spark-3.3", "spark-3.4", "spark-3.5"]
    runs-on: ubuntu-20.04
    container: centos:7
    steps:
      - uses: actions/checkout@v2
      - name: Download All Artifacts
        uses: actions/download-artifact@v2
        with:
          name: velox-native-lib-${{github.sha}}
          path: ./cpp/build/releases
      - name: Setup java and maven
        run: |
          yum update -y && yum install -y java-1.8.0-openjdk-devel wget
          wget https://downloads.apache.org/maven/maven-3/3.8.8/binaries/apache-maven-3.8.8-bin.tar.gz
          tar -xvf apache-maven-3.8.8-bin.tar.gz
          mv apache-maven-3.8.8 /usr/lib/maven
          echo 'MAVEN_HOME=/usr/lib/maven' >> /etc/profile.d/maven.sh
          echo 'PATH=${PATH}:${MAVEN_HOME}/bin' >> /etc/profile.d/maven.sh
      - name: Build for Spark ${{ matrix.spark }}
        run: |
          cd $GITHUB_WORKSPACE/ && \
          mvn clean install -P${{ matrix.spark }} -Pbackends-velox -DskipTests
      - name: Build and run TPCH/DS ${{ matrix.spark }}
        run: |
          cd $GITHUB_WORKSPACE/tools/gluten-it && \
          mvn clean install -P${{ matrix.spark }} \
          && GLUTEN_IT_JVM_ARGS=-Xmx5G sbin/gluten-it.sh queries-compare \
            --local --preset=velox --benchmark-type=h --error-on-memleak --off-heap-size=10g -s=1.0 --threads=16 --iterations=1 \
          && GLUTEN_IT_JVM_ARGS=-Xmx5G sbin/gluten-it.sh queries-compare \
            --local --preset=velox --benchmark-type=ds --error-on-memleak --off-heap-size=10g -s=1.0 --threads=16 --iterations=1

  run-tpc-test-centos8:
    needs: build-native-lib
    strategy:
      fail-fast: false
      matrix:
        spark: ["spark-3.2", "spark-3.3", "spark-3.4", "spark-3.5"]
    runs-on: ubuntu-20.04
    container: centos:8
    steps:
      - uses: actions/checkout@v2
      - name: Download All Artifacts
        uses: actions/download-artifact@v2
        with:
          name: velox-native-lib-${{github.sha}}
          path: ./cpp/build/releases
      - name: Update mirror list
        run: |
          sed -i -e "s|mirrorlist=|#mirrorlist=|g" /etc/yum.repos.d/CentOS-* || true
          sed -i -e "s|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g" /etc/yum.repos.d/CentOS-* || true
      - name: Setup java and maven
        run: |
          yum update -y && yum install -y java-1.8.0-openjdk-devel wget
          wget https://downloads.apache.org/maven/maven-3/3.8.8/binaries/apache-maven-3.8.8-bin.tar.gz
          tar -xvf apache-maven-3.8.8-bin.tar.gz
          mv apache-maven-3.8.8 /usr/lib/maven
          echo 'MAVEN_HOME=/usr/lib/maven' >> /etc/profile.d/maven.sh
          echo 'PATH=${PATH}:${MAVEN_HOME}/bin' >> /etc/profile.d/maven.sh
      - name: Build for Spark ${{ matrix.spark }}
        run: |
          cd $GITHUB_WORKSPACE/ && \
          mvn clean install -P${{ matrix.spark }} -Pbackends-velox -DskipTests
      - name: Build and run TPCH/DS ${{ matrix.spark }}
        run: |
          cd $GITHUB_WORKSPACE/tools/gluten-it && \
          mvn clean install -P${{ matrix.spark }} \
          && GLUTEN_IT_JVM_ARGS=-Xmx5G sbin/gluten-it.sh queries-compare \
            --local --preset=velox --benchmark-type=h --error-on-memleak --off-heap-size=10g -s=1.0 --threads=16 --iterations=1 \
          && GLUTEN_IT_JVM_ARGS=-Xmx5G sbin/gluten-it.sh queries-compare \
            --local --preset=velox --benchmark-type=ds --error-on-memleak --off-heap-size=10g -s=1.0 --threads=16 --iterations=1            

  run-spark-test-spark32:
    needs: build-native-lib
    runs-on: ubuntu-20.04
    container: ubuntu:20.04
    steps:
      - uses: actions/checkout@v2
      - name: Download All Artifacts
        uses: actions/download-artifact@v2
        with:
          name: velox-native-lib-${{github.sha}}
          path: ./cpp/build/releases
      - name: Setup java and maven
        run: |
          apt update && apt install -y openjdk-8-jdk wget maven && apt remove openjdk-11* -y
      - name: Prepare spark.test.home for Spark 3.2.2 (other tests)
        run: |
          cd $GITHUB_WORKSPACE/ && \
          wget https://archive.apache.org/dist/spark/spark-3.2.2/spark-3.2.2-bin-hadoop3.2.tgz && \
          tar --strip-components=1 -xf spark-3.2.2-bin-hadoop3.2.tgz spark-3.2.2-bin-hadoop3.2/jars/ && \
          rm -rf spark-3.2.2-bin-hadoop3.2.tgz && \
          mkdir -p $GITHUB_WORKSPACE//shims/spark32/spark_home/assembly/target/scala-2.12 && \
          mv jars $GITHUB_WORKSPACE//shims/spark32/spark_home/assembly/target/scala-2.12 && \
          cd $GITHUB_WORKSPACE// && \
          wget https://github.com/apache/spark/archive/refs/tags/v3.2.2.tar.gz && \
          tar --strip-components=1 -xf v3.2.2.tar.gz spark-3.2.2/sql/core/src/test/resources/  && \
          mkdir -p shims/spark32/spark_home/ && \
          mv sql shims/spark32/spark_home/ 
      - name: Build and run unit test for Spark 3.2.2 (other tests)
        run: |
          cd $GITHUB_WORKSPACE/ && \
          export SPARK_SCALA_VERSION=2.12 && \
          mvn clean install -Pspark-3.2 -Pspark-ut -Pbackends-velox -Prss -DargLine="-Dspark.test.home=$GITHUB_WORKSPACE//shims/spark32/spark_home/" -DtagsToExclude=org.apache.spark.tags.ExtendedSQLTest,io.glutenproject.tags.UDFTest,io.glutenproject.tags.SkipTestTags && \
          mvn test -Pspark-3.2 -Pbackends-velox -DtagsToExclude=None -DtagsToInclude=io.glutenproject.tags.UDFTest

  run-spark-test-spark32-slow:
    needs: build-native-lib
    runs-on: ubuntu-20.04
    container: ubuntu:20.04
    steps:
      - uses: actions/checkout@v2
      - name: Download All Artifacts
        uses: actions/download-artifact@v2
        with:
          name: velox-native-lib-${{github.sha}}
          path: ./cpp/build/releases
      - name: Setup java and maven
        run: |
          apt update && apt install -y openjdk-8-jdk wget maven && apt remove openjdk-11* -y
      - name: Prepare spark.test.home for Spark 3.2.2 (slow tests)
        run: |
          cd $GITHUB_WORKSPACE// && \
          wget https://github.com/apache/spark/archive/refs/tags/v3.2.2.tar.gz && \
          tar --strip-components=1 -xf v3.2.2.tar.gz spark-3.2.2/sql/core/src/test/resources/  && \
          mkdir -p shims/spark32/spark_home/ && \
          mv sql shims/spark32/spark_home/ 
      - name: Build and run unit test for Spark 3.2.2 (slow tests)
        run: |
          cd $GITHUB_WORKSPACE/ && \
          mvn clean install -Pspark-3.2 -Pspark-ut -Pbackends-velox -Prss -Piceberg -Pdelta -DargLine="-Dspark.test.home=$GITHUB_WORKSPACE//shims/spark32/spark_home/" -DtagsToInclude=org.apache.spark.tags.ExtendedSQLTest

  run-spark-test-spark33:
    needs: build-native-lib
    runs-on: ubuntu-20.04
    container: ubuntu:20.04
    steps:
      - uses: actions/checkout@v2
      - name: Download All Artifacts
        uses: actions/download-artifact@v2
        with:
          name: velox-native-lib-${{github.sha}}
          path: ./cpp/build/releases
      - name: Setup java and maven
        run: |
          apt update && apt install -y openjdk-8-jdk wget maven && apt remove openjdk-11* -y
      - name: Prepare spark.test.home for Spark 3.3.1 (other tests)
        run: |
          cd $GITHUB_WORKSPACE/ && \
          wget https://archive.apache.org/dist/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz && \
          tar --strip-components=1 -xf spark-3.3.1-bin-hadoop3.tgz spark-3.3.1-bin-hadoop3/jars/ && \
          rm -rf spark-3.3.1-bin-hadoop3.tgz && \
          mkdir -p $GITHUB_WORKSPACE//shims/spark33/spark_home/assembly/target/scala-2.12 && \
          mv jars $GITHUB_WORKSPACE//shims/spark33/spark_home/assembly/target/scala-2.12 && \
          cd $GITHUB_WORKSPACE// && \
          wget https://github.com/apache/spark/archive/refs/tags/v3.3.1.tar.gz && \
          tar --strip-components=1 -xf v3.3.1.tar.gz spark-3.3.1/sql/core/src/test/resources/  && \
          mkdir -p shims/spark33/spark_home/ && \
          mv sql shims/spark33/spark_home/ 
      - name: Build and Run unit test for Spark 3.3.1 (other tests)
        run: |
          cd $GITHUB_WORKSPACE/ && \
          export SPARK_SCALA_VERSION=2.12 && \
          mvn clean install -Pspark-3.3 -Pbackends-velox -Prss -Piceberg -Pdelta -Pspark-ut -DargLine="-Dspark.test.home=$GITHUB_WORKSPACE//shims/spark33/spark_home/" -DtagsToExclude=org.apache.spark.tags.ExtendedSQLTest,io.glutenproject.tags.UDFTest,io.glutenproject.tags.SkipTestTags && \
          mvn test -Pspark-3.3 -Pbackends-velox -DtagsToExclude=None -DtagsToInclude=io.glutenproject.tags.UDFTest

  run-spark-test-spark33-slow:
    needs: build-native-lib
    runs-on: ubuntu-20.04
    container: ubuntu:20.04
    steps:
      - uses: actions/checkout@v2
      - name: Download All Artifacts
        uses: actions/download-artifact@v2
        with:
          name: velox-native-lib-${{github.sha}}
          path: ./cpp/build/releases
      - name: Setup java and maven
        run: |
          apt update && apt install -y openjdk-8-jdk wget maven && apt remove openjdk-11* -y
      - name: Prepare spark.test.home for Spark 3.3.1 (slow tests)
        run: |
          cd $GITHUB_WORKSPACE// && \
          wget https://github.com/apache/spark/archive/refs/tags/v3.3.1.tar.gz && \
          tar --strip-components=1 -xf v3.3.1.tar.gz spark-3.3.1/sql/core/src/test/resources/  && \
          mkdir -p shims/spark33/spark_home/ && \
          mv sql shims/spark33/spark_home/ 
      - name: Build and Run unit test for Spark 3.3.1 (slow tests)
        run: |
          cd $GITHUB_WORKSPACE/ && \
          mvn clean install -Pspark-3.3 -Pbackends-velox -Prss -Piceberg -Pdelta -Pspark-ut -DargLine="-Dspark.test.home=$GITHUB_WORKSPACE//shims/spark33/spark_home/" -DtagsToInclude=org.apache.spark.tags.ExtendedSQLTest




  run-spark-test-spark34:
    needs: build-native-lib
    runs-on: ubuntu-20.04
    container: ubuntu:20.04
    steps:
      - uses: actions/checkout@v2
      - name: Download All Artifacts
        uses: actions/download-artifact@v2
        with:
          name: velox-native-lib-${{github.sha}}
          path: ./cpp/build/releases
      - name: Setup java and maven
        run: |
          apt update && apt install -y openjdk-8-jdk wget maven && apt remove openjdk-11* -y
      - name: Prepare spark.test.home for Spark 3.4.2 (other tests)
        run: |
          cd $GITHUB_WORKSPACE/ && \
          wget https://archive.apache.org/dist/spark/spark-3.4.2/spark-3.4.2-bin-hadoop3.tgz && \
          tar --strip-components=1 -xf spark-3.4.2-bin-hadoop3.tgz spark-3.4.2-bin-hadoop3/jars/ && \
          rm -rf spark-3.4.2-bin-hadoop3.tgz && \
          mkdir -p $GITHUB_WORKSPACE//shims/spark34/spark_home/assembly/target/scala-2.12 && \
          mv jars $GITHUB_WORKSPACE//shims/spark34/spark_home/assembly/target/scala-2.12 && \
          cd $GITHUB_WORKSPACE// && \
          wget https://github.com/apache/spark/archive/refs/tags/v3.4.2.tar.gz && \
          tar --strip-components=1 -xf v3.4.2.tar.gz spark-3.4.2/sql/core/src/test/resources/  && \
          mkdir -p shims/spark34/spark_home/ && \
          mv sql shims/spark34/spark_home/ 
      - name: Build and Run unit test for Spark 3.4.2 (other tests)
        run: |
          cd $GITHUB_WORKSPACE/ && \
          export SPARK_SCALA_VERSION=2.12 && \
          mvn clean install -Pspark-3.4 -Pbackends-velox -Prss -Piceberg -Pdelta -Pspark-ut -DargLine="-Dspark.test.home=$GITHUB_WORKSPACE//shims/spark34/spark_home/" -DtagsToExclude=org.apache.spark.tags.ExtendedSQLTest,io.glutenproject.tags.UDFTest,io.glutenproject.tags.SkipTestTags && \
          mvn test -Pspark-3.4 -Pbackends-velox -DtagsToExclude=None -DtagsToInclude=io.glutenproject.tags.UDFTest

  run-spark-test-spark34-slow:
    needs: build-native-lib
    runs-on: ubuntu-20.04
    container: ubuntu:20.04
    steps:
      - uses: actions/checkout@v2
      - name: Download All Artifacts
        uses: actions/download-artifact@v2
        with:
          name: velox-native-lib-${{github.sha}}
          path: ./cpp/build/releases
      - name: Setup java and maven
        run: |
          apt update && apt install -y openjdk-8-jdk wget maven && apt remove openjdk-11* -y
      - name: Prepare spark.test.home for Spark 3.4.2 (slow tests)
        run: |
          cd $GITHUB_WORKSPACE// && \
          wget https://github.com/apache/spark/archive/refs/tags/v3.4.2.tar.gz && \
          tar --strip-components=1 -xf v3.4.2.tar.gz spark-3.4.2/sql/core/src/test/resources/  && \
          mkdir -p shims/spark34/spark_home/ && \
          mv sql shims/spark34/spark_home/ 
      - name: Build and Run unit test for Spark 3.4.2 (slow tests)
        run: |
          cd $GITHUB_WORKSPACE/ && \
          mvn clean install -Pspark-3.4 -Pbackends-velox -Prss -Piceberg -Pdelta -Pspark-ut -DargLine="-Dspark.test.home=$GITHUB_WORKSPACE//shims/spark34/spark_home/" -DtagsToInclude=org.apache.spark.tags.ExtendedSQLTest