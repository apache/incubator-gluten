== Physical Plan ==
AdaptiveSparkPlan (51)
+- == Final Plan ==
   VeloxColumnarToRowExec (36)
   +- ^ SortExecTransformer (34)
      +- ^ InputIteratorTransformer (33)
         +- AQEShuffleRead (32)
            +- ShuffleQueryStage (31), Statistics(X)
               +- ColumnarExchange (30)
                  +- ^ RegularHashAggregateExecTransformer (28)
                     +- ^ InputIteratorTransformer (27)
                        +- AQEShuffleRead (26)
                           +- ShuffleQueryStage (25), Statistics(X)
                              +- ColumnarExchange (24)
                                 +- ^ ProjectExecTransformer (22)
                                    +- ^ FlushableHashAggregateExecTransformer (21)
                                       +- ^ ProjectExecTransformer (20)
                                          +- ^ GlutenBroadcastHashJoinExecTransformer Inner (19)
                                             :- ^ InputIteratorTransformer (8)
                                             :  +- AQEShuffleRead (7)
                                             :     +- ShuffleQueryStage (6), Statistics(X)
                                             :        +- ColumnarExchange (5)
                                             :           +- ^ ProjectExecTransformer (3)
                                             :              +- ^ FilterExecTransformer (2)
                                             :                 +- ^ Scan parquet spark_catalog.default.orders (1)
                                             +- ^ InputIteratorTransformer (18)
                                                +- BroadcastQueryStage (17), Statistics(X)
                                                   +- ColumnarBroadcastExchange (16)
                                                      +- AQEShuffleRead (15)
                                                         +- ShuffleQueryStage (14), Statistics(X)
                                                            +- ColumnarExchange (13)
                                                               +- ^ ProjectExecTransformer (11)
                                                                  +- ^ FilterExecTransformer (10)
                                                                     +- ^ Scan parquet spark_catalog.default.lineitem (9)
+- == Initial Plan ==
   Sort (50)
   +- Exchange (49)
      +- HashAggregate (48)
         +- Exchange (47)
            +- HashAggregate (46)
               +- Project (45)
                  +- ShuffledHashJoin Inner BuildLeft (44)
                     :- Exchange (39)
                     :  +- Filter (38)
                     :     +- Scan parquet spark_catalog.default.orders (37)
                     +- Exchange (43)
                        +- Project (42)
                           +- Filter (41)
                              +- Scan parquet spark_catalog.default.lineitem (40)


(1) Scan parquet spark_catalog.default.orders
Output [2]: [o_orderkey#X, o_orderpriority#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/orders]
PushedFilters: [IsNotNull(o_orderkey)]
ReadSchema: struct<o_orderkey:bigint,o_orderpriority:string>

(2) FilterExecTransformer
Input [2]: [o_orderkey#X, o_orderpriority#X]
Arguments: isnotnull(o_orderkey#X)

(3) ProjectExecTransformer
Input [2]: [o_orderkey#X, o_orderpriority#X]
Arguments: [hash(o_orderkey#X, 42) AS hash_partition_key#X, o_orderkey#X, o_orderpriority#X]

(4) WholeStageCodegenTransformer (X)
Input [3]: [hash_partition_key#X, o_orderkey#X, o_orderpriority#X]
Arguments: false
Native Plan:
-- Project[expressions: (n1_2:INTEGER, hash_with_seed(42,"n0_0")), (n1_3:BIGINT, "n0_0"), (n1_4:VARCHAR, "n0_1")] -> n1_2:INTEGER, n1_3:BIGINT, n1_4:VARCHAR
  -- TableScan[table: hive_table, range filters: [(o_orderkey, Filter(IsNotNull, deterministic, null not allowed))]] -> n0_0:BIGINT, n0_1:VARCHAR

(5) ColumnarExchange
Input [3]: [hash_partition_key#X, o_orderkey#X, o_orderpriority#X]
Arguments: hashpartitioning(o_orderkey#X, 100), ENSURE_REQUIREMENTS, [o_orderkey#X, o_orderpriority#X], [plan_id=X], [id=#X]

(6) ShuffleQueryStage
Output [2]: [o_orderkey#X, o_orderpriority#X]
Arguments: 0

(7) AQEShuffleRead
Input [2]: [o_orderkey#X, o_orderpriority#X]
Arguments: local

(8) InputIteratorTransformer
Input [2]: [o_orderkey#X, o_orderpriority#X]

(9) Scan parquet spark_catalog.default.lineitem
Output [5]: [l_orderkey#X, l_commitdate#X, l_receiptdate#X, l_shipmode#X, l_shipdate#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/lineitem]
PushedFilters: [IsNotNull(l_commitdate), IsNotNull(l_receiptdate), IsNotNull(l_shipdate), In(l_shipmode, [MAIL,SHIP]), GreaterThanOrEqual(l_receiptdate,1994-01-01), LessThan(l_receiptdate,1995-01-01), IsNotNull(l_orderkey)]
ReadSchema: struct<l_orderkey:bigint,l_commitdate:date,l_receiptdate:date,l_shipmode:string,l_shipdate:date>

(10) FilterExecTransformer
Input [5]: [l_orderkey#X, l_commitdate#X, l_receiptdate#X, l_shipmode#X, l_shipdate#X]
Arguments: ((((((((isnotnull(l_commitdate#X) AND isnotnull(l_receiptdate#X)) AND isnotnull(l_shipdate#X)) AND l_shipmode#X IN (MAIL,SHIP)) AND (l_commitdate#X < l_receiptdate#X)) AND (l_shipdate#X < l_commitdate#X)) AND (l_receiptdate#X >= 1994-01-01)) AND (l_receiptdate#X < 1995-01-01)) AND isnotnull(l_orderkey#X))

(11) ProjectExecTransformer
Input [5]: [l_orderkey#X, l_commitdate#X, l_receiptdate#X, l_shipmode#X, l_shipdate#X]
Arguments: [hash(l_orderkey#X, 42) AS hash_partition_key#X, l_orderkey#X, l_shipmode#X]

(12) WholeStageCodegenTransformer (X)
Input [3]: [hash_partition_key#X, l_orderkey#X, l_shipmode#X]
Arguments: false
Native Plan:
-- Project[expressions: (n1_5:INTEGER, hash_with_seed(42,"n0_0")), (n1_6:BIGINT, "n0_0"), (n1_7:VARCHAR, "n0_3")] -> n1_5:INTEGER, n1_6:BIGINT, n1_7:VARCHAR
  -- TableScan[table: hive_table, range filters: [(l_commitdate, Filter(IsNotNull, deterministic, null not allowed)), (l_orderkey, Filter(IsNotNull, deterministic, null not allowed)), (l_receiptdate, BigintRange: [8766, 9130] no nulls), (l_shipdate, Filter(IsNotNull, deterministic, null not allowed)), (l_shipmode, Filter(BytesValues, deterministic, null not allowed))], remaining filter: (and(lessthan("l_commitdate","l_receiptdate"),lessthan("l_shipdate","l_commitdate")))] -> n0_0:BIGINT, n0_1:DATE, n0_2:DATE, n0_3:VARCHAR, n0_4:DATE

(13) ColumnarExchange
Input [3]: [hash_partition_key#X, l_orderkey#X, l_shipmode#X]
Arguments: hashpartitioning(l_orderkey#X, 100), ENSURE_REQUIREMENTS, [l_orderkey#X, l_shipmode#X], [plan_id=X], [id=#X]

(14) ShuffleQueryStage
Output [2]: [l_orderkey#X, l_shipmode#X]
Arguments: 1

(15) AQEShuffleRead
Input [2]: [l_orderkey#X, l_shipmode#X]
Arguments: local

(16) ColumnarBroadcastExchange
Input [2]: [l_orderkey#X, l_shipmode#X]
Arguments: HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=X]

(17) BroadcastQueryStage
Output [2]: [l_orderkey#X, l_shipmode#X]
Arguments: 2

(18) InputIteratorTransformer
Input [2]: [l_orderkey#X, l_shipmode#X]

(19) GlutenBroadcastHashJoinExecTransformer
Left keys [1]: [o_orderkey#X]
Right keys [1]: [l_orderkey#X]
Join type: Inner
Join condition: None

(20) ProjectExecTransformer
Input [4]: [o_orderkey#X, o_orderpriority#X, l_orderkey#X, l_shipmode#X]
Arguments: [o_orderpriority#X, l_shipmode#X]

(21) FlushableHashAggregateExecTransformer
Input [2]: [o_orderpriority#X, l_shipmode#X]
Keys [1]: [l_shipmode#X]
Functions [2]: [partial_sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END), partial_sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)]
Aggregate Attributes [2]: [sum#X, sum#X]
Results [3]: [l_shipmode#X, sum#X, sum#X]

(22) ProjectExecTransformer
Input [3]: [l_shipmode#X, sum#X, sum#X]
Arguments: [hash(l_shipmode#X, 42) AS hash_partition_key#X, l_shipmode#X, sum#X, sum#X]

(23) WholeStageCodegenTransformer (X)
Input [4]: [hash_partition_key#X, l_shipmode#X, sum#X, sum#X]
Arguments: false
Native Plan:
-- Project[expressions: (n7_3:INTEGER, hash_with_seed(42,"n5_2")), (n7_4:VARCHAR, "n5_2"), (n7_5:BIGINT, "n6_1"), (n7_6:BIGINT, "n6_2")] -> n7_3:INTEGER, n7_4:VARCHAR, n7_5:BIGINT, n7_6:BIGINT
  -- Aggregation[PARTIAL [n5_2] n6_1 := sum_partial("n5_3"), n6_2 := sum_partial("n5_4")] -> n5_2:VARCHAR, n6_1:BIGINT, n6_2:BIGINT
    -- Project[expressions: (n5_2:VARCHAR, "n4_5"), (n5_3:INTEGER, if(or(equalto("n4_4","1-URGENT"),equalto("n4_4","2-HIGH")),1,0)), (n5_4:INTEGER, if(and(not(equalto("n4_4","1-URGENT")),not(equalto("n4_4","2-HIGH"))),1,0))] -> n5_2:VARCHAR, n5_3:INTEGER, n5_4:INTEGER
      -- Project[expressions: (n4_4:VARCHAR, "n3_5"), (n4_5:VARCHAR, "n3_7")] -> n4_4:VARCHAR, n4_5:VARCHAR
        -- Project[expressions: (n3_4:BIGINT, "n0_0"), (n3_5:VARCHAR, "n0_1"), (n3_6:BIGINT, "n1_0"), (n3_7:VARCHAR, "n1_1")] -> n3_4:BIGINT, n3_5:VARCHAR, n3_6:BIGINT, n3_7:VARCHAR
          -- HashJoin[INNER n0_0=n1_0] -> n0_0:BIGINT, n0_1:VARCHAR, n1_0:BIGINT, n1_1:VARCHAR
            -- ValueStream[] -> n0_0:BIGINT, n0_1:VARCHAR
            -- ValueStream[] -> n1_0:BIGINT, n1_1:VARCHAR

(24) ColumnarExchange
Input [4]: [hash_partition_key#X, l_shipmode#X, sum#X, sum#X]
Arguments: hashpartitioning(l_shipmode#X, 100), ENSURE_REQUIREMENTS, [l_shipmode#X, sum#X, sum#X], [plan_id=X], [id=#X]

(25) ShuffleQueryStage
Output [3]: [l_shipmode#X, sum#X, sum#X]
Arguments: 3

(26) AQEShuffleRead
Input [3]: [l_shipmode#X, sum#X, sum#X]
Arguments: coalesced

(27) InputIteratorTransformer
Input [3]: [l_shipmode#X, sum#X, sum#X]

(28) RegularHashAggregateExecTransformer
Input [3]: [l_shipmode#X, sum#X, sum#X]
Keys [1]: [l_shipmode#X]
Functions [2]: [sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END), sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)]
Aggregate Attributes [2]: [sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X, sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X]
Results [3]: [l_shipmode#X, sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X AS high_line_count#X, sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X AS low_line_count#X]

(29) WholeStageCodegenTransformer (X)
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: false
Native Plan:
-- Project[expressions: (n2_3:VARCHAR, "n0_0"), (n2_4:BIGINT, "n1_1"), (n2_5:BIGINT, "n1_2")] -> n2_3:VARCHAR, n2_4:BIGINT, n2_5:BIGINT
  -- Aggregation[SINGLE [n0_0] n1_1 := sum_merge_extract("n0_1"), n1_2 := sum_merge_extract("n0_2")] -> n0_0:VARCHAR, n1_1:BIGINT, n1_2:BIGINT
    -- ValueStream[] -> n0_0:VARCHAR, n0_1:BIGINT, n0_2:BIGINT

(30) ColumnarExchange
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: rangepartitioning(l_shipmode#X ASC NULLS FIRST, 100), ENSURE_REQUIREMENTS, [plan_id=X], [id=#X]

(31) ShuffleQueryStage
Output [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: 4

(32) AQEShuffleRead
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: coalesced

(33) InputIteratorTransformer
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]

(34) SortExecTransformer
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: [l_shipmode#X ASC NULLS FIRST], true, 0

(35) WholeStageCodegenTransformer (X)
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: false
Native Plan:
-- OrderBy[n0_0 ASC NULLS FIRST] -> n0_0:VARCHAR, n0_1:BIGINT, n0_2:BIGINT
  -- ValueStream[] -> n0_0:VARCHAR, n0_1:BIGINT, n0_2:BIGINT

(36) VeloxColumnarToRowExec
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]

(37) Scan parquet spark_catalog.default.orders
Output [2]: [o_orderkey#X, o_orderpriority#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/orders]
PushedFilters: [IsNotNull(o_orderkey)]
ReadSchema: struct<o_orderkey:bigint,o_orderpriority:string>

(38) Filter
Input [2]: [o_orderkey#X, o_orderpriority#X]
Condition : isnotnull(o_orderkey#X)

(39) Exchange
Input [2]: [o_orderkey#X, o_orderpriority#X]
Arguments: hashpartitioning(o_orderkey#X, 100), ENSURE_REQUIREMENTS, [plan_id=X]

(40) Scan parquet spark_catalog.default.lineitem
Output [5]: [l_orderkey#X, l_commitdate#X, l_receiptdate#X, l_shipmode#X, l_shipdate#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/lineitem]
PushedFilters: [IsNotNull(l_commitdate), IsNotNull(l_receiptdate), IsNotNull(l_shipdate), In(l_shipmode, [MAIL,SHIP]), GreaterThanOrEqual(l_receiptdate,1994-01-01), LessThan(l_receiptdate,1995-01-01), IsNotNull(l_orderkey)]
ReadSchema: struct<l_orderkey:bigint,l_commitdate:date,l_receiptdate:date,l_shipmode:string,l_shipdate:date>

(41) Filter
Input [5]: [l_orderkey#X, l_commitdate#X, l_receiptdate#X, l_shipmode#X, l_shipdate#X]
Condition : ((((((((isnotnull(l_commitdate#X) AND isnotnull(l_receiptdate#X)) AND isnotnull(l_shipdate#X)) AND l_shipmode#X IN (MAIL,SHIP)) AND (l_commitdate#X < l_receiptdate#X)) AND (l_shipdate#X < l_commitdate#X)) AND (l_receiptdate#X >= 1994-01-01)) AND (l_receiptdate#X < 1995-01-01)) AND isnotnull(l_orderkey#X))

(42) Project
Output [2]: [l_orderkey#X, l_shipmode#X]
Input [5]: [l_orderkey#X, l_commitdate#X, l_receiptdate#X, l_shipmode#X, l_shipdate#X]

(43) Exchange
Input [2]: [l_orderkey#X, l_shipmode#X]
Arguments: hashpartitioning(l_orderkey#X, 100), ENSURE_REQUIREMENTS, [plan_id=X]

(44) ShuffledHashJoin
Left keys [1]: [o_orderkey#X]
Right keys [1]: [l_orderkey#X]
Join type: Inner
Join condition: None

(45) Project
Output [2]: [o_orderpriority#X, l_shipmode#X]
Input [4]: [o_orderkey#X, o_orderpriority#X, l_orderkey#X, l_shipmode#X]

(46) HashAggregate
Input [2]: [o_orderpriority#X, l_shipmode#X]
Keys [1]: [l_shipmode#X]
Functions [2]: [partial_sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END), partial_sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)]
Aggregate Attributes [2]: [sum#X, sum#X]
Results [3]: [l_shipmode#X, sum#X, sum#X]

(47) Exchange
Input [3]: [l_shipmode#X, sum#X, sum#X]
Arguments: hashpartitioning(l_shipmode#X, 100), ENSURE_REQUIREMENTS, [plan_id=X]

(48) HashAggregate
Input [3]: [l_shipmode#X, sum#X, sum#X]
Keys [1]: [l_shipmode#X]
Functions [2]: [sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END), sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)]
Aggregate Attributes [2]: [sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X, sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X]
Results [3]: [l_shipmode#X, sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X AS high_line_count#X, sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X AS low_line_count#X]

(49) Exchange
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: rangepartitioning(l_shipmode#X ASC NULLS FIRST, 100), ENSURE_REQUIREMENTS, [plan_id=X]

(50) Sort
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: [l_shipmode#X ASC NULLS FIRST], true, 0

(51) AdaptiveSparkPlan
Output [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: isFinalPlan=true

