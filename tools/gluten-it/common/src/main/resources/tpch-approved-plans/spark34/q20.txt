== Physical Plan ==
VeloxColumnarToRowExec (53)
+- ^ SortExecTransformer (51)
   +- ^ InputIteratorTransformer (50)
      +- ColumnarExchange (49)
         +- ^ ProjectExecTransformer (47)
            +- ^ GlutenBroadcastHashJoinExecTransformer Inner (46)
               :- ^ ProjectExecTransformer (39)
               :  +- ^ ShuffledHashJoinExecTransformer LeftSemi (38)
               :     :- ^ InputIteratorTransformer (6)
               :     :  +- ColumnarExchange (5)
               :     :     +- ^ ProjectExecTransformer (3)
               :     :        +- ^ FilterExecTransformer (2)
               :     :           +- ^ Scan parquet spark_catalog.default.supplier (1)
               :     +- ^ InputIteratorTransformer (37)
               :        +- ColumnarExchange (36)
               :           +- ^ ProjectExecTransformer (34)
               :              +- ^ ShuffledHashJoinExecTransformer Inner (33)
               :                 :- ^ InputIteratorTransformer (19)
               :                 :  +- ColumnarExchange (18)
               :                 :     +- ^ ProjectExecTransformer (16)
               :                 :        +- ^ GlutenBroadcastHashJoinExecTransformer LeftSemi (15)
               :                 :           :- ^ FilterExecTransformer (8)
               :                 :           :  +- ^ Scan parquet spark_catalog.default.partsupp (7)
               :                 :           +- ^ InputIteratorTransformer (14)
               :                 :              +- ColumnarBroadcastExchange (13)
               :                 :                 +- ^ ProjectExecTransformer (11)
               :                 :                    +- ^ FilterExecTransformer (10)
               :                 :                       +- ^ Scan parquet spark_catalog.default.part (9)
               :                 +- ^ FilterExecTransformer (32)
               :                    +- ^ RegularHashAggregateExecTransformer (31)
               :                       +- ^ InputIteratorTransformer (30)
               :                          +- ColumnarExchange (29)
               :                             +- ^ ProjectExecTransformer (27)
               :                                +- ^ FlushableHashAggregateExecTransformer (26)
               :                                   +- ^ GlutenBroadcastHashJoinExecTransformer LeftSemi (25)
               :                                      :- ^ ProjectExecTransformer (22)
               :                                      :  +- ^ FilterExecTransformer (21)
               :                                      :     +- ^ Scan parquet spark_catalog.default.lineitem (20)
               :                                      +- ^ InputIteratorTransformer (24)
               :                                         +- ReusedExchange (23)
               +- ^ InputIteratorTransformer (45)
                  +- ColumnarBroadcastExchange (44)
                     +- ^ ProjectExecTransformer (42)
                        +- ^ FilterExecTransformer (41)
                           +- ^ Scan parquet spark_catalog.default.nation (40)


(1) Scan parquet spark_catalog.default.supplier
Output [4]: [s_suppkey#X, s_name#X, s_address#X, s_nationkey#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/supplier]
PushedFilters: [IsNotNull(s_nationkey)]
ReadSchema: struct<s_suppkey:bigint,s_name:string,s_address:string,s_nationkey:bigint>

(2) FilterExecTransformer
Input [4]: [s_suppkey#X, s_name#X, s_address#X, s_nationkey#X]
Arguments: (isnotnull(s_nationkey#X) AND might_contain(Subquery scalar-subquery#X, [id=#X], xxhash64(s_nationkey#X, 42)))

(3) ProjectExecTransformer
Input [4]: [s_suppkey#X, s_name#X, s_address#X, s_nationkey#X]
Arguments: [hash(s_suppkey#X, 42) AS hash_partition_key#X, s_suppkey#X, s_name#X, s_address#X, s_nationkey#X]

(4) WholeStageCodegenTransformer (X)
Input [5]: [hash_partition_key#X, s_suppkey#X, s_name#X, s_address#X, s_nationkey#X]
Arguments: false
Native Plan:
-- Project
  -- TableScan

(5) ColumnarExchange
Input [5]: [hash_partition_key#X, s_suppkey#X, s_name#X, s_address#X, s_nationkey#X]
Arguments: hashpartitioning(s_suppkey#X, 100), ENSURE_REQUIREMENTS, [s_suppkey#X, s_name#X, s_address#X, s_nationkey#X], [plan_id=X], [id=#X]

(6) InputIteratorTransformer
Input [4]: [s_suppkey#X, s_name#X, s_address#X, s_nationkey#X]

(7) Scan parquet spark_catalog.default.partsupp
Output [3]: [ps_partkey#X, ps_suppkey#X, ps_availqty#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/partsupp]
PushedFilters: [IsNotNull(ps_availqty), IsNotNull(ps_partkey), IsNotNull(ps_suppkey)]
ReadSchema: struct<ps_partkey:bigint,ps_suppkey:bigint,ps_availqty:int>

(8) FilterExecTransformer
Input [3]: [ps_partkey#X, ps_suppkey#X, ps_availqty#X]
Arguments: ((isnotnull(ps_availqty#X) AND isnotnull(ps_partkey#X)) AND isnotnull(ps_suppkey#X))

(9) Scan parquet spark_catalog.default.part
Output [2]: [p_partkey#X, p_name#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/part]
PushedFilters: [IsNotNull(p_name), StringStartsWith(p_name,forest)]
ReadSchema: struct<p_partkey:bigint,p_name:string>

(10) FilterExecTransformer
Input [2]: [p_partkey#X, p_name#X]
Arguments: (isnotnull(p_name#X) AND StartsWith(p_name#X, forest))

(11) ProjectExecTransformer
Input [2]: [p_partkey#X, p_name#X]
Arguments: [p_partkey#X]

(12) WholeStageCodegenTransformer (X)
Input [1]: [p_partkey#X]
Arguments: false
Native Plan:
-- Project
  -- TableScan

(13) ColumnarBroadcastExchange
Input [1]: [p_partkey#X]
Arguments: HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=X]

(14) InputIteratorTransformer
Input [1]: [p_partkey#X]

(15) GlutenBroadcastHashJoinExecTransformer
Left keys [1]: [ps_partkey#X]
Right keys [1]: [p_partkey#X]
Join type: LeftSemi
Join condition: None

(16) ProjectExecTransformer
Input [3]: [ps_partkey#X, ps_suppkey#X, ps_availqty#X]
Arguments: [hash(ps_partkey#X, ps_suppkey#X, 42) AS hash_partition_key#X, hash(ps_partkey#X, ps_suppkey#X, 42) AS hash_partition_key#X, ps_partkey#X, ps_suppkey#X, ps_availqty#X]

(17) WholeStageCodegenTransformer (X)
Input [5]: [hash_partition_key#X, hash_partition_key#X, ps_partkey#X, ps_suppkey#X, ps_availqty#X]
Arguments: false
Native Plan:
-- Project
  -- Project
    -- HashJoin
      -- TableScan
      -- ValueStream

(18) ColumnarExchange
Input [5]: [hash_partition_key#X, hash_partition_key#X, ps_partkey#X, ps_suppkey#X, ps_availqty#X]
Arguments: hashpartitioning(ps_partkey#X, ps_suppkey#X, 100), ENSURE_REQUIREMENTS, [hash_partition_key#X, ps_partkey#X, ps_suppkey#X, ps_availqty#X], [plan_id=X], [id=#X]

(19) InputIteratorTransformer
Input [4]: [hash_partition_key#X, ps_partkey#X, ps_suppkey#X, ps_availqty#X]

(20) Scan parquet spark_catalog.default.lineitem
Output [4]: [l_partkey#X, l_suppkey#X, l_quantity#X, l_shipdate#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/lineitem]
PushedFilters: [IsNotNull(l_shipdate), GreaterThanOrEqual(l_shipdate,1994-01-01), LessThan(l_shipdate,1995-01-01), IsNotNull(l_partkey), IsNotNull(l_suppkey)]
ReadSchema: struct<l_partkey:bigint,l_suppkey:bigint,l_quantity:decimal(12,2),l_shipdate:date>

(21) FilterExecTransformer
Input [4]: [l_partkey#X, l_suppkey#X, l_quantity#X, l_shipdate#X]
Arguments: ((((isnotnull(l_shipdate#X) AND (l_shipdate#X >= 1994-01-01)) AND (l_shipdate#X < 1995-01-01)) AND isnotnull(l_partkey#X)) AND isnotnull(l_suppkey#X))

(22) ProjectExecTransformer
Input [4]: [l_partkey#X, l_suppkey#X, l_quantity#X, l_shipdate#X]
Arguments: [l_partkey#X, l_suppkey#X, l_quantity#X]

(23) ReusedExchange [Reuses operator id: 13]
Output [1]: [p_partkey#X]

(24) InputIteratorTransformer
Input [1]: [p_partkey#X]

(25) GlutenBroadcastHashJoinExecTransformer
Left keys [1]: [l_partkey#X]
Right keys [1]: [p_partkey#X]
Join type: LeftSemi
Join condition: None

(26) FlushableHashAggregateExecTransformer
Input [3]: [l_partkey#X, l_suppkey#X, l_quantity#X]
Keys [2]: [l_partkey#X, l_suppkey#X]
Functions [1]: [partial_sum(l_quantity#X)]
Aggregate Attributes [2]: [sum#X, isEmpty#X]
Results [4]: [l_partkey#X, l_suppkey#X, sum#X, isEmpty#X]

(27) ProjectExecTransformer
Input [4]: [l_partkey#X, l_suppkey#X, sum#X, isEmpty#X]
Arguments: [hash(l_partkey#X, l_suppkey#X, 42) AS hash_partition_key#X, hash(l_partkey#X, l_suppkey#X, 42) AS hash_partition_key#X, l_partkey#X, l_suppkey#X, sum#X, isEmpty#X]

(28) WholeStageCodegenTransformer (X)
Input [6]: [hash_partition_key#X, hash_partition_key#X, l_partkey#X, l_suppkey#X, sum#X, isEmpty#X]
Arguments: false
Native Plan:
-- Project
  -- Project
    -- Aggregation
      -- Project
        -- HashJoin
          -- Project
            -- TableScan
          -- ValueStream

(29) ColumnarExchange
Input [6]: [hash_partition_key#X, hash_partition_key#X, l_partkey#X, l_suppkey#X, sum#X, isEmpty#X]
Arguments: hashpartitioning(l_partkey#X, l_suppkey#X, 100), ENSURE_REQUIREMENTS, [hash_partition_key#X, l_partkey#X, l_suppkey#X, sum#X, isEmpty#X], [plan_id=X], [id=#X]

(30) InputIteratorTransformer
Input [5]: [hash_partition_key#X, l_partkey#X, l_suppkey#X, sum#X, isEmpty#X]

(31) RegularHashAggregateExecTransformer
Input [5]: [hash_partition_key#X, l_partkey#X, l_suppkey#X, sum#X, isEmpty#X]
Keys [2]: [l_partkey#X, l_suppkey#X]
Functions [1]: [sum(l_quantity#X)]
Aggregate Attributes [1]: [sum(l_quantity#X)#X]
Results [3]: [(0.5 * sum(l_quantity#X)#X) AS (0.5 * sum(l_quantity))#X, l_partkey#X, l_suppkey#X]

(32) FilterExecTransformer
Input [3]: [(0.5 * sum(l_quantity))#X, l_partkey#X, l_suppkey#X]
Arguments: isnotnull((0.5 * sum(l_quantity))#X)

(33) ShuffledHashJoinExecTransformer
Left keys [2]: [ps_partkey#X, ps_suppkey#X]
Right keys [2]: [l_partkey#X, l_suppkey#X]
Join type: Inner
Join condition: (cast(ps_availqty#X as decimal(24,3)) > (0.5 * sum(l_quantity))#X)

(34) ProjectExecTransformer
Input [7]: [hash_partition_key#X, ps_partkey#X, ps_suppkey#X, ps_availqty#X, (0.5 * sum(l_quantity))#X, l_partkey#X, l_suppkey#X]
Arguments: [hash(ps_suppkey#X, 42) AS hash_partition_key#X, ps_suppkey#X]

(35) WholeStageCodegenTransformer (X)
Input [2]: [hash_partition_key#X, ps_suppkey#X]
Arguments: false
Native Plan:
-- Project
  -- Project
    -- HashJoin
      -- Filter
        -- Project
          -- Aggregation
            -- Project
              -- ValueStream
      -- ValueStream

(36) ColumnarExchange
Input [2]: [hash_partition_key#X, ps_suppkey#X]
Arguments: hashpartitioning(ps_suppkey#X, 100), ENSURE_REQUIREMENTS, [ps_suppkey#X], [plan_id=X], [id=#X]

(37) InputIteratorTransformer
Input [1]: [ps_suppkey#X]

(38) ShuffledHashJoinExecTransformer
Left keys [1]: [s_suppkey#X]
Right keys [1]: [ps_suppkey#X]
Join type: LeftSemi
Join condition: None

(39) ProjectExecTransformer
Input [4]: [s_suppkey#X, s_name#X, s_address#X, s_nationkey#X]
Arguments: [s_name#X, s_address#X, s_nationkey#X]

(40) Scan parquet spark_catalog.default.nation
Output [2]: [n_nationkey#X, n_name#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/nation]
PushedFilters: [IsNotNull(n_name), EqualTo(n_name,CANADA), IsNotNull(n_nationkey)]
ReadSchema: struct<n_nationkey:bigint,n_name:string>

(41) FilterExecTransformer
Input [2]: [n_nationkey#X, n_name#X]
Arguments: ((isnotnull(n_name#X) AND (n_name#X = CANADA)) AND isnotnull(n_nationkey#X))

(42) ProjectExecTransformer
Input [2]: [n_nationkey#X, n_name#X]
Arguments: [n_nationkey#X]

(43) WholeStageCodegenTransformer (X)
Input [1]: [n_nationkey#X]
Arguments: false
Native Plan:
-- Project
  -- TableScan

(44) ColumnarBroadcastExchange
Input [1]: [n_nationkey#X]
Arguments: HashedRelationBroadcastMode(List(input[0, bigint, true]),false), [plan_id=X]

(45) InputIteratorTransformer
Input [1]: [n_nationkey#X]

(46) GlutenBroadcastHashJoinExecTransformer
Left keys [1]: [s_nationkey#X]
Right keys [1]: [n_nationkey#X]
Join type: Inner
Join condition: None

(47) ProjectExecTransformer
Input [4]: [s_name#X, s_address#X, s_nationkey#X, n_nationkey#X]
Arguments: [s_name#X, s_address#X]

(48) WholeStageCodegenTransformer (X)
Input [2]: [s_name#X, s_address#X]
Arguments: false
Native Plan:
-- Project
  -- Project
    -- HashJoin
      -- Project
        -- Project
          -- HashJoin
            -- ValueStream
            -- ValueStream
      -- ValueStream

(49) ColumnarExchange
Input [2]: [s_name#X, s_address#X]
Arguments: rangepartitioning(s_name#X ASC NULLS FIRST, 100), ENSURE_REQUIREMENTS, [plan_id=X], [id=#X]

(50) InputIteratorTransformer
Input [2]: [s_name#X, s_address#X]

(51) SortExecTransformer
Input [2]: [s_name#X, s_address#X]
Arguments: [s_name#X ASC NULLS FIRST], true, 0

(52) WholeStageCodegenTransformer (X)
Input [2]: [s_name#X, s_address#X]
Arguments: false
Native Plan:
-- OrderBy
  -- ValueStream

(53) VeloxColumnarToRowExec
Input [2]: [s_name#X, s_address#X]

===== Subqueries =====

Subquery:1 Hosting operator id = 2 Hosting Expression = Subquery scalar-subquery#X, [id=#X]
VeloxColumnarToRowExec (63)
+- ^ RegularHashAggregateExecTransformer (61)
   +- ^ InputIteratorTransformer (60)
      +- ColumnarExchange (59)
         +- ^ FlushableHashAggregateExecTransformer (57)
            +- ^ ProjectExecTransformer (56)
               +- ^ FilterExecTransformer (55)
                  +- ^ Scan parquet spark_catalog.default.nation (54)


(54) Scan parquet spark_catalog.default.nation
Output [2]: [n_nationkey#X, n_name#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/nation]
PushedFilters: [IsNotNull(n_name), EqualTo(n_name,CANADA), IsNotNull(n_nationkey)]
ReadSchema: struct<n_nationkey:bigint,n_name:string>

(55) FilterExecTransformer
Input [2]: [n_nationkey#X, n_name#X]
Arguments: ((isnotnull(n_name#X) AND (n_name#X = CANADA)) AND isnotnull(n_nationkey#X))

(56) ProjectExecTransformer
Input [2]: [n_nationkey#X, n_name#X]
Arguments: [n_nationkey#X]

(57) FlushableHashAggregateExecTransformer
Input [1]: [n_nationkey#X]
Keys: []
Functions [1]: [partial_bloom_filter_agg(xxhash64(n_nationkey#X, 42), 1000000, 8388608, 0, 0)]
Aggregate Attributes [1]: [buf#X]
Results [1]: [buf#X]

(58) WholeStageCodegenTransformer (X)
Input [1]: [buf#X]
Arguments: false
Native Plan:
-- Aggregation[PARTIAL n3_0 := bloom_filter_agg_partial("n2_1","n2_2","n2_3")] -> n3_0:VARBINARY
  -- Project[expressions: (n2_1:BIGINT, xxhash64(42,"n1_2")), (n2_2:BIGINT, 1000000), (n2_3:BIGINT, 8388608)] -> n2_1:BIGINT, n2_2:BIGINT, n2_3:BIGINT
    -- Project[expressions: (n1_2:BIGINT, "n0_0")] -> n1_2:BIGINT
      -- TableScan[table: hive_table, range filters: [(n_name, BytesRange: [CANADA, CANADA] no nulls), (n_nationkey, Filter(IsNotNull, deterministic, null not allowed))]] -> n0_0:BIGINT, n0_1:VARCHAR

(59) ColumnarExchange
Input [1]: [buf#X]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=X], [id=#X]

(60) InputIteratorTransformer
Input [1]: [buf#X]

(61) RegularHashAggregateExecTransformer
Input [1]: [buf#X]
Keys: []
Functions [1]: [bloom_filter_agg(xxhash64(n_nationkey#X, 42), 1000000, 8388608, 0, 0)]
Aggregate Attributes [1]: [bloom_filter_agg(xxhash64(n_nationkey#X, 42), 1000000, 8388608, 0, 0)#X]
Results [1]: [bloom_filter_agg(xxhash64(n_nationkey#X, 42), 1000000, 8388608, 0, 0)#X AS bloomFilter#X]

(62) WholeStageCodegenTransformer (X)
Input [1]: [bloomFilter#X]
Arguments: false
Native Plan:
-- Project[expressions: (n2_1:VARBINARY, "n1_0")] -> n2_1:VARBINARY
  -- Aggregation[SINGLE n1_0 := bloom_filter_agg_merge_extract("n0_0")] -> n1_0:VARBINARY
    -- ValueStream[] -> n0_0:VARBINARY

(63) VeloxColumnarToRowExec
Input [1]: [bloomFilter#X]

Subquery:2 Hosting operator id = 1 Hosting Expression = Subquery scalar-subquery#X, [id=#X]
VeloxColumnarToRowExec (63)
+- ^ RegularHashAggregateExecTransformer (61)
   +- ^ InputIteratorTransformer (60)
      +- ColumnarExchange (59)
         +- ^ FlushableHashAggregateExecTransformer (57)
            +- ^ ProjectExecTransformer (56)
               +- ^ FilterExecTransformer (55)
                  +- ^ Scan parquet spark_catalog.default.nation (54)



