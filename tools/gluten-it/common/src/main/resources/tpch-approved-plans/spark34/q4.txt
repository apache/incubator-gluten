== Physical Plan ==
VeloxColumnarToRowExec (26)
+- ^ SortExecTransformer (24)
   +- ^ InputIteratorTransformer (23)
      +- ColumnarExchange (22)
         +- ^ RegularHashAggregateExecTransformer (20)
            +- ^ InputIteratorTransformer (19)
               +- ColumnarExchange (18)
                  +- ^ ProjectExecTransformer (16)
                     +- ^ FlushableHashAggregateExecTransformer (15)
                        +- ^ ProjectExecTransformer (14)
                           +- ^ ShuffledHashJoinExecTransformer LeftSemi (13)
                              :- ^ InputIteratorTransformer (6)
                              :  +- ColumnarExchange (5)
                              :     +- ^ ProjectExecTransformer (3)
                              :        +- ^ FilterExecTransformer (2)
                              :           +- ^ Scan parquet spark_catalog.default.orders (1)
                              +- ^ InputIteratorTransformer (12)
                                 +- ColumnarExchange (11)
                                    +- ^ ProjectExecTransformer (9)
                                       +- ^ FilterExecTransformer (8)
                                          +- ^ Scan parquet spark_catalog.default.lineitem (7)


(1) Scan parquet spark_catalog.default.orders
Output [3]: [o_orderkey#1958L, o_orderpriority#1962, o_orderdate#1966]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/orders]
PushedFilters: [IsNotNull(o_orderdate), GreaterThanOrEqual(o_orderdate,1993-07-01), LessThan(o_orderdate,1993-10-01)]
ReadSchema: struct<o_orderkey:bigint,o_orderpriority:string,o_orderdate:date>

(2) FilterExecTransformer
Input [3]: [o_orderkey#1958L, o_orderpriority#1962, o_orderdate#1966]
Arguments: ((isnotnull(o_orderdate#1966) AND (o_orderdate#1966 >= 1993-07-01)) AND (o_orderdate#1966 < 1993-10-01))

(3) ProjectExecTransformer
Input [3]: [o_orderkey#1958L, o_orderpriority#1962, o_orderdate#1966]
Arguments: [hash(o_orderkey#1958L, 42) AS hash_partition_key#2072, hash(o_orderkey#1958L, 42) AS hash_partition_key#2069, o_orderkey#1958L, o_orderpriority#1962]

(4) WholeStageCodegenTransformer (25)
Input [4]: [hash_partition_key#2072, hash_partition_key#2069, o_orderkey#1958L, o_orderpriority#1962]
Arguments: false
Native Plan:
-- Project[expressions: (n1_3:INTEGER, hash_with_seed(42,"n0_0")), (n1_4:INTEGER, hash_with_seed(42,"n0_0")), (n1_5:BIGINT, "n0_0"), (n1_6:VARCHAR, "n0_1")] -> n1_3:INTEGER, n1_4:INTEGER, n1_5:BIGINT, n1_6:VARCHAR
  -- TableScan[table: hive_table, range filters: [(o_orderdate, BigintRange: [8582, 8673] no nulls)]] -> n0_0:BIGINT, n0_1:VARCHAR, n0_2:DATE

(5) ColumnarExchange
Input [4]: [hash_partition_key#2072, hash_partition_key#2069, o_orderkey#1958L, o_orderpriority#1962]
Arguments: hashpartitioning(o_orderkey#1958L, 100), ENSURE_REQUIREMENTS, [hash_partition_key#2069, o_orderkey#1958L, o_orderpriority#1962], [plan_id=2680], [id=#2680]

(6) InputIteratorTransformer
Input [3]: [hash_partition_key#2069, o_orderkey#1958L, o_orderpriority#1962]

(7) Scan parquet spark_catalog.default.lineitem
Output [3]: [l_orderkey#2012L, l_commitdate#2022, l_receiptdate#2023]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/lineitem]
PushedFilters: [IsNotNull(l_commitdate), IsNotNull(l_receiptdate)]
ReadSchema: struct<l_orderkey:bigint,l_commitdate:date,l_receiptdate:date>

(8) FilterExecTransformer
Input [3]: [l_orderkey#2012L, l_commitdate#2022, l_receiptdate#2023]
Arguments: ((isnotnull(l_commitdate#2022) AND isnotnull(l_receiptdate#2023)) AND (l_commitdate#2022 < l_receiptdate#2023))

(9) ProjectExecTransformer
Input [3]: [l_orderkey#2012L, l_commitdate#2022, l_receiptdate#2023]
Arguments: [hash(l_orderkey#2012L, 42) AS hash_partition_key#2073, hash(l_orderkey#2012L, 42) AS hash_partition_key#2070, l_orderkey#2012L]

(10) WholeStageCodegenTransformer (26)
Input [3]: [hash_partition_key#2073, hash_partition_key#2070, l_orderkey#2012L]
Arguments: false
Native Plan:
-- Project[expressions: (n1_3:INTEGER, hash_with_seed(42,"n0_0")), (n1_4:INTEGER, hash_with_seed(42,"n0_0")), (n1_5:BIGINT, "n0_0")] -> n1_3:INTEGER, n1_4:INTEGER, n1_5:BIGINT
  -- TableScan[table: hive_table, range filters: [(l_commitdate, Filter(IsNotNull, deterministic, null not allowed)), (l_receiptdate, Filter(IsNotNull, deterministic, null not allowed))], remaining filter: (lessthan("l_commitdate","l_receiptdate"))] -> n0_0:BIGINT, n0_1:DATE, n0_2:DATE

(11) ColumnarExchange
Input [3]: [hash_partition_key#2073, hash_partition_key#2070, l_orderkey#2012L]
Arguments: hashpartitioning(l_orderkey#2012L, 100), ENSURE_REQUIREMENTS, [hash_partition_key#2070, l_orderkey#2012L], [plan_id=2684], [id=#2684]

(12) InputIteratorTransformer
Input [2]: [hash_partition_key#2070, l_orderkey#2012L]

(13) ShuffledHashJoinExecTransformer
Left keys [1]: [o_orderkey#1958L]
Right keys [1]: [l_orderkey#2012L]
Join type: LeftSemi
Join condition: None

(14) ProjectExecTransformer
Input [3]: [hash_partition_key#2069, o_orderkey#1958L, o_orderpriority#1962]
Arguments: [o_orderpriority#1962]

(15) FlushableHashAggregateExecTransformer
Input [1]: [o_orderpriority#1962]
Keys [1]: [o_orderpriority#1962]
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#2067L]
Results [2]: [o_orderpriority#1962, count#2068L]

(16) ProjectExecTransformer
Input [2]: [o_orderpriority#1962, count#2068L]
Arguments: [hash(o_orderpriority#1962, 42) AS hash_partition_key#2071, o_orderpriority#1962, count#2068L]

(17) WholeStageCodegenTransformer (27)
Input [3]: [hash_partition_key#2071, o_orderpriority#1962, count#2068L]
Arguments: false
Native Plan:
-- Project[expressions: (n6_2:INTEGER, hash_with_seed(42,"n4_3")), (n6_3:VARCHAR, "n4_3"), (n6_4:BIGINT, "n5_1")] -> n6_2:INTEGER, n6_3:VARCHAR, n6_4:BIGINT
  -- Aggregation[PARTIAL [n4_3] n5_1 := count_partial(1)] -> n4_3:VARCHAR, n5_1:BIGINT
    -- Project[expressions: (n4_3:VARCHAR, "n3_5")] -> n4_3:VARCHAR
      -- Project[expressions: (n3_3:INTEGER, "n0_0"), (n3_4:BIGINT, "n0_1"), (n3_5:VARCHAR, "n0_2")] -> n3_3:INTEGER, n3_4:BIGINT, n3_5:VARCHAR
        -- HashJoin[LEFT SEMI (FILTER) n0_1=n1_1] -> n0_0:INTEGER, n0_1:BIGINT, n0_2:VARCHAR
          -- ValueStream[] -> n0_0:INTEGER, n0_1:BIGINT, n0_2:VARCHAR
          -- ValueStream[] -> n1_0:INTEGER, n1_1:BIGINT

(18) ColumnarExchange
Input [3]: [hash_partition_key#2071, o_orderpriority#1962, count#2068L]
Arguments: hashpartitioning(o_orderpriority#1962, 100), ENSURE_REQUIREMENTS, [o_orderpriority#1962, count#2068L], [plan_id=2692], [id=#2692]

(19) InputIteratorTransformer
Input [2]: [o_orderpriority#1962, count#2068L]

(20) RegularHashAggregateExecTransformer
Input [2]: [o_orderpriority#1962, count#2068L]
Keys [1]: [o_orderpriority#1962]
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#2062L]
Results [2]: [o_orderpriority#1962, count(1)#2062L AS order_count#2060L]

(21) WholeStageCodegenTransformer (28)
Input [2]: [o_orderpriority#1962, order_count#2060L]
Arguments: false
Native Plan:
-- Project[expressions: (n2_2:VARCHAR, "n0_0"), (n2_3:BIGINT, "n1_1")] -> n2_2:VARCHAR, n2_3:BIGINT
  -- Aggregation[SINGLE [n0_0] n1_1 := count_merge_extract("n0_1")] -> n0_0:VARCHAR, n1_1:BIGINT
    -- ValueStream[] -> n0_0:VARCHAR, n0_1:BIGINT

(22) ColumnarExchange
Input [2]: [o_orderpriority#1962, order_count#2060L]
Arguments: rangepartitioning(o_orderpriority#1962 ASC NULLS FIRST, 100), ENSURE_REQUIREMENTS, [plan_id=2697], [id=#2697]

(23) InputIteratorTransformer
Input [2]: [o_orderpriority#1962, order_count#2060L]

(24) SortExecTransformer
Input [2]: [o_orderpriority#1962, order_count#2060L]
Arguments: [o_orderpriority#1962 ASC NULLS FIRST], true, 0

(25) WholeStageCodegenTransformer (29)
Input [2]: [o_orderpriority#1962, order_count#2060L]
Arguments: false
Native Plan:
-- OrderBy[n0_0 ASC NULLS FIRST] -> n0_0:VARCHAR, n0_1:BIGINT
  -- ValueStream[] -> n0_0:VARCHAR, n0_1:BIGINT

(26) VeloxColumnarToRowExec
Input [2]: [o_orderpriority#1962, order_count#2060L]

