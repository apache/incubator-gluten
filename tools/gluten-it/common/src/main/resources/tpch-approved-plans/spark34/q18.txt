== Physical Plan ==
AdaptiveSparkPlan (82)
+- == Final Plan ==
   VeloxColumnarToRowExec (51)
   +- TakeOrderedAndProjectExecTransformer (50)
      +- ^ RegularHashAggregateExecTransformer (48)
         +- ^ RegularHashAggregateExecTransformer (47)
            +- ^ ProjectExecTransformer (46)
               +- ^ ShuffledHashJoinExecTransformer Inner (45)
                  :- ^ ProjectExecTransformer (28)
                  :  +- ^ GlutenBroadcastHashJoinExecTransformer Inner (27)
                  :     :- ^ InputIteratorTransformer (6)
                  :     :  +- BroadcastQueryStage (5), Statistics(X)
                  :     :     +- ColumnarBroadcastExchange (4)
                  :     :        +- ^ FilterExecTransformer (2)
                  :     :           +- ^ Scan parquet spark_catalog.default.customer (1)
                  :     +- ^ ShuffledHashJoinExecTransformer LeftSemi (26)
                  :        :- ^ InputIteratorTransformer (14)
                  :        :  +- AQEShuffleRead (13)
                  :        :     +- ShuffleQueryStage (12), Statistics(X)
                  :        :        +- ColumnarExchange (11)
                  :        :           +- ^ ProjectExecTransformer (9)
                  :        :              +- ^ FilterExecTransformer (8)
                  :        :                 +- ^ Scan parquet spark_catalog.default.orders (7)
                  :        +- ^ ProjectExecTransformer (25)
                  :           +- ^ FilterExecTransformer (24)
                  :              +- ^ RegularHashAggregateExecTransformer (23)
                  :                 +- ^ InputIteratorTransformer (22)
                  :                    +- AQEShuffleRead (21)
                  :                       +- ShuffleQueryStage (20), Statistics(X)
                  :                          +- ColumnarExchange (19)
                  :                             +- ^ ProjectExecTransformer (17)
                  :                                +- ^ FlushableHashAggregateExecTransformer (16)
                  :                                   +- ^ Scan parquet spark_catalog.default.lineitem (15)
                  +- ^ ShuffledHashJoinExecTransformer LeftSemi (44)
                     :- ^ InputIteratorTransformer (36)
                     :  +- AQEShuffleRead (35)
                     :     +- ShuffleQueryStage (34), Statistics(X)
                     :        +- ColumnarExchange (33)
                     :           +- ^ ProjectExecTransformer (31)
                     :              +- ^ FilterExecTransformer (30)
                     :                 +- ^ Scan parquet spark_catalog.default.lineitem (29)
                     +- ^ ProjectExecTransformer (43)
                        +- ^ FilterExecTransformer (42)
                           +- ^ RegularHashAggregateExecTransformer (41)
                              +- ^ InputIteratorTransformer (40)
                                 +- AQEShuffleRead (39)
                                    +- ShuffleQueryStage (38), Statistics(X)
                                       +- ReusedExchange (37)
+- == Initial Plan ==
   TakeOrderedAndProject (81)
   +- HashAggregate (80)
      +- HashAggregate (79)
         +- Project (78)
            +- ShuffledHashJoin Inner BuildRight (77)
               :- Project (66)
               :  +- BroadcastHashJoin Inner BuildLeft (65)
               :     :- BroadcastExchange (54)
               :     :  +- Filter (53)
               :     :     +- Scan parquet spark_catalog.default.customer (52)
               :     +- ShuffledHashJoin LeftSemi BuildRight (64)
               :        :- Exchange (57)
               :        :  +- Filter (56)
               :        :     +- Scan parquet spark_catalog.default.orders (55)
               :        +- Project (63)
               :           +- Filter (62)
               :              +- HashAggregate (61)
               :                 +- Exchange (60)
               :                    +- HashAggregate (59)
               :                       +- Scan parquet spark_catalog.default.lineitem (58)
               +- ShuffledHashJoin LeftSemi BuildRight (76)
                  :- Exchange (69)
                  :  +- Filter (68)
                  :     +- Scan parquet spark_catalog.default.lineitem (67)
                  +- Project (75)
                     +- Filter (74)
                        +- HashAggregate (73)
                           +- Exchange (72)
                              +- HashAggregate (71)
                                 +- Scan parquet spark_catalog.default.lineitem (70)


(1) Scan parquet spark_catalog.default.customer
Output [2]: [c_custkey#X, c_name#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/customer]
PushedFilters: [IsNotNull(c_custkey)]
ReadSchema: struct<c_custkey:bigint,c_name:string>

(2) FilterExecTransformer
Input [2]: [c_custkey#X, c_name#X]
Arguments: isnotnull(c_custkey#X)

(3) WholeStageCodegenTransformer (X)
Input [2]: [c_custkey#X, c_name#X]
Arguments: false
Native Plan:
-- TableScan[table: hive_table, range filters: [(c_custkey, Filter(IsNotNull, deterministic, null not allowed))]] -> n0_0:BIGINT, n0_1:VARCHAR

(4) ColumnarBroadcastExchange
Input [2]: [c_custkey#X, c_name#X]
Arguments: HashedRelationBroadcastMode(List(input[0, bigint, false]),false), [plan_id=X]

(5) BroadcastQueryStage
Output [2]: [c_custkey#X, c_name#X]
Arguments: 0

(6) InputIteratorTransformer
Input [2]: [c_custkey#X, c_name#X]

(7) Scan parquet spark_catalog.default.orders
Output [4]: [o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/orders]
PushedFilters: [IsNotNull(o_custkey), IsNotNull(o_orderkey)]
ReadSchema: struct<o_orderkey:bigint,o_custkey:bigint,o_totalprice:decimal(12,2),o_orderdate:date>

(8) FilterExecTransformer
Input [4]: [o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]
Arguments: (isnotnull(o_custkey#X) AND isnotnull(o_orderkey#X))

(9) ProjectExecTransformer
Input [4]: [o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]
Arguments: [hash(o_orderkey#X, 42) AS hash_partition_key#X, o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]

(10) WholeStageCodegenTransformer (X)
Input [5]: [hash_partition_key#X, o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]
Arguments: false
Native Plan:
-- Project[expressions: (n1_4:INTEGER, hash_with_seed(42,"n0_0")), (n1_5:BIGINT, "n0_0"), (n1_6:BIGINT, "n0_1"), (n1_7:DECIMAL(12, 2), "n0_2"), (n1_8:DATE, "n0_3")] -> n1_4:INTEGER, n1_5:BIGINT, n1_6:BIGINT, n1_7:DECIMAL(12, 2), n1_8:DATE
  -- TableScan[table: hive_table, range filters: [(o_custkey, Filter(IsNotNull, deterministic, null not allowed)), (o_orderkey, Filter(IsNotNull, deterministic, null not allowed))]] -> n0_0:BIGINT, n0_1:BIGINT, n0_2:DECIMAL(12, 2), n0_3:DATE

(11) ColumnarExchange
Input [5]: [hash_partition_key#X, o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]
Arguments: hashpartitioning(o_orderkey#X, 100), ENSURE_REQUIREMENTS, [o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X], [plan_id=X], [id=#X]

(12) ShuffleQueryStage
Output [4]: [o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]
Arguments: 1

(13) AQEShuffleRead
Input [4]: [o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]
Arguments: coalesced

(14) InputIteratorTransformer
Input [4]: [o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]

(15) Scan parquet spark_catalog.default.lineitem
Output [2]: [l_orderkey#X, l_quantity#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/lineitem]
ReadSchema: struct<l_orderkey:bigint,l_quantity:decimal(12,2)>

(16) FlushableHashAggregateExecTransformer
Input [2]: [l_orderkey#X, l_quantity#X]
Keys [1]: [l_orderkey#X]
Functions [1]: [partial_sum(l_quantity#X)]
Aggregate Attributes [2]: [sum#X, isEmpty#X]
Results [3]: [l_orderkey#X, sum#X, isEmpty#X]

(17) ProjectExecTransformer
Input [3]: [l_orderkey#X, sum#X, isEmpty#X]
Arguments: [hash(l_orderkey#X, 42) AS hash_partition_key#X, l_orderkey#X, sum#X, isEmpty#X]

(18) WholeStageCodegenTransformer (X)
Input [4]: [hash_partition_key#X, l_orderkey#X, sum#X, isEmpty#X]
Arguments: false
Native Plan:
-- Project[expressions: (n3_3:INTEGER, hash_with_seed(42,"n2_2")), (n3_4:BIGINT, "n2_2"), (n3_5:DECIMAL(22, 2), "n2_3"), (n3_6:BOOLEAN, "n2_4")] -> n3_3:INTEGER, n3_4:BIGINT, n3_5:DECIMAL(22, 2), n3_6:BOOLEAN
  -- Project[expressions: (n2_2:BIGINT, "n0_0"), (n2_3:DECIMAL(22, 2), "n1_1"["col_0"]), (n2_4:BOOLEAN, "n1_1"["col_1"])] -> n2_2:BIGINT, n2_3:DECIMAL(22, 2), n2_4:BOOLEAN
    -- Aggregation[PARTIAL [n0_0] n1_1 := sum_partial("n0_1")] -> n0_0:BIGINT, n1_1:ROW<col_0:DECIMAL(22, 2),col_1:BOOLEAN>
      -- TableScan[table: hive_table] -> n0_0:BIGINT, n0_1:DECIMAL(12, 2)

(19) ColumnarExchange
Input [4]: [hash_partition_key#X, l_orderkey#X, sum#X, isEmpty#X]
Arguments: hashpartitioning(l_orderkey#X, 100), ENSURE_REQUIREMENTS, [l_orderkey#X, sum#X, isEmpty#X], [plan_id=X], [id=#X]

(20) ShuffleQueryStage
Output [3]: [l_orderkey#X, sum#X, isEmpty#X]
Arguments: 2

(21) AQEShuffleRead
Input [3]: [l_orderkey#X, sum#X, isEmpty#X]
Arguments: coalesced

(22) InputIteratorTransformer
Input [3]: [l_orderkey#X, sum#X, isEmpty#X]

(23) RegularHashAggregateExecTransformer
Input [3]: [l_orderkey#X, sum#X, isEmpty#X]
Keys [1]: [l_orderkey#X]
Functions [1]: [sum(l_quantity#X)]
Aggregate Attributes [1]: [sum(l_quantity#X)#X]
Results [2]: [l_orderkey#X, sum(l_quantity#X)#X AS sum(l_quantity#X)#X]

(24) FilterExecTransformer
Input [2]: [l_orderkey#X, sum(l_quantity#X)#X]
Arguments: (isnotnull(sum(l_quantity#X)#X) AND (sum(l_quantity#X)#X > 300.00))

(25) ProjectExecTransformer
Input [2]: [l_orderkey#X, sum(l_quantity#X)#X]
Arguments: [l_orderkey#X]

(26) ShuffledHashJoinExecTransformer
Left keys [1]: [o_orderkey#X]
Right keys [1]: [l_orderkey#X]
Join type: LeftSemi
Join condition: None

(27) GlutenBroadcastHashJoinExecTransformer
Left keys [1]: [c_custkey#X]
Right keys [1]: [o_custkey#X]
Join type: Inner
Join condition: None

(28) ProjectExecTransformer
Input [6]: [c_custkey#X, c_name#X, o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]
Arguments: [c_custkey#X, c_name#X, o_orderkey#X, o_totalprice#X, o_orderdate#X]

(29) Scan parquet spark_catalog.default.lineitem
Output [2]: [l_orderkey#X, l_quantity#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/lineitem]
PushedFilters: [IsNotNull(l_orderkey)]
ReadSchema: struct<l_orderkey:bigint,l_quantity:decimal(12,2)>

(30) FilterExecTransformer
Input [2]: [l_orderkey#X, l_quantity#X]
Arguments: isnotnull(l_orderkey#X)

(31) ProjectExecTransformer
Input [2]: [l_orderkey#X, l_quantity#X]
Arguments: [hash(l_orderkey#X, 42) AS hash_partition_key#X, l_orderkey#X, l_quantity#X]

(32) WholeStageCodegenTransformer (X)
Input [3]: [hash_partition_key#X, l_orderkey#X, l_quantity#X]
Arguments: false
Native Plan:
-- Project[expressions: (n1_2:INTEGER, hash_with_seed(42,"n0_0")), (n1_3:BIGINT, "n0_0"), (n1_4:DECIMAL(12, 2), "n0_1")] -> n1_2:INTEGER, n1_3:BIGINT, n1_4:DECIMAL(12, 2)
  -- TableScan[table: hive_table, range filters: [(l_orderkey, Filter(IsNotNull, deterministic, null not allowed))]] -> n0_0:BIGINT, n0_1:DECIMAL(12, 2)

(33) ColumnarExchange
Input [3]: [hash_partition_key#X, l_orderkey#X, l_quantity#X]
Arguments: hashpartitioning(l_orderkey#X, 100), ENSURE_REQUIREMENTS, [l_orderkey#X, l_quantity#X], [plan_id=X], [id=#X]

(34) ShuffleQueryStage
Output [2]: [l_orderkey#X, l_quantity#X]
Arguments: 3

(35) AQEShuffleRead
Input [2]: [l_orderkey#X, l_quantity#X]
Arguments: coalesced

(36) InputIteratorTransformer
Input [2]: [l_orderkey#X, l_quantity#X]

(37) ReusedExchange [Reuses operator id: 19]
Output [3]: [l_orderkey#X, sum#X, isEmpty#X]

(38) ShuffleQueryStage
Output [3]: [l_orderkey#X, sum#X, isEmpty#X]
Arguments: 5

(39) AQEShuffleRead
Input [3]: [l_orderkey#X, sum#X, isEmpty#X]
Arguments: coalesced

(40) InputIteratorTransformer
Input [3]: [l_orderkey#X, sum#X, isEmpty#X]

(41) RegularHashAggregateExecTransformer
Input [3]: [l_orderkey#X, sum#X, isEmpty#X]
Keys [1]: [l_orderkey#X]
Functions [1]: [sum(l_quantity#X)]
Aggregate Attributes [1]: [sum(l_quantity#X)#X]
Results [2]: [l_orderkey#X, sum(l_quantity#X)#X AS sum(l_quantity#X)#X]

(42) FilterExecTransformer
Input [2]: [l_orderkey#X, sum(l_quantity#X)#X]
Arguments: (isnotnull(sum(l_quantity#X)#X) AND (sum(l_quantity#X)#X > 300.00))

(43) ProjectExecTransformer
Input [2]: [l_orderkey#X, sum(l_quantity#X)#X]
Arguments: [l_orderkey#X]

(44) ShuffledHashJoinExecTransformer
Left keys [1]: [l_orderkey#X]
Right keys [1]: [l_orderkey#X]
Join type: LeftSemi
Join condition: None

(45) ShuffledHashJoinExecTransformer
Left keys [1]: [o_orderkey#X]
Right keys [1]: [l_orderkey#X]
Join type: Inner
Join condition: None

(46) ProjectExecTransformer
Input [7]: [c_custkey#X, c_name#X, o_orderkey#X, o_totalprice#X, o_orderdate#X, l_orderkey#X, l_quantity#X]
Arguments: [c_custkey#X, c_name#X, o_orderkey#X, o_totalprice#X, o_orderdate#X, l_quantity#X]

(47) RegularHashAggregateExecTransformer
Input [6]: [c_custkey#X, c_name#X, o_orderkey#X, o_totalprice#X, o_orderdate#X, l_quantity#X]
Keys [5]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X]
Functions [1]: [partial_sum(l_quantity#X)]
Aggregate Attributes [2]: [sum#X, isEmpty#X]
Results [7]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum#X, isEmpty#X]

(48) RegularHashAggregateExecTransformer
Input [7]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum#X, isEmpty#X]
Keys [5]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X]
Functions [1]: [sum(l_quantity#X)]
Aggregate Attributes [1]: [sum(l_quantity#X)#X]
Results [6]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum(l_quantity#X)#X AS sum(l_quantity)#X]

(49) WholeStageCodegenTransformer (X)
Input [6]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum(l_quantity)#X]
Arguments: false
Native Plan:
-- Project[expressions: (n29_6:VARCHAR, "n27_7"), (n29_7:BIGINT, "n27_8"), (n29_8:BIGINT, "n27_9"), (n29_9:DATE, "n27_10"), (n29_10:DECIMAL(12, 2), "n27_11"), (n29_11:DECIMAL(22, 2), "n28_5")] -> n29_6:VARCHAR, n29_7:BIGINT, n29_8:BIGINT, n29_9:DATE, n29_10:DECIMAL(12, 2), n29_11:DECIMAL(22, 2)
  -- Aggregation[SINGLE [n27_7, n27_8, n27_9, n27_10, n27_11] n28_5 := sum_merge_extract("n27_12")] -> n27_7:VARCHAR, n27_8:BIGINT, n27_9:BIGINT, n27_10:DATE, n27_11:DECIMAL(12, 2), n28_5:DECIMAL(22, 2)
    -- Project[expressions: (n27_7:VARCHAR, "n26_6"), (n27_8:BIGINT, "n26_7"), (n27_9:BIGINT, "n26_8"), (n27_10:DATE, "n26_9"), (n27_11:DECIMAL(12, 2), "n26_10"), (n27_12:ROW<col_0:DECIMAL(22, 2),col_1:BOOLEAN>, row_constructor("n26_11","n26_12"))] -> n27_7:VARCHAR, n27_8:BIGINT, n27_9:BIGINT, n27_10:DATE, n27_11:DECIMAL(12, 2), n27_12:ROW<col_0:DECIMAL(22, 2),col_1:BOOLEAN>
      -- Project[expressions: (n26_6:VARCHAR, "n24_8"), (n26_7:BIGINT, "n24_7"), (n26_8:BIGINT, "n24_9"), (n26_9:DATE, "n24_11"), (n26_10:DECIMAL(12, 2), "n24_10"), (n26_11:DECIMAL(22, 2), "n25_5"["col_0"]), (n26_12:BOOLEAN, "n25_5"["col_1"])] -> n26_6:VARCHAR, n26_7:BIGINT, n26_8:BIGINT, n26_9:DATE, n26_10:DECIMAL(12, 2), n26_11:DECIMAL(22, 2), n26_12:BOOLEAN
        -- Aggregation[SINGLE [n24_8, n24_7, n24_9, n24_11, n24_10] n25_5 := sum_partial("n24_12")] -> n24_8:VARCHAR, n24_7:BIGINT, n24_9:BIGINT, n24_11:DATE, n24_10:DECIMAL(12, 2), n25_5:ROW<col_0:DECIMAL(22, 2),col_1:BOOLEAN>
          -- Project[expressions: (n24_7:BIGINT, "n23_7"), (n24_8:VARCHAR, "n23_8"), (n24_9:BIGINT, "n23_9"), (n24_10:DECIMAL(12, 2), "n23_10"), (n24_11:DATE, "n23_11"), (n24_12:DECIMAL(12, 2), "n23_13")] -> n24_7:BIGINT, n24_8:VARCHAR, n24_9:BIGINT, n24_10:DECIMAL(12, 2), n24_11:DATE, n24_12:DECIMAL(12, 2)
            -- Project[expressions: (n23_7:BIGINT, "n14_6"), (n23_8:VARCHAR, "n14_7"), (n23_9:BIGINT, "n14_8"), (n23_10:DECIMAL(12, 2), "n14_9"), (n23_11:DATE, "n14_10"), (n23_12:BIGINT, "n21_2"), (n23_13:DECIMAL(12, 2), "n21_3")] -> n23_7:BIGINT, n23_8:VARCHAR, n23_9:BIGINT, n23_10:DECIMAL(12, 2), n23_11:DATE, n23_12:BIGINT, n23_13:DECIMAL(12, 2)
              -- HashJoin[INNER n14_8=n21_2] -> n14_6:BIGINT, n14_7:VARCHAR, n14_8:BIGINT, n14_9:DECIMAL(12, 2), n14_10:DATE, n21_2:BIGINT, n21_3:DECIMAL(12, 2)
                -- Project[expressions: (n14_6:BIGINT, "n13_6"), (n14_7:VARCHAR, "n13_7"), (n14_8:BIGINT, "n13_8"), (n14_9:DECIMAL(12, 2), "n13_10"), (n14_10:DATE, "n13_11")] -> n14_6:BIGINT, n14_7:VARCHAR, n14_8:BIGINT, n14_9:DECIMAL(12, 2), n14_10:DATE
                  -- Project[expressions: (n13_6:BIGINT, "n2_0"), (n13_7:VARCHAR, "n2_1"), (n13_8:BIGINT, "n11_4"), (n13_9:BIGINT, "n11_5"), (n13_10:DECIMAL(12, 2), "n11_6"), (n13_11:DATE, "n11_7")] -> n13_6:BIGINT, n13_7:VARCHAR, n13_8:BIGINT, n13_9:BIGINT, n13_10:DECIMAL(12, 2), n13_11:DATE
                    -- HashJoin[INNER n11_5=n2_0] -> n11_4:BIGINT, n11_5:BIGINT, n11_6:DECIMAL(12, 2), n11_7:DATE, n2_0:BIGINT, n2_1:VARCHAR
                      -- Project[expressions: (n11_4:BIGINT, "n0_0"), (n11_5:BIGINT, "n0_1"), (n11_6:DECIMAL(12, 2), "n0_2"), (n11_7:DATE, "n0_3")] -> n11_4:BIGINT, n11_5:BIGINT, n11_6:DECIMAL(12, 2), n11_7:DATE
                        -- HashJoin[LEFT SEMI (FILTER) n0_0=n9_2] -> n0_0:BIGINT, n0_1:BIGINT, n0_2:DECIMAL(12, 2), n0_3:DATE
                          -- ValueStream[] -> n0_0:BIGINT, n0_1:BIGINT, n0_2:DECIMAL(12, 2), n0_3:DATE
                          -- Project[expressions: (n9_2:BIGINT, "n7_2")] -> n9_2:BIGINT
                            -- Filter[expression: and(isnotnull("n7_3"),decimal_greaterthan("n7_3",300.00))] -> n7_2:BIGINT, n7_3:DECIMAL(22, 2)
                              -- Project[expressions: (n7_2:BIGINT, "n5_3"), (n7_3:DECIMAL(22, 2), "n6_1")] -> n7_2:BIGINT, n7_3:DECIMAL(22, 2)
                                -- Aggregation[SINGLE [n5_3] n6_1 := sum_merge_extract("n5_4")] -> n5_3:BIGINT, n6_1:DECIMAL(22, 2)
                                  -- Project[expressions: (n5_3:BIGINT, "n1_0"), (n5_4:ROW<col_0:DECIMAL(22, 2),col_1:BOOLEAN>, row_constructor("n1_1","n1_2"))] -> n5_3:BIGINT, n5_4:ROW<col_0:DECIMAL(22, 2),col_1:BOOLEAN>
                                    -- ValueStream[] -> n1_0:BIGINT, n1_1:DECIMAL(22, 2), n1_2:BOOLEAN
                      -- ValueStream[] -> n2_0:BIGINT, n2_1:VARCHAR
                -- Project[expressions: (n21_2:BIGINT, "n3_0"), (n21_3:DECIMAL(12, 2), "n3_1")] -> n21_2:BIGINT, n21_3:DECIMAL(12, 2)
                  -- HashJoin[LEFT SEMI (FILTER) n3_0=n19_2] -> n3_0:BIGINT, n3_1:DECIMAL(12, 2)
                    -- ValueStream[] -> n3_0:BIGINT, n3_1:DECIMAL(12, 2)
                    -- Project[expressions: (n19_2:BIGINT, "n17_2")] -> n19_2:BIGINT
                      -- Filter[expression: and(isnotnull("n17_3"),decimal_greaterthan("n17_3",300.00))] -> n17_2:BIGINT, n17_3:DECIMAL(22, 2)
                        -- Project[expressions: (n17_2:BIGINT, "n15_3"), (n17_3:DECIMAL(22, 2), "n16_1")] -> n17_2:BIGINT, n17_3:DECIMAL(22, 2)
                          -- Aggregation[SINGLE [n15_3] n16_1 := sum_merge_extract("n15_4")] -> n15_3:BIGINT, n16_1:DECIMAL(22, 2)
                            -- Project[expressions: (n15_3:BIGINT, "n4_0"), (n15_4:ROW<col_0:DECIMAL(22, 2),col_1:BOOLEAN>, row_constructor("n4_1","n4_2"))] -> n15_3:BIGINT, n15_4:ROW<col_0:DECIMAL(22, 2),col_1:BOOLEAN>
                              -- ValueStream[] -> n4_0:BIGINT, n4_1:DECIMAL(22, 2), n4_2:BOOLEAN

(50) TakeOrderedAndProjectExecTransformer
Input [6]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum(l_quantity)#X]
Arguments: 100, [o_totalprice#X DESC NULLS LAST, o_orderdate#X ASC NULLS FIRST], [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum(l_quantity)#X]

(51) VeloxColumnarToRowExec
Input [6]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum(l_quantity)#X]

(52) Scan parquet spark_catalog.default.customer
Output [2]: [c_custkey#X, c_name#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/customer]
PushedFilters: [IsNotNull(c_custkey)]
ReadSchema: struct<c_custkey:bigint,c_name:string>

(53) Filter
Input [2]: [c_custkey#X, c_name#X]
Condition : isnotnull(c_custkey#X)

(54) BroadcastExchange
Input [2]: [c_custkey#X, c_name#X]
Arguments: HashedRelationBroadcastMode(List(input[0, bigint, false]),false), [plan_id=X]

(55) Scan parquet spark_catalog.default.orders
Output [4]: [o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/orders]
PushedFilters: [IsNotNull(o_custkey), IsNotNull(o_orderkey)]
ReadSchema: struct<o_orderkey:bigint,o_custkey:bigint,o_totalprice:decimal(12,2),o_orderdate:date>

(56) Filter
Input [4]: [o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]
Condition : (isnotnull(o_custkey#X) AND isnotnull(o_orderkey#X))

(57) Exchange
Input [4]: [o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]
Arguments: hashpartitioning(o_orderkey#X, 100), ENSURE_REQUIREMENTS, [plan_id=X]

(58) Scan parquet spark_catalog.default.lineitem
Output [2]: [l_orderkey#X, l_quantity#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/lineitem]
ReadSchema: struct<l_orderkey:bigint,l_quantity:decimal(12,2)>

(59) HashAggregate
Input [2]: [l_orderkey#X, l_quantity#X]
Keys [1]: [l_orderkey#X]
Functions [1]: [partial_sum(l_quantity#X)]
Aggregate Attributes [2]: [sum#X, isEmpty#X]
Results [3]: [l_orderkey#X, sum#X, isEmpty#X]

(60) Exchange
Input [3]: [l_orderkey#X, sum#X, isEmpty#X]
Arguments: hashpartitioning(l_orderkey#X, 100), ENSURE_REQUIREMENTS, [plan_id=X]

(61) HashAggregate
Input [3]: [l_orderkey#X, sum#X, isEmpty#X]
Keys [1]: [l_orderkey#X]
Functions [1]: [sum(l_quantity#X)]
Aggregate Attributes [1]: [sum(l_quantity#X)#X]
Results [2]: [l_orderkey#X, sum(l_quantity#X)#X AS sum(l_quantity#X)#X]

(62) Filter
Input [2]: [l_orderkey#X, sum(l_quantity#X)#X]
Condition : (isnotnull(sum(l_quantity#X)#X) AND (sum(l_quantity#X)#X > 300.00))

(63) Project
Output [1]: [l_orderkey#X]
Input [2]: [l_orderkey#X, sum(l_quantity#X)#X]

(64) ShuffledHashJoin
Left keys [1]: [o_orderkey#X]
Right keys [1]: [l_orderkey#X]
Join type: LeftSemi
Join condition: None

(65) BroadcastHashJoin
Left keys [1]: [c_custkey#X]
Right keys [1]: [o_custkey#X]
Join type: Inner
Join condition: None

(66) Project
Output [5]: [c_custkey#X, c_name#X, o_orderkey#X, o_totalprice#X, o_orderdate#X]
Input [6]: [c_custkey#X, c_name#X, o_orderkey#X, o_custkey#X, o_totalprice#X, o_orderdate#X]

(67) Scan parquet spark_catalog.default.lineitem
Output [2]: [l_orderkey#X, l_quantity#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/lineitem]
PushedFilters: [IsNotNull(l_orderkey)]
ReadSchema: struct<l_orderkey:bigint,l_quantity:decimal(12,2)>

(68) Filter
Input [2]: [l_orderkey#X, l_quantity#X]
Condition : isnotnull(l_orderkey#X)

(69) Exchange
Input [2]: [l_orderkey#X, l_quantity#X]
Arguments: hashpartitioning(l_orderkey#X, 100), ENSURE_REQUIREMENTS, [plan_id=X]

(70) Scan parquet spark_catalog.default.lineitem
Output [2]: [l_orderkey#X, l_quantity#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/lineitem]
ReadSchema: struct<l_orderkey:bigint,l_quantity:decimal(12,2)>

(71) HashAggregate
Input [2]: [l_orderkey#X, l_quantity#X]
Keys [1]: [l_orderkey#X]
Functions [1]: [partial_sum(l_quantity#X)]
Aggregate Attributes [2]: [sum#X, isEmpty#X]
Results [3]: [l_orderkey#X, sum#X, isEmpty#X]

(72) Exchange
Input [3]: [l_orderkey#X, sum#X, isEmpty#X]
Arguments: hashpartitioning(l_orderkey#X, 100), ENSURE_REQUIREMENTS, [plan_id=X]

(73) HashAggregate
Input [3]: [l_orderkey#X, sum#X, isEmpty#X]
Keys [1]: [l_orderkey#X]
Functions [1]: [sum(l_quantity#X)]
Aggregate Attributes [1]: [sum(l_quantity#X)#X]
Results [2]: [l_orderkey#X, sum(l_quantity#X)#X AS sum(l_quantity#X)#X]

(74) Filter
Input [2]: [l_orderkey#X, sum(l_quantity#X)#X]
Condition : (isnotnull(sum(l_quantity#X)#X) AND (sum(l_quantity#X)#X > 300.00))

(75) Project
Output [1]: [l_orderkey#X]
Input [2]: [l_orderkey#X, sum(l_quantity#X)#X]

(76) ShuffledHashJoin
Left keys [1]: [l_orderkey#X]
Right keys [1]: [l_orderkey#X]
Join type: LeftSemi
Join condition: None

(77) ShuffledHashJoin
Left keys [1]: [o_orderkey#X]
Right keys [1]: [l_orderkey#X]
Join type: Inner
Join condition: None

(78) Project
Output [6]: [c_custkey#X, c_name#X, o_orderkey#X, o_totalprice#X, o_orderdate#X, l_quantity#X]
Input [7]: [c_custkey#X, c_name#X, o_orderkey#X, o_totalprice#X, o_orderdate#X, l_orderkey#X, l_quantity#X]

(79) HashAggregate
Input [6]: [c_custkey#X, c_name#X, o_orderkey#X, o_totalprice#X, o_orderdate#X, l_quantity#X]
Keys [5]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X]
Functions [1]: [partial_sum(l_quantity#X)]
Aggregate Attributes [2]: [sum#X, isEmpty#X]
Results [7]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum#X, isEmpty#X]

(80) HashAggregate
Input [7]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum#X, isEmpty#X]
Keys [5]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X]
Functions [1]: [sum(l_quantity#X)]
Aggregate Attributes [1]: [sum(l_quantity#X)#X]
Results [6]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum(l_quantity#X)#X AS sum(l_quantity)#X]

(81) TakeOrderedAndProject
Input [6]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum(l_quantity)#X]
Arguments: 100, [o_totalprice#X DESC NULLS LAST, o_orderdate#X ASC NULLS FIRST], [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum(l_quantity)#X]

(82) AdaptiveSparkPlan
Output [6]: [c_name#X, c_custkey#X, o_orderkey#X, o_orderdate#X, o_totalprice#X, sum(l_quantity)#X]
Arguments: isFinalPlan=true

