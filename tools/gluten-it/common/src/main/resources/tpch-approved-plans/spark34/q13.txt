== Physical Plan ==
VeloxColumnarToRowExec (27)
+- ^ SortExecTransformer (25)
   +- ^ InputIteratorTransformer (24)
      +- ColumnarExchange (23)
         +- ^ RegularHashAggregateExecTransformer (21)
            +- ^ InputIteratorTransformer (20)
               +- ColumnarExchange (19)
                  +- ^ ProjectExecTransformer (17)
                     +- ^ FlushableHashAggregateExecTransformer (16)
                        +- ^ RegularHashAggregateExecTransformer (15)
                           +- ^ RegularHashAggregateExecTransformer (14)
                              +- ^ ProjectExecTransformer (13)
                                 +- ^ ShuffledHashJoinExecTransformer LeftOuter (12)
                                    :- ^ InputIteratorTransformer (5)
                                    :  +- ColumnarExchange (4)
                                    :     +- ^ ProjectExecTransformer (2)
                                    :        +- ^ Scan parquet spark_catalog.default.customer (1)
                                    +- ^ InputIteratorTransformer (11)
                                       +- ColumnarExchange (10)
                                          +- ^ ProjectExecTransformer (8)
                                             +- ^ FilterExecTransformer (7)
                                                +- ^ Scan parquet spark_catalog.default.orders (6)


(1) Scan parquet spark_catalog.default.customer
Output [1]: [c_custkey#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/customer]
ReadSchema: struct<c_custkey:bigint>

(2) ProjectExecTransformer
Input [1]: [c_custkey#X]
Arguments: [hash(c_custkey#X, 42) AS hash_partition_key#X, hash(c_custkey#X, 42) AS hash_partition_key#X, c_custkey#X]

(3) WholeStageCodegenTransformer (X)
Input [3]: [hash_partition_key#X, hash_partition_key#X, c_custkey#X]
Arguments: false
Native Plan:
-- Project[expressions: (n1_1:INTEGER, hash_with_seed(42,"n0_0")), (n1_2:INTEGER, hash_with_seed(42,"n0_0")), (n1_3:BIGINT, "n0_0")] -> n1_1:INTEGER, n1_2:INTEGER, n1_3:BIGINT
  -- TableScan[table: hive_table] -> n0_0:BIGINT

(4) ColumnarExchange
Input [3]: [hash_partition_key#X, hash_partition_key#X, c_custkey#X]
Arguments: hashpartitioning(c_custkey#X, 100), ENSURE_REQUIREMENTS, [hash_partition_key#X, c_custkey#X], [plan_id=X], [id=#X]

(5) InputIteratorTransformer
Input [2]: [hash_partition_key#X, c_custkey#X]

(6) Scan parquet spark_catalog.default.orders
Output [3]: [o_orderkey#X, o_custkey#X, o_comment#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-1.0/orders]
PushedFilters: [IsNotNull(o_comment), IsNotNull(o_custkey)]
ReadSchema: struct<o_orderkey:bigint,o_custkey:bigint,o_comment:string>

(7) FilterExecTransformer
Input [3]: [o_orderkey#X, o_custkey#X, o_comment#X]
Arguments: ((isnotnull(o_comment#X) AND NOT o_comment#X LIKE %special%requests%) AND isnotnull(o_custkey#X))

(8) ProjectExecTransformer
Input [3]: [o_orderkey#X, o_custkey#X, o_comment#X]
Arguments: [hash(o_custkey#X, 42) AS hash_partition_key#X, hash(o_custkey#X, 42) AS hash_partition_key#X, o_orderkey#X, o_custkey#X]

(9) WholeStageCodegenTransformer (X)
Input [4]: [hash_partition_key#X, hash_partition_key#X, o_orderkey#X, o_custkey#X]
Arguments: false
Native Plan:
-- Project[expressions: (n1_3:INTEGER, hash_with_seed(42,"n0_1")), (n1_4:INTEGER, hash_with_seed(42,"n0_1")), (n1_5:BIGINT, "n0_0"), (n1_6:BIGINT, "n0_1")] -> n1_3:INTEGER, n1_4:INTEGER, n1_5:BIGINT, n1_6:BIGINT
  -- TableScan[table: hive_table, range filters: [(o_comment, Filter(IsNotNull, deterministic, null not allowed)), (o_custkey, Filter(IsNotNull, deterministic, null not allowed))], remaining filter: (not(like("o_comment","%special%requests%","\\")))] -> n0_0:BIGINT, n0_1:BIGINT, n0_2:VARCHAR

(10) ColumnarExchange
Input [4]: [hash_partition_key#X, hash_partition_key#X, o_orderkey#X, o_custkey#X]
Arguments: hashpartitioning(o_custkey#X, 100), ENSURE_REQUIREMENTS, [hash_partition_key#X, o_orderkey#X, o_custkey#X], [plan_id=X], [id=#X]

(11) InputIteratorTransformer
Input [3]: [hash_partition_key#X, o_orderkey#X, o_custkey#X]

(12) ShuffledHashJoinExecTransformer
Left keys [1]: [c_custkey#X]
Right keys [1]: [o_custkey#X]
Join type: LeftOuter
Join condition: None

(13) ProjectExecTransformer
Input [5]: [hash_partition_key#X, c_custkey#X, hash_partition_key#X, o_orderkey#X, o_custkey#X]
Arguments: [c_custkey#X, o_orderkey#X]

(14) RegularHashAggregateExecTransformer
Input [2]: [c_custkey#X, o_orderkey#X]
Keys [1]: [c_custkey#X]
Functions [1]: [partial_count(o_orderkey#X)]
Aggregate Attributes [1]: [count#X]
Results [2]: [c_custkey#X, count#X]

(15) RegularHashAggregateExecTransformer
Input [2]: [c_custkey#X, count#X]
Keys [1]: [c_custkey#X]
Functions [1]: [count(o_orderkey#X)]
Aggregate Attributes [1]: [count(o_orderkey#X)#X]
Results [1]: [count(o_orderkey#X)#X AS c_count#X]

(16) FlushableHashAggregateExecTransformer
Input [1]: [c_count#X]
Keys [1]: [c_count#X]
Functions [1]: [partial_count(1)]
Aggregate Attributes [1]: [count#X]
Results [2]: [c_count#X, count#X]

(17) ProjectExecTransformer
Input [2]: [c_count#X, count#X]
Arguments: [hash(c_count#X, 42) AS hash_partition_key#X, c_count#X, count#X]

(18) WholeStageCodegenTransformer (X)
Input [3]: [hash_partition_key#X, c_count#X, count#X]
Arguments: false
Native Plan:
-- Project[expressions: (n9_2:INTEGER, hash_with_seed(42,"n7_2")), (n9_3:BIGINT, "n7_2"), (n9_4:BIGINT, "n8_1")] -> n9_2:INTEGER, n9_3:BIGINT, n9_4:BIGINT
  -- Aggregation[PARTIAL [n7_2] n8_1 := count_partial(1)] -> n7_2:BIGINT, n8_1:BIGINT
    -- Project[expressions: (n7_2:BIGINT, "n6_1")] -> n7_2:BIGINT
      -- Aggregation[SINGLE [n4_5] n6_1 := count_merge_extract("n5_1")] -> n4_5:BIGINT, n6_1:BIGINT
        -- Aggregation[SINGLE [n4_5] n5_1 := count_partial("n4_6")] -> n4_5:BIGINT, n5_1:BIGINT
          -- Project[expressions: (n4_5:BIGINT, "n3_6"), (n4_6:BIGINT, "n3_8")] -> n4_5:BIGINT, n4_6:BIGINT
            -- Project[expressions: (n3_5:INTEGER, "n0_0"), (n3_6:BIGINT, "n0_1"), (n3_7:INTEGER, "n1_0"), (n3_8:BIGINT, "n1_1"), (n3_9:BIGINT, "n1_2")] -> n3_5:INTEGER, n3_6:BIGINT, n3_7:INTEGER, n3_8:BIGINT, n3_9:BIGINT
              -- HashJoin[LEFT n0_1=n1_2] -> n0_0:INTEGER, n0_1:BIGINT, n1_0:INTEGER, n1_1:BIGINT, n1_2:BIGINT
                -- ValueStream[] -> n0_0:INTEGER, n0_1:BIGINT
                -- ValueStream[] -> n1_0:INTEGER, n1_1:BIGINT, n1_2:BIGINT

(19) ColumnarExchange
Input [3]: [hash_partition_key#X, c_count#X, count#X]
Arguments: hashpartitioning(c_count#X, 100), ENSURE_REQUIREMENTS, [c_count#X, count#X], [plan_id=X], [id=#X]

(20) InputIteratorTransformer
Input [2]: [c_count#X, count#X]

(21) RegularHashAggregateExecTransformer
Input [2]: [c_count#X, count#X]
Keys [1]: [c_count#X]
Functions [1]: [count(1)]
Aggregate Attributes [1]: [count(1)#X]
Results [2]: [c_count#X, count(1)#X AS custdist#X]

(22) WholeStageCodegenTransformer (X)
Input [2]: [c_count#X, custdist#X]
Arguments: false
Native Plan:
-- Project[expressions: (n2_2:BIGINT, "n0_0"), (n2_3:BIGINT, "n1_1")] -> n2_2:BIGINT, n2_3:BIGINT
  -- Aggregation[SINGLE [n0_0] n1_1 := count_merge_extract("n0_1")] -> n0_0:BIGINT, n1_1:BIGINT
    -- ValueStream[] -> n0_0:BIGINT, n0_1:BIGINT

(23) ColumnarExchange
Input [2]: [c_count#X, custdist#X]
Arguments: rangepartitioning(custdist#X DESC NULLS LAST, c_count#X DESC NULLS LAST, 100), ENSURE_REQUIREMENTS, [plan_id=X], [id=#X]

(24) InputIteratorTransformer
Input [2]: [c_count#X, custdist#X]

(25) SortExecTransformer
Input [2]: [c_count#X, custdist#X]
Arguments: [custdist#X DESC NULLS LAST, c_count#X DESC NULLS LAST], true, 0

(26) WholeStageCodegenTransformer (X)
Input [2]: [c_count#X, custdist#X]
Arguments: false
Native Plan:
-- OrderBy[n0_1 DESC NULLS LAST, n0_0 DESC NULLS LAST] -> n0_0:BIGINT, n0_1:BIGINT
  -- ValueStream[] -> n0_0:BIGINT, n0_1:BIGINT

(27) VeloxColumnarToRowExec
Input [2]: [c_count#X, custdist#X]