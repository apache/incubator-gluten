== Physical Plan ==
AdaptiveSparkPlan (18)
+- == Final Plan ==
   VeloxColumnarToRowExec (11)
   +- ^ RegularHashAggregateExecTransformer (9)
      +- ^ InputIteratorTransformer (8)
         +- ShuffleQueryStage (7), Statistics(X)
            +- ColumnarExchange (6)
               +- ^ FlushableHashAggregateExecTransformer (4)
                  +- ^ ProjectExecTransformer (3)
                     +- ^ FilterExecTransformer (2)
                        +- ^ Scan parquet spark_catalog.default.lineitem (1)
+- == Initial Plan ==
   HashAggregate (17)
   +- Exchange (16)
      +- HashAggregate (15)
         +- Project (14)
            +- Filter (13)
               +- Scan parquet spark_catalog.default.lineitem (12)


(1) Scan parquet spark_catalog.default.lineitem
Output [4]: [l_quantity#X, l_extendedprice#X, l_discount#X, l_shipdate#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-0.1/lineitem]
PushedFilters: [IsNotNull(l_shipdate), IsNotNull(l_discount), IsNotNull(l_quantity), GreaterThanOrEqual(l_shipdate,1994-01-01), LessThan(l_shipdate,1995-01-01), GreaterThanOrEqual(l_discount,0.05), LessThanOrEqual(l_discount,0.07), LessThan(l_quantity,24.00)]
ReadSchema: struct<l_quantity:decimal(12,2),l_extendedprice:decimal(12,2),l_discount:decimal(12,2),l_shipdate:date>

(2) FilterExecTransformer
Input [4]: [l_quantity#X, l_extendedprice#X, l_discount#X, l_shipdate#X]
Arguments: (((((((isnotnull(l_shipdate#X) AND isnotnull(l_discount#X)) AND isnotnull(l_quantity#X)) AND (l_shipdate#X >= 1994-01-01)) AND (l_shipdate#X < 1995-01-01)) AND (l_discount#X >= 0.05)) AND (l_discount#X <= 0.07)) AND (l_quantity#X < 24.00))

(3) ProjectExecTransformer
Input [4]: [l_quantity#X, l_extendedprice#X, l_discount#X, l_shipdate#X]
Arguments: [l_extendedprice#X, l_discount#X]

(4) FlushableHashAggregateExecTransformer
Input [2]: [l_extendedprice#X, l_discount#X]
Keys: []
Functions [1]: [partial_sum((l_extendedprice#X * l_discount#X))]
Aggregate Attributes [2]: [sum#X, isEmpty#X]
Results [2]: [sum#X, isEmpty#X]

(5) WholeStageCodegenTransformer (X)
Input [2]: [sum#X, isEmpty#X]
Arguments: false
Native Plan:
-- Project[expressions: (n4_1:DECIMAL(35, 4), "n3_0"["col_0"]), (n4_2:BOOLEAN, "n3_0"["col_1"])] -> n4_1:DECIMAL(35, 4), n4_2:BOOLEAN
  -- Aggregation[PARTIAL n3_0 := sum_partial("n2_2")] -> n3_0:ROW<col_0:DECIMAL(35, 4),col_1:BOOLEAN>
    -- Project[expressions: (n2_2:DECIMAL(25, 4), multiply("n1_4","n1_5"))] -> n2_2:DECIMAL(25, 4)
      -- Project[expressions: (n1_4:DECIMAL(12, 2), "n0_1"), (n1_5:DECIMAL(12, 2), "n0_2")] -> n1_4:DECIMAL(12, 2), n1_5:DECIMAL(12, 2)
        -- TableScan[table: hive_table, range filters: [(l_discount, BigintRange: [5, 7] no nulls), (l_quantity, BigintRange: [-999999999999999999, 2399] no nulls), (l_shipdate, BigintRange: [8766, 9130] no nulls)]] -> n0_0:DECIMAL(12, 2), n0_1:DECIMAL(12, 2), n0_2:DECIMAL(12, 2), n0_3:DATE

(6) ColumnarExchange
Input [2]: [sum#X, isEmpty#X]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=X], [id=#X]

(7) ShuffleQueryStage
Output [2]: [sum#X, isEmpty#X]
Arguments: 0

(8) InputIteratorTransformer
Input [2]: [sum#X, isEmpty#X]

(9) RegularHashAggregateExecTransformer
Input [2]: [sum#X, isEmpty#X]
Keys: []
Functions [1]: [sum((l_extendedprice#X * l_discount#X))]
Aggregate Attributes [1]: [sum((l_extendedprice#X * l_discount#X))#X]
Results [1]: [sum((l_extendedprice#X * l_discount#X))#X AS revenue#X]

(10) WholeStageCodegenTransformer (X)
Input [1]: [revenue#X]
Arguments: false
Native Plan:
-- Project[expressions: (n3_1:DECIMAL(35, 4), "n2_0")] -> n3_1:DECIMAL(35, 4)
  -- Aggregation[SINGLE n2_0 := sum_merge_extract("n1_2")] -> n2_0:DECIMAL(35, 4)
    -- Project[expressions: (n1_2:ROW<col_0:DECIMAL(35, 4),col_1:BOOLEAN>, row_constructor("n0_0","n0_1"))] -> n1_2:ROW<col_0:DECIMAL(35, 4),col_1:BOOLEAN>
      -- ValueStream[] -> n0_0:DECIMAL(35, 4), n0_1:BOOLEAN

(11) VeloxColumnarToRowExec
Input [1]: [revenue#X]

(12) Scan parquet spark_catalog.default.lineitem
Output [4]: [l_quantity#X, l_extendedprice#X, l_discount#X, l_shipdate#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-0.1/lineitem]
PushedFilters: [IsNotNull(l_shipdate), IsNotNull(l_discount), IsNotNull(l_quantity), GreaterThanOrEqual(l_shipdate,1994-01-01), LessThan(l_shipdate,1995-01-01), GreaterThanOrEqual(l_discount,0.05), LessThanOrEqual(l_discount,0.07), LessThan(l_quantity,24.00)]
ReadSchema: struct<l_quantity:decimal(12,2),l_extendedprice:decimal(12,2),l_discount:decimal(12,2),l_shipdate:date>

(13) Filter
Input [4]: [l_quantity#X, l_extendedprice#X, l_discount#X, l_shipdate#X]
Condition : (((((((isnotnull(l_shipdate#X) AND isnotnull(l_discount#X)) AND isnotnull(l_quantity#X)) AND (l_shipdate#X >= 1994-01-01)) AND (l_shipdate#X < 1995-01-01)) AND (l_discount#X >= 0.05)) AND (l_discount#X <= 0.07)) AND (l_quantity#X < 24.00))

(14) Project
Output [2]: [l_extendedprice#X, l_discount#X]
Input [4]: [l_quantity#X, l_extendedprice#X, l_discount#X, l_shipdate#X]

(15) HashAggregate
Input [2]: [l_extendedprice#X, l_discount#X]
Keys: []
Functions [1]: [partial_sum((l_extendedprice#X * l_discount#X))]
Aggregate Attributes [2]: [sum#X, isEmpty#X]
Results [2]: [sum#X, isEmpty#X]

(16) Exchange
Input [2]: [sum#X, isEmpty#X]
Arguments: SinglePartition, ENSURE_REQUIREMENTS, [plan_id=X]

(17) HashAggregate
Input [2]: [sum#X, isEmpty#X]
Keys: []
Functions [1]: [sum((l_extendedprice#X * l_discount#X))]
Aggregate Attributes [1]: [sum((l_extendedprice#X * l_discount#X))#X]
Results [1]: [sum((l_extendedprice#X * l_discount#X))#X AS revenue#X]

(18) AdaptiveSparkPlan
Output [1]: [revenue#X]
Arguments: isFinalPlan=true
