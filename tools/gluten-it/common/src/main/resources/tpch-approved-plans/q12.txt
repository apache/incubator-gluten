== Physical Plan ==
AdaptiveSparkPlan (41)
+- == Final Plan ==
   VeloxColumnarToRowExec (27)
   +- ^ SortExecTransformer (25)
      +- ^ InputIteratorTransformer (24)
         +- AQEShuffleRead (23)
            +- ShuffleQueryStage (22), Statistics(X)
               +- ColumnarExchange (21)
                  +- ^ RegularHashAggregateExecTransformer (19)
                     +- ^ InputIteratorTransformer (18)
                        +- AQEShuffleRead (17)
                           +- ShuffleQueryStage (16), Statistics(X)
                              +- ColumnarExchange (15)
                                 +- ^ ProjectExecTransformer (13)
                                    +- ^ FlushableHashAggregateExecTransformer (12)
                                       +- ^ ProjectExecTransformer (11)
                                          +- ^ GlutenBroadcastHashJoinExecTransformer Inner (10)
                                             :- ^ InputIteratorTransformer (6)
                                             :  +- BroadcastQueryStage (5), Statistics(X)
                                             :     +- ColumnarBroadcastExchange (4)
                                             :        +- ^ FilterExecTransformer (2)
                                             :           +- ^ Scan parquet spark_catalog.default.orders (1)
                                             +- ^ ProjectExecTransformer (9)
                                                +- ^ FilterExecTransformer (8)
                                                   +- ^ Scan parquet spark_catalog.default.lineitem (7)
+- == Initial Plan ==
   Sort (40)
   +- Exchange (39)
      +- HashAggregate (38)
         +- Exchange (37)
            +- HashAggregate (36)
               +- Project (35)
                  +- BroadcastHashJoin Inner BuildLeft (34)
                     :- BroadcastExchange (30)
                     :  +- Filter (29)
                     :     +- Scan parquet spark_catalog.default.orders (28)
                     +- Project (33)
                        +- Filter (32)
                           +- Scan parquet spark_catalog.default.lineitem (31)


(1) Scan parquet spark_catalog.default.orders
Output [2]: [o_orderkey#X, o_orderpriority#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-0.1/orders]
PushedFilters: [IsNotNull(o_orderkey)]
ReadSchema: struct<o_orderkey:bigint,o_orderpriority:string>

(2) FilterExecTransformer
Input [2]: [o_orderkey#X, o_orderpriority#X]
Arguments: isnotnull(o_orderkey#X)

(3) WholeStageCodegenTransformer (X)
Input [2]: [o_orderkey#X, o_orderpriority#X]
Arguments: false
Native Plan:
-- TableScan[table: hive_table, range filters: [(o_orderkey, Filter(IsNotNull, deterministic, null not allowed))]] -> n0_0:BIGINT, n0_1:VARCHAR

(4) ColumnarBroadcastExchange
Input [2]: [o_orderkey#X, o_orderpriority#X]
Arguments: HashedRelationBroadcastMode(List(input[0, bigint, false]),false), [plan_id=X]

(5) BroadcastQueryStage
Output [2]: [o_orderkey#X, o_orderpriority#X]
Arguments: 0

(6) InputIteratorTransformer
Input [2]: [o_orderkey#X, o_orderpriority#X]

(7) Scan parquet spark_catalog.default.lineitem
Output [5]: [l_orderkey#X, l_commitdate#X, l_receiptdate#X, l_shipmode#X, l_shipdate#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-0.1/lineitem]
PushedFilters: [IsNotNull(l_commitdate), IsNotNull(l_receiptdate), IsNotNull(l_shipdate), In(l_shipmode, [MAIL,SHIP]), GreaterThanOrEqual(l_receiptdate,1994-01-01), LessThan(l_receiptdate,1995-01-01), IsNotNull(l_orderkey)]
ReadSchema: struct<l_orderkey:bigint,l_commitdate:date,l_receiptdate:date,l_shipmode:string,l_shipdate:date>

(8) FilterExecTransformer
Input [5]: [l_orderkey#X, l_commitdate#X, l_receiptdate#X, l_shipmode#X, l_shipdate#X]
Arguments: ((((((((isnotnull(l_commitdate#X) AND isnotnull(l_receiptdate#X)) AND isnotnull(l_shipdate#X)) AND l_shipmode#X IN (MAIL,SHIP)) AND (l_commitdate#X < l_receiptdate#X)) AND (l_shipdate#X < l_commitdate#X)) AND (l_receiptdate#X >= 1994-01-01)) AND (l_receiptdate#X < 1995-01-01)) AND isnotnull(l_orderkey#X))

(9) ProjectExecTransformer
Input [5]: [l_orderkey#X, l_commitdate#X, l_receiptdate#X, l_shipmode#X, l_shipdate#X]
Arguments: [l_orderkey#X, l_shipmode#X]

(10) GlutenBroadcastHashJoinExecTransformer
Left keys [1]: [o_orderkey#X]
Right keys [1]: [l_orderkey#X]
Join type: Inner
Join condition: None

(11) ProjectExecTransformer
Input [4]: [o_orderkey#X, o_orderpriority#X, l_orderkey#X, l_shipmode#X]
Arguments: [o_orderpriority#X, l_shipmode#X]

(12) FlushableHashAggregateExecTransformer
Input [2]: [o_orderpriority#X, l_shipmode#X]
Keys [1]: [l_shipmode#X]
Functions [2]: [partial_sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END), partial_sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)]
Aggregate Attributes [2]: [sum#X, sum#X]
Results [3]: [l_shipmode#X, sum#X, sum#X]

(13) ProjectExecTransformer
Input [3]: [l_shipmode#X, sum#X, sum#X]
Arguments: [hash(l_shipmode#X, 42) AS hash_partition_key#X, l_shipmode#X, sum#X, sum#X]

(14) WholeStageCodegenTransformer (X)
Input [4]: [hash_partition_key#X, l_shipmode#X, sum#X, sum#X]
Arguments: false
Native Plan:
-- Project[expressions: (n8_3:INTEGER, hash_with_seed(42,"n6_2")), (n8_4:VARCHAR, "n6_2"), (n8_5:BIGINT, "n7_1"), (n8_6:BIGINT, "n7_2")] -> n8_3:INTEGER, n8_4:VARCHAR, n8_5:BIGINT, n8_6:BIGINT
  -- Aggregation[PARTIAL [n6_2] n7_1 := sum_partial("n6_3"), n7_2 := sum_partial("n6_4")] -> n6_2:VARCHAR, n7_1:BIGINT, n7_2:BIGINT
    -- Project[expressions: (n6_2:VARCHAR, "n5_5"), (n6_3:INTEGER, if(or(equalto("n5_4","1-URGENT"),equalto("n5_4","2-HIGH")),1,0)), (n6_4:INTEGER, if(and(not(equalto("n5_4","1-URGENT")),not(equalto("n5_4","2-HIGH"))),1,0))] -> n6_2:VARCHAR, n6_3:INTEGER, n6_4:INTEGER
      -- Project[expressions: (n5_4:VARCHAR, "n4_5"), (n5_5:VARCHAR, "n4_7")] -> n5_4:VARCHAR, n5_5:VARCHAR
        -- Project[expressions: (n4_4:BIGINT, "n0_0"), (n4_5:VARCHAR, "n0_1"), (n4_6:BIGINT, "n2_5"), (n4_7:VARCHAR, "n2_6")] -> n4_4:BIGINT, n4_5:VARCHAR, n4_6:BIGINT, n4_7:VARCHAR
          -- HashJoin[INNER n2_5=n0_0] -> n2_5:BIGINT, n2_6:VARCHAR, n0_0:BIGINT, n0_1:VARCHAR
            -- Project[expressions: (n2_5:BIGINT, "n1_0"), (n2_6:VARCHAR, "n1_3")] -> n2_5:BIGINT, n2_6:VARCHAR
              -- TableScan[table: hive_table, range filters: [(l_commitdate, Filter(IsNotNull, deterministic, null not allowed)), (l_orderkey, Filter(IsNotNull, deterministic, null not allowed)), (l_receiptdate, BigintRange: [8766, 9130] no nulls), (l_shipdate, Filter(IsNotNull, deterministic, null not allowed)), (l_shipmode, Filter(BytesValues, deterministic, null not allowed))], remaining filter: (and(lessthan("l_commitdate","l_receiptdate"),lessthan("l_shipdate","l_commitdate")))] -> n1_0:BIGINT, n1_1:DATE, n1_2:DATE, n1_3:VARCHAR, n1_4:DATE
            -- ValueStream[] -> n0_0:BIGINT, n0_1:VARCHAR

(15) ColumnarExchange
Input [4]: [hash_partition_key#X, l_shipmode#X, sum#X, sum#X]
Arguments: hashpartitioning(l_shipmode#X, 100), ENSURE_REQUIREMENTS, [l_shipmode#X, sum#X, sum#X], [plan_id=X], [id=#X]

(16) ShuffleQueryStage
Output [3]: [l_shipmode#X, sum#X, sum#X]
Arguments: 1

(17) AQEShuffleRead
Input [3]: [l_shipmode#X, sum#X, sum#X]
Arguments: coalesced

(18) InputIteratorTransformer
Input [3]: [l_shipmode#X, sum#X, sum#X]

(19) RegularHashAggregateExecTransformer
Input [3]: [l_shipmode#X, sum#X, sum#X]
Keys [1]: [l_shipmode#X]
Functions [2]: [sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END), sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)]
Aggregate Attributes [2]: [sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X, sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X]
Results [3]: [l_shipmode#X, sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X AS high_line_count#X, sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X AS low_line_count#X]

(20) WholeStageCodegenTransformer (X)
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: false
Native Plan:
-- Project[expressions: (n2_3:VARCHAR, "n0_0"), (n2_4:BIGINT, "n1_1"), (n2_5:BIGINT, "n1_2")] -> n2_3:VARCHAR, n2_4:BIGINT, n2_5:BIGINT
  -- Aggregation[SINGLE [n0_0] n1_1 := sum_merge_extract("n0_1"), n1_2 := sum_merge_extract("n0_2")] -> n0_0:VARCHAR, n1_1:BIGINT, n1_2:BIGINT
    -- ValueStream[] -> n0_0:VARCHAR, n0_1:BIGINT, n0_2:BIGINT

(21) ColumnarExchange
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: rangepartitioning(l_shipmode#X ASC NULLS FIRST, 100), ENSURE_REQUIREMENTS, [plan_id=X], [id=#X]

(22) ShuffleQueryStage
Output [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: 2

(23) AQEShuffleRead
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: coalesced

(24) InputIteratorTransformer
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]

(25) SortExecTransformer
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: [l_shipmode#X ASC NULLS FIRST], true, 0

(26) WholeStageCodegenTransformer (X)
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: false
Native Plan:
-- OrderBy[n0_0 ASC NULLS FIRST] -> n0_0:VARCHAR, n0_1:BIGINT, n0_2:BIGINT
  -- ValueStream[] -> n0_0:VARCHAR, n0_1:BIGINT, n0_2:BIGINT

(27) VeloxColumnarToRowExec
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]

(28) Scan parquet spark_catalog.default.orders
Output [2]: [o_orderkey#X, o_orderpriority#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-0.1/orders]
PushedFilters: [IsNotNull(o_orderkey)]
ReadSchema: struct<o_orderkey:bigint,o_orderpriority:string>

(29) Filter
Input [2]: [o_orderkey#X, o_orderpriority#X]
Condition : isnotnull(o_orderkey#X)

(30) BroadcastExchange
Input [2]: [o_orderkey#X, o_orderpriority#X]
Arguments: HashedRelationBroadcastMode(List(input[0, bigint, false]),false), [plan_id=X]

(31) Scan parquet spark_catalog.default.lineitem
Output [5]: [l_orderkey#X, l_commitdate#X, l_receiptdate#X, l_shipmode#X, l_shipdate#X]
Batched: true
Location: InMemoryFileIndex [file:/tmp/tpch-generated-0.1/lineitem]
PushedFilters: [IsNotNull(l_commitdate), IsNotNull(l_receiptdate), IsNotNull(l_shipdate), In(l_shipmode, [MAIL,SHIP]), GreaterThanOrEqual(l_receiptdate,1994-01-01), LessThan(l_receiptdate,1995-01-01), IsNotNull(l_orderkey)]
ReadSchema: struct<l_orderkey:bigint,l_commitdate:date,l_receiptdate:date,l_shipmode:string,l_shipdate:date>

(32) Filter
Input [5]: [l_orderkey#X, l_commitdate#X, l_receiptdate#X, l_shipmode#X, l_shipdate#X]
Condition : ((((((((isnotnull(l_commitdate#X) AND isnotnull(l_receiptdate#X)) AND isnotnull(l_shipdate#X)) AND l_shipmode#X IN (MAIL,SHIP)) AND (l_commitdate#X < l_receiptdate#X)) AND (l_shipdate#X < l_commitdate#X)) AND (l_receiptdate#X >= 1994-01-01)) AND (l_receiptdate#X < 1995-01-01)) AND isnotnull(l_orderkey#X))

(33) Project
Output [2]: [l_orderkey#X, l_shipmode#X]
Input [5]: [l_orderkey#X, l_commitdate#X, l_receiptdate#X, l_shipmode#X, l_shipdate#X]

(34) BroadcastHashJoin
Left keys [1]: [o_orderkey#X]
Right keys [1]: [l_orderkey#X]
Join type: Inner
Join condition: None

(35) Project
Output [2]: [o_orderpriority#X, l_shipmode#X]
Input [4]: [o_orderkey#X, o_orderpriority#X, l_orderkey#X, l_shipmode#X]

(36) HashAggregate
Input [2]: [o_orderpriority#X, l_shipmode#X]
Keys [1]: [l_shipmode#X]
Functions [2]: [partial_sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END), partial_sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)]
Aggregate Attributes [2]: [sum#X, sum#X]
Results [3]: [l_shipmode#X, sum#X, sum#X]

(37) Exchange
Input [3]: [l_shipmode#X, sum#X, sum#X]
Arguments: hashpartitioning(l_shipmode#X, 100), ENSURE_REQUIREMENTS, [plan_id=X]

(38) HashAggregate
Input [3]: [l_shipmode#X, sum#X, sum#X]
Keys [1]: [l_shipmode#X]
Functions [2]: [sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END), sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)]
Aggregate Attributes [2]: [sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X, sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X]
Results [3]: [l_shipmode#X, sum(CASE WHEN ((o_orderpriority#X = 1-URGENT) OR (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X AS high_line_count#X, sum(CASE WHEN (NOT (o_orderpriority#X = 1-URGENT) AND NOT (o_orderpriority#X = 2-HIGH)) THEN 1 ELSE 0 END)#X AS low_line_count#X]

(39) Exchange
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: rangepartitioning(l_shipmode#X ASC NULLS FIRST, 100), ENSURE_REQUIREMENTS, [plan_id=X]

(40) Sort
Input [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: [l_shipmode#X ASC NULLS FIRST], true, 0

(41) AdaptiveSparkPlan
Output [3]: [l_shipmode#X, high_line_count#X, low_line_count#X]
Arguments: isFinalPlan=true
