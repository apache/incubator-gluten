-- Automatically generated by GlutenSqlLogicTestSuite
-- Number of queries: 1008


-- !query
DROP DATABASE IF EXISTS mydb1 CASCADE
-- !query schema
struct<>
-- !query output



-- !query
CREATE DATABASE mydb1
-- !query schema
struct<>
-- !query output



-- !query
USE mydb1
-- !query schema
struct<>
-- !query output



-- !query
DROP TABLE IF EXISTS t1
-- !query schema
struct<>
-- !query output



-- !query
DROP TABLE IF EXISTS t2
-- !query schema
struct<>
-- !query output



-- !query
CREATE TABLE t1(a int, b int, c int, d int, e int) USING PARQUET
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO t1 VALUES(103,102,100,101,104)
-- !query schema
struct<>
-- !query output



-- !query
INSERT INTO t1 VALUES(107,106,108,109,105)
-- !query schema
struct<>
-- !query output



-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
214
1020


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
1531	102.0
1604	107.0


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(b-c),
       (a+b+c+d+e)/5,
       a+b*2+c*3
  FROM t1
 WHERE (e>c OR e<d)
   AND d>e
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 4,2,1,3,5
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,abs((b - c)):int,(((((a + b) + c) + d) + e) / 5):double,((a + (b * 2)) + (c * 3)):int>
-- !query output
1604	333	2	107.0	643


-- !query
SELECT c,
       d-e,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4,
       e
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
    OR c BETWEEN b-2 AND d+2
    OR (e>c OR e<d)
 ORDER BY 1,5,3,2,4
-- !query schema
struct<c:int,(d - e):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,e:int>
-- !query output
100	-3	444	1011	104
108	4	222	1079	105


-- !query
SELECT a+b*2+c*3+d*4,
       (a+b+c+d+e)/5,
       abs(a),
       e,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d
  FROM t1
 WHERE b>c
   AND c>d
 ORDER BY 3,4,5,1,2,6
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(((((a + b) + c) + d) + e) / 5):double,abs(a):int,e:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,d:int>
-- !query output



-- !query
SELECT a+b*2+c*3+d*4,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 4,2,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 ORDER BY 1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
222
444


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR c>d
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       b-c,
       a-b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR a>b
    OR b>c
 ORDER BY 1,4,3,2,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4,
       a+b*2+c*3,
       c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(b-c)
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR b>c
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 4,1,5,2,6,3,7
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((a + (b * 2)) + (c * 3)):int,c:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,abs((b - c)):int>
-- !query output
444	333	1011	607	100	1020	2
222	333	1079	643	108	214	2


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c,
       b-c
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR a>b
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 5,3,6,1,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d,
       a+b*2+c*3+d*4,
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR c>d
 ORDER BY 3,5,4,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a-b,
       abs(b-c),
       c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4
  FROM t1
 ORDER BY 4,3,6,2,5,1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(a - b):int,abs((b - c)):int,c:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1020	1	2	100	333	1011
214	1	2	108	333	1079


-- !query
SELECT a+b*2,
       a,
       a+b*2+c*3+d*4+e*5,
       (a+b+c+d+e)/5,
       e,
       c-d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE a>b
 ORDER BY 5,4,6,2,1,7,3
-- !query schema
struct<(a + (b * 2)):int,a:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(((((a + b) + c) + d) + e) / 5):double,e:int,(c - d):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
307	103	1531	102.0	104	-1	333
319	107	1604	107.0	105	-1	333


-- !query
SELECT a,
       b
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<a:int,b:int>
-- !query output
103	102
107	106


-- !query
SELECT c,
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4+e*5,
       abs(b-c),
       b-c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a-b
  FROM t1
 WHERE b>c
   AND a>b
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 2,1,6,4,3,5
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,abs((b - c)):int,(b - c):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(a - b):int>
-- !query output
1020	1531	2	2	444	1


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       abs(a),
       b-c,
       c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1,5,4,2,6,3
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,abs(a):int,(b - c):int,(c - d):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,a:int>
-- !query output
1531	103	2	-1	444	103
1604	107	-2	-1	222	107


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b-c,
       b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2
  FROM t1
 ORDER BY 4,3,5,1,6,2,7
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       a+b*2+c*3+d*4+e*5,
       c-d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b-c,
       a+b*2
  FROM t1
 ORDER BY 6,2,4,5,3,1
-- !query schema
struct<a:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(c - d):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(b - c):int,(a + (b * 2)):int>
-- !query output
103	1531	-1	1020	2	307
107	1604	-1	214	-2	319


-- !query
SELECT d-e,
       abs(a),
       b,
       c-d,
       a+b*2+c*3,
       abs(b-c),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE (e>c OR e<d)
   AND d>e
   AND c>d
 ORDER BY 1,3,7,5,2,6,4
-- !query schema
struct<(d - e):int,abs(a):int,b:int,(c - d):int,((a + (b * 2)) + (c * 3)):int,abs((b - c)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output



-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3,
       a+b*2+c*3+d*4+e*5,
       (a+b+c+d+e)/5,
       a+b*2+c*3+d*4,
       b-c,
       c
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 2,5,1,7,3,6,4
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,((a + (b * 2)) + (c * 3)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(((((a + b) + c) + d) + e) / 5):double,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(b - c):int,c:int>
-- !query output
333	607	1531	102.0	1011	2	100
333	643	1604	107.0	1079	-2	108


-- !query
SELECT e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a-b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c-d,
       c
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1,4,5,6,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND c>d
 ORDER BY 1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output



-- !query
SELECT a+b*2+c*3,
       abs(b-c),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a,
       a+b*2+c*3+d*4,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 6,1,7,3,4,5,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2,
       a+b*2+c*3,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE d>e
   AND (c<=d-2 OR c>=d+2)
   AND b>c
 ORDER BY 2,3,1,5,4
-- !query schema
struct<(a + (b * 2)):int,((a + (b * 2)) + (c * 3)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,c:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output



-- !query
SELECT a+b*2+c*3+d*4+e*5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a,
       abs(b-c),
       a+b*2,
       d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (e>c OR e<d)
    OR a>b
 ORDER BY 4,5,3,7,1,6,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,a:int,abs((b - c)):int,(a + (b * 2)):int,d:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
1531	333	103	2	307	101	1020
1604	333	107	2	319	109	214


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c-d,
       a-b
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 3,5,4,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND a>b
   AND (a>b-2 AND a<b+2)
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE a>b
    OR c BETWEEN b-2 AND d+2
    OR c>d
 ORDER BY 3,2,1,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       a+b*2+c*3+d*4+e*5,
       a+b*2+c*3,
       c-d,
       (a+b+c+d+e)/5,
       a-b
  FROM t1
 ORDER BY 3,4,2,6,5,1
-- !query schema
struct<d:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,((a + (b * 2)) + (c * 3)):int,(c - d):int,(((((a + b) + c) + d) + e) / 5):double,(a - b):int>
-- !query output
101	1531	607	-1	102.0	1
109	1604	643	-1	107.0	1


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4+e*5,
       (a+b+c+d+e)/5,
       abs(b-c),
       abs(a),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 7,2,5,1,3,6,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b,
       c,
       e
  FROM t1
 WHERE b>c
 ORDER BY 1,2,4,3,5
-- !query schema
struct<d:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,b:int,c:int,e:int>
-- !query output
101	1020	102	100	104


-- !query
SELECT a-b,
       a,
       a+b*2+c*3,
       b,
       d,
       d-e
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 2,6,4,1,5,3
-- !query schema
struct<(a - b):int,a:int,((a + (b * 2)) + (c * 3)):int,b:int,d:int,(d - e):int>
-- !query output



-- !query
SELECT (a+b+c+d+e)/5,
       a+b*2,
       c-d,
       a,
       e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE b>c
 ORDER BY 2,6,5,4,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b,
       (a+b+c+d+e)/5,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(b-c),
       b-c
  FROM t1
 WHERE a>b
 ORDER BY 2,5,3,4,1
-- !query schema
struct<b:int,(((((a + b) + c) + d) + e) / 5):double,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,abs((b - c)):int,(b - c):int>
-- !query output
102	102.0	444	2	2
106	107.0	222	2	-2


-- !query
SELECT abs(b-c),
       a,
       a+b*2,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 ORDER BY 1,4,3,2
-- !query schema
struct<abs((b - c)):int,a:int,(a + (b * 2)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
2	103	307	333
2	107	319	333


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c,
       d-e
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND c>d
 ORDER BY 2,1,3
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,c:int,(d - e):int>
-- !query output



-- !query
SELECT a,
       e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a-b
  FROM t1
 ORDER BY 2,4,3,1
-- !query schema
struct<a:int,e:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(a - b):int>
-- !query output
103	104	1020	1
107	105	214	1


-- !query
SELECT (a+b+c+d+e)/5,
       e,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (e>c OR e<d)
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d-e
  FROM t1
 WHERE d>e
    OR (e>a AND e<b)
 ORDER BY 4,1,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR a>b
 ORDER BY 1
-- !query schema
struct<(a + (b * 2)):int>
-- !query output
307
319


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d-e,
       b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR (a>b-2 AND a<b+2)
 ORDER BY 2,6,3,5,4,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       c-d,
       d
  FROM t1
 WHERE c>d
   AND a>b
   AND (a>b-2 AND a<b+2)
 ORDER BY 1,2,3
-- !query schema
struct<a:int,(c - d):int,d:int>
-- !query output



-- !query
SELECT a+b*2+c*3,
       a+b*2+c*3+d*4+e*5,
       c,
       (a+b+c+d+e)/5,
       b
  FROM t1
 ORDER BY 5,4,1,3,2
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,c:int,(((((a + b) + c) + d) + e) / 5):double,b:int>
-- !query output
607	1531	100	102.0	102
643	1604	108	107.0	106


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c-d,
       abs(a),
       abs(b-c),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1,5,3,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(a),
       (a+b+c+d+e)/5,
       a+b*2,
       d-e
  FROM t1
 WHERE b>c
   AND (a>b-2 AND a<b+2)
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 4,5,3,1,2,6
-- !query schema
struct<c:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,abs(a):int,(((((a + b) + c) + d) + e) / 5):double,(a + (b * 2)):int,(d - e):int>
-- !query output
100	333	103	102.0	307	-3


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4+e*5,
       d
  FROM t1
 WHERE d>e
    OR (a>b-2 AND a<b+2)
 ORDER BY 3,2,4,1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,d:int>
-- !query output
444	1020	1531	101
222	214	1604	109


-- !query
SELECT d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(a),
       a+b*2+c*3+d*4
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR c>d
 ORDER BY 2,3,4,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3
  FROM t1
 ORDER BY 1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int>
-- !query output
607
643


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3+d*4,
       a+b*2
  FROM t1
 WHERE d>e
 ORDER BY 3,4,1,2,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a-b
  FROM t1
 WHERE b>c
 ORDER BY 1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4,
       b-c
  FROM t1
 WHERE d>e
 ORDER BY 4,1,5,3,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,a:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(b - c):int>
-- !query output
1604	107	222	1079	-2


-- !query
SELECT a-b,
       a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       a+b*2,
       a,
       b,
       b-c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 5,2,7,1,4,6,3
-- !query schema
struct<d:int,(a + (b * 2)):int,a:int,b:int,(b - c):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
109	319	107	106	-2	222	107.0
101	307	103	102	2	444	102.0


-- !query
SELECT e
  FROM t1
 WHERE b>c
   AND d>e
 ORDER BY 1
-- !query schema
struct<e:int>
-- !query output



-- !query
SELECT b,
       e
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 2,1
-- !query schema
struct<b:int,e:int>
-- !query output



-- !query
SELECT b-c,
       d-e,
       c-d,
       a+b*2+c*3
  FROM t1
 ORDER BY 1,2,4,3
-- !query schema
struct<(b - c):int,(d - e):int,(c - d):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
-2	4	-1	643
2	-3	-1	607


-- !query
SELECT abs(b-c),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE (e>c OR e<d)
    OR b>c
    OR (a>b-2 AND a<b+2)
 ORDER BY 2,1
-- !query schema
struct<abs((b - c)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
2	333
2	333


-- !query
SELECT e,
       d-e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1,3,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       a+b*2+c*3+d*4+e*5,
       c-d
  FROM t1
 ORDER BY 3,2,1
-- !query schema
struct<abs(a):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(c - d):int>
-- !query output
103	1531	-1
107	1604	-1


-- !query
SELECT abs(a),
       c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2,
       d-e
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND d>e
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 5,3,1,4,2
-- !query schema
struct<abs(a):int,c:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(a + (b * 2)):int,(d - e):int>
-- !query output
107	108	222	319	4


-- !query
SELECT (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c-d,
       a+b*2+c*3+d*4,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (e>a AND e<b)
   AND c>d
 ORDER BY 2,5,6,4,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d,
       b-c,
       (a+b+c+d+e)/5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a-b
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR (e>c OR e<d)
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 7,2,4,1,5,6,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2,
       d,
       a,
       b-c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND d NOT BETWEEN 110 AND 150
   AND e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1,2,4,5,3
-- !query schema
struct<(a + (b * 2)):int,d:int,a:int,(b - c):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
319	109	107	-2	222


-- !query
SELECT c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 3,2,4,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT e
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND (a>b-2 AND a<b+2)
 ORDER BY 1
-- !query schema
struct<e:int>
-- !query output



-- !query
SELECT abs(b-c),
       a+b*2+c*3+d*4+e*5,
       d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c-d
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 3,4,5,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND d>e
 ORDER BY 1,2
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
333	1604


-- !query
SELECT b-c
  FROM t1
 ORDER BY 1
-- !query schema
struct<(b - c):int>
-- !query output
-2
2


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(b-c),
       a+b*2+c*3+d*4,
       (a+b+c+d+e)/5,
       d-e,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1,6,2,4,5,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       c,
       b,
       a+b*2+c*3+d*4,
       b-c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR c>d
    OR (a>b-2 AND a<b+2)
 ORDER BY 3,5,6,2,4,1
-- !query schema
struct<d:int,c:int,b:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(b - c):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
101	100	102	1011	2	333
109	108	106	1079	-2	333


-- !query
SELECT b-c,
       (a+b+c+d+e)/5,
       c-d,
       b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE d>e
   AND d NOT BETWEEN 110 AND 150
   AND (e>a AND e<b)
 ORDER BY 1,3,2,5,4,6
-- !query schema
struct<(b - c):int,(((((a + b) + c) + d) + e) / 5):double,(c - d):int,b:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output



-- !query
SELECT abs(a),
       a+b*2+c*3+d*4+e*5,
       a,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 4,3,2,1
-- !query schema
struct<abs(a):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,a:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
103	1531	103	102.0
107	1604	107	107.0


-- !query
SELECT b,
       c,
       a-b,
       d-e,
       a+b*2+c*3+d*4
  FROM t1
 WHERE d>e
    OR c BETWEEN b-2 AND d+2
 ORDER BY 2,1,4,3,5
-- !query schema
struct<b:int,c:int,(a - b):int,(d - e):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
102	100	1	-3	1011
106	108	1	4	1079


-- !query
SELECT a-b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND b>c
   AND (a>b-2 AND a<b+2)
 ORDER BY 1,2
-- !query schema
struct<(a - b):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
1	333


-- !query
SELECT b,
       abs(a),
       a,
       c
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR (e>c OR e<d)
    OR b>c
 ORDER BY 4,3,2,1
-- !query schema
struct<b:int,abs(a):int,a:int,c:int>
-- !query output
102	103	103	100
106	107	107	108


-- !query
SELECT a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c-d,
       a+b*2
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND b>c
 ORDER BY 2,4,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b,
       abs(b-c)
  FROM t1
 WHERE c>d
   AND a>b
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,1
-- !query schema
struct<b:int,abs((b - c)):int>
-- !query output



-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d-e,
       b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a-b,
       a,
       e
  FROM t1
 ORDER BY 4,5,1,3,7,6,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(b-c),
       a+b*2+c*3+d*4+e*5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d-e
  FROM t1
 ORDER BY 1,6,2,3,5,4
-- !query schema
struct<d:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,abs((b - c)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(d - e):int>
-- !query output
101	1020	2	1531	333	-3
109	214	2	1604	333	4


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 2,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       abs(b-c),
       c-d
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 2,3,1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,abs((b - c)):int,(c - d):int>
-- !query output
1011	2	-1
1079	2	-1


-- !query
SELECT a-b,
       abs(a),
       d
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR d>e
    OR c BETWEEN b-2 AND d+2
 ORDER BY 3,2,1
-- !query schema
struct<(a - b):int,abs(a):int,d:int>
-- !query output
1	103	101
1	107	109


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (e>a AND e<b)
    OR (c<=d-2 OR c>=d+2)
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       abs(a),
       d
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND (e>c OR e<d)
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,1,3
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,abs(a):int,d:int>
-- !query output
107.0	107	109


-- !query
SELECT a+b*2,
       a+b*2+c*3+d*4+e*5,
       a-b,
       abs(b-c),
       c,
       b,
       e
  FROM t1
 WHERE d>e
 ORDER BY 4,5,3,6,2,1,7
-- !query schema
struct<(a + (b * 2)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(a - b):int,abs((b - c)):int,c:int,b:int,e:int>
-- !query output
319	1604	1	2	108	106	105


-- !query
SELECT a,
       d,
       a+b*2+c*3+d*4+e*5,
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR (a>b-2 AND a<b+2)
    OR b>c
 ORDER BY 1,3,5,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3,
       d-e,
       b,
       a,
       c,
       a+b*2
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR (e>a AND e<b)
    OR d>e
 ORDER BY 5,6,3,7,2,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c-d
  FROM t1
 WHERE c>d
    OR (a>b-2 AND a<b+2)
    OR b>c
 ORDER BY 1,3,5,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(a),
       c-d,
       d
  FROM t1
 WHERE b>c
    OR d NOT BETWEEN 110 AND 150
    OR (e>c OR e<d)
 ORDER BY 4,6,5,1,3,7,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       (a+b+c+d+e)/5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR (c<=d-2 OR c>=d+2)
    OR c>d
 ORDER BY 1,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3
  FROM t1
 ORDER BY 2,1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,((a + (b * 2)) + (c * 3)):int>
-- !query output
444	607
222	643


-- !query
SELECT a+b*2+c*3+d*4,
       c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3,
       a+b*2,
       d-e
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1,3,7,2,5,6,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a-b,
       d,
       a
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 6,2,4,3,1,7,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       a-b,
       b,
       a+b*2,
       a
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND (e>c OR e<d)
   AND d>e
 ORDER BY 4,2,5,3,1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,(a - b):int,b:int,(a + (b * 2)):int,a:int>
-- !query output
107.0	1	106	319	107


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d,
       e,
       c-d,
       a+b*2+c*3+d*4,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND c>d
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1,4,3,2,5,6
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,d:int,e:int,(c - d):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output



-- !query
SELECT c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a,
       abs(a),
       abs(b-c),
       a+b*2+c*3,
       e
  FROM t1
 WHERE d>e
   AND (e>a AND e<b)
 ORDER BY 7,2,6,1,3,4,5
-- !query schema
struct<(c - d):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,a:int,abs(a):int,abs((b - c)):int,((a + (b * 2)) + (c * 3)):int,e:int>
-- !query output



-- !query
SELECT c-d,
       d-e,
       abs(a),
       a,
       (a+b+c+d+e)/5
  FROM t1
 WHERE a>b
    OR c>d
 ORDER BY 1,5,3,2,4
-- !query schema
struct<(c - d):int,(d - e):int,abs(a):int,a:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
-1	-3	103	103	102.0
-1	4	107	107	107.0


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a,
       abs(a),
       a-b,
       d-e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND b>c
 ORDER BY 4,6,3,1,5,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,a:int,abs(a):int,(a - b):int,(d - e):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output



-- !query
SELECT a+b*2+c*3,
       a
  FROM t1
 WHERE (e>c OR e<d)
    OR a>b
 ORDER BY 1,2
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,a:int>
-- !query output
607	103
643	107


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c-d,
       a+b*2+c*3
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND (a>b-2 AND a<b+2)
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 1,2,3
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(c - d):int,((a + (b * 2)) + (c * 3)):int>
-- !query output



-- !query
SELECT a+b*2,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c-d,
       a+b*2+c*3
  FROM t1
 WHERE d>e
 ORDER BY 4,2,1,5,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT e
  FROM t1
 ORDER BY 1
-- !query schema
struct<e:int>
-- !query output
104
105


-- !query
SELECT c-d,
       b,
       d,
       a+b*2+c*3+d*4+e*5,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE c>d
 ORDER BY 4,3,5,6,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(b-c),
       c-d,
       a,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a-b
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR b>c
 ORDER BY 4,2,1,5,3
-- !query schema
struct<abs((b - c)):int,(c - d):int,a:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(a - b):int>
-- !query output
2	-1	103	333	1
2	-1	107	333	1


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b-c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3
  FROM t1
 WHERE c>d
   AND b>c
   AND e+d BETWEEN a+b-10 AND c+130
 ORDER BY 3,4,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5
  FROM t1
 ORDER BY 1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double>
-- !query output
102.0
107.0


-- !query
SELECT a+b*2,
       (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(b-c),
       a-b
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND c>d
 ORDER BY 6,5,4,1,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d,
       e
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 3,1,2,4
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,d:int,e:int>
-- !query output
1011	333	101	104
1079	333	109	105


-- !query
SELECT a+b*2+c*3,
       a+b*2,
       a-b,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE a>b
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR d>e
 ORDER BY 2,1,3,4
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,(a + (b * 2)):int,(a - b):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
607	307	1	1531
643	319	1	1604


-- !query
SELECT (a+b+c+d+e)/5,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (e>c OR e<d)
    OR b>c
 ORDER BY 2,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       d,
       e,
       a+b*2+c*3+d*4,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b-c,
       a
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 3,2,7,6,4,1,5
-- !query schema
struct<abs(a):int,d:int,e:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(b - c):int,a:int>
-- !query output
103	101	104	1011	444	2	103
107	109	105	1079	222	-2	107


-- !query
SELECT c,
       d,
       a+b*2+c*3,
       a-b,
       e
  FROM t1
 ORDER BY 3,2,1,5,4
-- !query schema
struct<c:int,d:int,((a + (b * 2)) + (c * 3)):int,(a - b):int,e:int>
-- !query output
100	101	607	1	104
108	109	643	1	105


-- !query
SELECT c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b-c,
       (a+b+c+d+e)/5,
       abs(b-c),
       a+b*2+c*3,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND (e>c OR e<d)
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 6,7,2,1,3,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3,
       d-e
  FROM t1
 WHERE a>b
   AND c BETWEEN b-2 AND d+2
   AND (a>b-2 AND a<b+2)
 ORDER BY 2,3,4,1,5
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,(c - d):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,((a + (b * 2)) + (c * 3)):int,(d - e):int>
-- !query output
107.0	-1	222	643	4
102.0	-1	444	607	-3


-- !query
SELECT c-d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2,
       a,
       abs(b-c),
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR b>c
 ORDER BY 3,5,4,2,6,7,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(a),
       a+b*2+c*3+d*4+e*5,
       d-e,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR d>e
    OR b>c
 ORDER BY 2,3,1,5,4,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       a+b*2,
       a,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c-d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE (e>a AND e<b)
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 1,3,6,2,5,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (e>c OR e<d)
   AND d>e
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1,2
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
214	1604


-- !query
SELECT b,
       abs(a)
  FROM t1
 WHERE (e>a AND e<b)
    OR c BETWEEN b-2 AND d+2
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,1
-- !query schema
struct<b:int,abs(a):int>
-- !query output
102	103
106	107


-- !query
SELECT a+b*2,
       a+b*2+c*3+d*4+e*5,
       b,
       c-d,
       abs(b-c),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 5,1,4,7,3,2,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (e>a AND e<b)
   AND (e>c OR e<d)
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output



-- !query
SELECT a+b*2+c*3+d*4,
       b,
       a-b
  FROM t1
 WHERE c>d
    OR d>e
    OR b>c
 ORDER BY 3,1,2
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,b:int,(a - b):int>
-- !query output
1011	102	1
1079	106	1


-- !query
SELECT a-b
  FROM t1
 ORDER BY 1
-- !query schema
struct<(a - b):int>
-- !query output
1
1


-- !query
SELECT e,
       a+b*2+c*3+d*4+e*5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a-b
  FROM t1
 WHERE a>b
    OR c BETWEEN b-2 AND d+2
 ORDER BY 3,2,4,1
-- !query schema
struct<e:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(a - b):int>
-- !query output
104	1531	333	1
105	1604	333	1


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       e,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2
  FROM t1
 ORDER BY 2,4,1,5,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       c,
       d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       (a+b+c+d+e)/5
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR d NOT BETWEEN 110 AND 150
    OR b>c
 ORDER BY 3,5,4,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE b>c
   AND a>b
   AND (e>a AND e<b)
 ORDER BY 2,1
-- !query schema
struct<(b - c):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output



-- !query
SELECT a+b*2,
       b-c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE b>c
   AND a>b
 ORDER BY 3,2,1
-- !query schema
struct<(a + (b * 2)):int,(b - c):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
307	2	444


-- !query
SELECT a+b*2+c*3,
       d,
       b-c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a-b
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND b>c
   AND c>d
 ORDER BY 3,5,1,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d-e,
       (a+b+c+d+e)/5,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 2,1,3,4
-- !query schema
struct<(d - e):int,(((((a + b) + c) + d) + e) / 5):double,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,d:int>
-- !query output
-3	102.0	444	101
4	107.0	222	109


-- !query
SELECT c-d,
       e
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND c>d
 ORDER BY 2,1
-- !query schema
struct<(c - d):int,e:int>
-- !query output



-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE (e>a AND e<b)
   AND d>e
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 1
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output



-- !query
SELECT a-b,
       b-c
  FROM t1
 WHERE b>c
   AND d>e
   AND c BETWEEN b-2 AND d+2
 ORDER BY 2,1
-- !query schema
struct<(a - b):int,(b - c):int>
-- !query output



-- !query
SELECT b,
       d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE b>c
 ORDER BY 1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
1604


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b-c,
       a+b*2
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1,3,2
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(b - c):int,(a + (b * 2)):int>
-- !query output
214	-2	319


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
214
1020


-- !query
SELECT a+b*2+c*3+d*4,
       a+b*2+c*3
  FROM t1
 WHERE b>c
 ORDER BY 1,2
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
1011	607


-- !query
SELECT e,
       a,
       a+b*2+c*3,
       b,
       d
  FROM t1
 WHERE c>d
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 4,5,1,3,2
-- !query schema
struct<e:int,a:int,((a + (b * 2)) + (c * 3)):int,b:int,d:int>
-- !query output
105	107	643	106	109


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       b-c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE a>b
 ORDER BY 3,1,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(b - c):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
1604	-2	214
1531	2	1020


-- !query
SELECT abs(a),
       (a+b+c+d+e)/5,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3,
       d-e
  FROM t1
 ORDER BY 3,1,2,5,4
-- !query schema
struct<abs(a):int,(((((a + b) + c) + d) + e) / 5):double,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,((a + (b * 2)) + (c * 3)):int,(d - e):int>
-- !query output
107	107.0	222	643	4
103	102.0	444	607	-3


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c,
       (a+b+c+d+e)/5,
       a+b*2,
       c-d
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND e+d BETWEEN a+b-10 AND c+130
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 5,3,2,4,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       a+b*2,
       abs(b-c)
  FROM t1
 WHERE b>c
    OR (a>b-2 AND a<b+2)
 ORDER BY 2,1,3
-- !query schema
struct<c:int,(a + (b * 2)):int,abs((b - c)):int>
-- !query output
100	307	2
108	319	2


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d-e,
       a+b*2+c*3+d*4,
       c,
       a+b*2
  FROM t1
 ORDER BY 7,3,2,6,4,5,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       abs(a),
       a-b
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 1,3,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,abs(a):int,(a - b):int>
-- !query output



-- !query
SELECT d
  FROM t1
 WHERE (e>a AND e<b)
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1
-- !query schema
struct<d:int>
-- !query output
109


-- !query
SELECT (a+b+c+d+e)/5,
       abs(b-c),
       c,
       a+b*2+c*3+d*4+e*5,
       abs(a),
       e
  FROM t1
 WHERE b>c
   AND d>e
 ORDER BY 4,5,6,3,2,1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,abs((b - c)):int,c:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,abs(a):int,e:int>
-- !query output



-- !query
SELECT a+b*2+c*3
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int>
-- !query output
607
643


-- !query
SELECT abs(b-c),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b,
       a
  FROM t1
 WHERE b>c
   AND d>e
 ORDER BY 4,1,3,2
-- !query schema
struct<abs((b - c)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,b:int,a:int>
-- !query output



-- !query
SELECT a+b*2+c*3+d*4,
       (a+b+c+d+e)/5,
       a,
       abs(a),
       c-d,
       c
  FROM t1
 ORDER BY 2,5,4,6,3,1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(((((a + b) + c) + d) + e) / 5):double,a:int,abs(a):int,(c - d):int,c:int>
-- !query output
1011	102.0	103	103	-1	100
1079	107.0	107	107	-1	108


-- !query
SELECT d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(b-c),
       b,
       e
  FROM t1
 WHERE a>b
 ORDER BY 1,3,2
-- !query schema
struct<abs((b - c)):int,b:int,e:int>
-- !query output
2	102	104
2	106	105


-- !query
SELECT abs(a),
       a-b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(b-c),
       d-e
  FROM t1
 ORDER BY 3,1,4,5,2
-- !query schema
struct<abs(a):int,(a - b):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,abs((b - c)):int,(d - e):int>
-- !query output
107	1	214	2	4
103	1	1020	2	-3


-- !query
SELECT abs(b-c),
       e
  FROM t1
 WHERE c>d
 ORDER BY 1,2
-- !query schema
struct<abs((b - c)):int,e:int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4+e*5,
       a,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d
  FROM t1
 WHERE a>b
   AND (e>a AND e<b)
 ORDER BY 7,2,4,6,1,3,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
1604


-- !query
SELECT b,
       e
  FROM t1
 WHERE d>e
    OR (a>b-2 AND a<b+2)
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 2,1
-- !query schema
struct<b:int,e:int>
-- !query output
102	104
106	105


-- !query
SELECT a+b*2+c*3,
       a+b*2
  FROM t1
 WHERE a>b
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 2,1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,(a + (b * 2)):int>
-- !query output
607	307
643	319


-- !query
SELECT (a+b+c+d+e)/5,
       d,
       a+b*2+c*3+d*4
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 3,2,1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,d:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
107.0	109	1079


-- !query
SELECT abs(b-c),
       c-d
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<abs((b - c)):int,(c - d):int>
-- !query output
2	-1
2	-1


-- !query
SELECT a+b*2+c*3+d*4,
       a+b*2+c*3+d*4+e*5,
       a,
       a+b*2
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR a>b
    OR b>c
 ORDER BY 3,1,2,4
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,a:int,(a + (b * 2)):int>
-- !query output
1011	1531	103	307
1079	1604	107	319


-- !query
SELECT a,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4+e*5,
       d,
       a+b*2+c*3
  FROM t1
 WHERE b>c
   AND (c<=d-2 OR c>=d+2)
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,3,1,6,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<c:int,b:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
100	102	333
108	106	333


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4+e*5,
       c-d,
       d
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1,3,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b
  FROM t1
 ORDER BY 1
-- !query schema
struct<b:int>
-- !query output
102
106


-- !query
SELECT a+b*2+c*3
  FROM t1
 ORDER BY 1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int>
-- !query output
607
643


-- !query
SELECT abs(a),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND d NOT BETWEEN 110 AND 150
   AND (a>b-2 AND a<b+2)
 ORDER BY 2,1
-- !query schema
struct<abs(a):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
103	333
107	333


-- !query
SELECT (a+b+c+d+e)/5,
       a+b*2,
       a+b*2+c*3+d*4+e*5,
       a,
       d-e
  FROM t1
 WHERE d>e
   AND (e>a AND e<b)
   AND b>c
 ORDER BY 1,5,3,4,2
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,(a + (b * 2)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,a:int,(d - e):int>
-- !query output



-- !query
SELECT a+b*2+c*3
  FROM t1
 WHERE b>c
    OR a>b
    OR (e>a AND e<b)
 ORDER BY 1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int>
-- !query output
607
643


-- !query
SELECT a+b*2+c*3,
       e,
       a-b
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND b>c
 ORDER BY 1,3,2
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,e:int,(a - b):int>
-- !query output
607	104	1


-- !query
SELECT d-e,
       a,
       b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 ORDER BY 3,1,2,4
-- !query schema
struct<(d - e):int,a:int,b:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
-3	103	102	444
4	107	106	222


-- !query
SELECT b,
       d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(b-c),
       a+b*2+c*3+d*4+e*5,
       a+b*2
  FROM t1
 WHERE d>e
   AND c>d
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 6,5,2,1,3,4
-- !query schema
struct<b:int,d:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,abs((b - c)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(a + (b * 2)):int>
-- !query output



-- !query
SELECT (a+b+c+d+e)/5,
       a+b*2+c*3
  FROM t1
 WHERE b>c
    OR d NOT BETWEEN 110 AND 150
    OR c BETWEEN b-2 AND d+2
 ORDER BY 2,1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,((a + (b * 2)) + (c * 3)):int>
-- !query output
102.0	607
107.0	643


-- !query
SELECT a+b*2+c*3,
       c-d,
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE d>e
    OR (c<=d-2 OR c>=d+2)
    OR c BETWEEN b-2 AND d+2
 ORDER BY 1,2,4,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       abs(a),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a-b,
       a,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4+e*5
  FROM t1
 ORDER BY 3,5,1,2,7,4,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       abs(a),
       d,
       (a+b+c+d+e)/5,
       c-d
  FROM t1
 WHERE d>e
   AND (e>c OR e<d)
 ORDER BY 2,1,3,5,4
-- !query schema
struct<a:int,abs(a):int,d:int,(((((a + b) + c) + d) + e) / 5):double,(c - d):int>
-- !query output
107	107	109	107.0	-1


-- !query
SELECT a+b*2+c*3,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 1,5,3,2,4
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,c:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,d:int>
-- !query output



-- !query
SELECT c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2,
       e,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       b-c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND d>e
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 7,2,1,5,6,4,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (a+b+c+d+e)/5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE a>b
 ORDER BY 7,6,5,2,1,3,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE a>b
   AND (c<=d-2 OR c>=d+2)
   AND c>d
 ORDER BY 6,5,4,2,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       a+b*2,
       e
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 1,2,3
-- !query schema
struct<c:int,(a + (b * 2)):int,e:int>
-- !query output
100	307	104
108	319	105


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4,
       b,
       b-c,
       e,
       a
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (e>a AND e<b)
   AND (a>b-2 AND a<b+2)
 ORDER BY 3,2,1,6,5,4
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,b:int,(b - c):int,e:int,a:int>
-- !query output



-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4,
       c
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 1,3,2
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,c:int>
-- !query output
214	1079	108
1020	1011	100


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c-d
  FROM t1
 ORDER BY 2,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d-e,
       abs(b-c),
       (a+b+c+d+e)/5,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND (e>a AND e<b)
   AND a>b
 ORDER BY 3,4,1,2
-- !query schema
struct<(d - e):int,abs((b - c)):int,(((((a + b) + c) + d) + e) / 5):double,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output



-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3,
       b-c,
       d-e
  FROM t1
 ORDER BY 1,2,3,4
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,((a + (b * 2)) + (c * 3)):int,(b - c):int,(d - e):int>
-- !query output
222	643	-2	4
444	607	2	-3


-- !query
SELECT d,
       a+b*2+c*3
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 2,1
-- !query schema
struct<d:int,((a + (b * 2)) + (c * 3)):int>
-- !query output
101	607
109	643


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       d,
       a+b*2+c*3+d*4,
       c,
       d-e,
       a+b*2
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND (a>b-2 AND a<b+2)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 4,6,2,5,1,3
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,d:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,c:int,(d - e):int,(a + (b * 2)):int>
-- !query output
1531	101	1011	100	-3	307
1604	109	1079	108	4	319


-- !query
SELECT abs(a),
       abs(b-c),
       c,
       a-b,
       c-d,
       a+b*2+c*3+d*4,
       b
  FROM t1
 ORDER BY 2,6,7,4,1,5,3
-- !query schema
struct<abs(a):int,abs((b - c)):int,c:int,(a - b):int,(c - d):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,b:int>
-- !query output
103	2	100	1	-1	1011	102
107	2	108	1	-1	1079	106


-- !query
SELECT b,
       d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (e>c OR e<d)
    OR e+d BETWEEN a+b-10 AND c+130
    OR a>b
 ORDER BY 3,2,1
-- !query schema
struct<b:int,d:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
106	109	222
102	101	444


-- !query
SELECT a-b,
       a+b*2+c*3+d*4,
       d,
       e
  FROM t1
 ORDER BY 2,4,1,3
-- !query schema
struct<(a - b):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,d:int,e:int>
-- !query output
1	1011	101	104
1	1079	109	105


-- !query
SELECT a+b*2,
       c-d,
       d-e,
       abs(a),
       a-b,
       c,
       b
  FROM t1
 WHERE a>b
 ORDER BY 3,2,1,4,7,5,6
-- !query schema
struct<(a + (b * 2)):int,(c - d):int,(d - e):int,abs(a):int,(a - b):int,c:int,b:int>
-- !query output
307	-1	-3	103	1	100	102
319	-1	4	107	1	108	106


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       e,
       a+b*2+c*3+d*4,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3,
       abs(a),
       c-d
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR (e>c OR e<d)
 ORDER BY 1,4,2,5,7,3,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       (a+b+c+d+e)/5,
       a+b*2+c*3,
       a+b*2+c*3+d*4+e*5,
       d-e,
       c
  FROM t1
 WHERE d>e
    OR (e>a AND e<b)
    OR (e>c OR e<d)
 ORDER BY 2,3,1,4,5,6
-- !query schema
struct<d:int,(((((a + b) + c) + d) + e) / 5):double,((a + (b * 2)) + (c * 3)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(d - e):int,c:int>
-- !query output
101	102.0	607	1531	-3	100
109	107.0	643	1604	4	108


-- !query
SELECT d
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
    OR c BETWEEN b-2 AND d+2
 ORDER BY 1
-- !query schema
struct<d:int>
-- !query output
101
109


-- !query
SELECT a+b*2,
       c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1,3,2,4
-- !query schema
struct<(a + (b * 2)):int,c:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,d:int>
-- !query output
307	100	1020	101
319	108	214	109


-- !query
SELECT a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       b,
       c,
       abs(a)
  FROM t1
 WHERE d>e
 ORDER BY 1,3,2,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4+e*5,
       c-d
  FROM t1
 ORDER BY 4,1,2,3,5
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(c - d):int>
-- !query output
1020	1011	444	1531	-1
214	1079	222	1604	-1


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       e,
       a+b*2+c*3,
       c
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR d>e
 ORDER BY 3,4,2,5,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a)
  FROM t1
 ORDER BY 1
-- !query schema
struct<abs(a):int>
-- !query output
103
107


-- !query
SELECT a+b*2+c*3+d*4,
       d,
       a-b,
       abs(a),
       c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 5,2,1,4,6,3
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,d:int,(a - b):int,abs(a):int,c:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
1011	101	1	103	100	333
1079	109	1	107	108	333


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(a),
       a-b,
       a+b*2+c*3,
       d-e,
       b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 1,5,6,2,4,7,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a+b*2+c*3,
       a-b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c,
       a
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (e>a AND e<b)
   AND a>b
 ORDER BY 2,4,6,5,1,3
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,((a + (b * 2)) + (c * 3)):int,(a - b):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,c:int,a:int>
-- !query output



-- !query
SELECT a+b*2+c*3+d*4,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE c>d
 ORDER BY 4,1,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
333
333


-- !query
SELECT b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c-d,
       b-c,
       a+b*2+c*3+d*4,
       c,
       abs(a)
  FROM t1
 WHERE d>e
 ORDER BY 2,1,4,5,6,3,7
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b,
       a+b*2+c*3+d*4,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a,
       abs(b-c),
       abs(a)
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 5,4,2,1,3,6
-- !query schema
struct<b:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,a:int,abs((b - c)):int,abs(a):int>
-- !query output



-- !query
SELECT d,
       a,
       abs(b-c),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b-c,
       (a+b+c+d+e)/5,
       e
  FROM t1
 WHERE (e>c OR e<d)
    OR (a>b-2 AND a<b+2)
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 3,5,1,4,7,6,2
-- !query schema
struct<d:int,a:int,abs((b - c)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(b - c):int,(((((a + b) + c) + d) + e) / 5):double,e:int>
-- !query output
109	107	2	222	-2	107.0	105
101	103	2	444	2	102.0	104


-- !query
SELECT a-b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b
  FROM t1
 ORDER BY 1,3,2
-- !query schema
struct<(a - b):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,b:int>
-- !query output
1	1020	102
1	214	106


-- !query
SELECT b,
       a-b,
       c,
       abs(b-c),
       d-e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b-c
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1,6,4,5,2,7,3
-- !query schema
struct<b:int,(a - b):int,c:int,abs((b - c)):int,(d - e):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(b - c):int>
-- !query output
106	1	108	2	4	214	-2


-- !query
SELECT c-d,
       a+b*2+c*3+d*4,
       a,
       abs(b-c),
       abs(a),
       (a+b+c+d+e)/5,
       c
  FROM t1
 ORDER BY 2,4,5,6,3,7,1
-- !query schema
struct<(c - d):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,a:int,abs((b - c)):int,abs(a):int,(((((a + b) + c) + d) + e) / 5):double,c:int>
-- !query output
-1	1011	103	2	103	102.0	100
-1	1079	107	2	107	107.0	108


-- !query
SELECT c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(a),
       e,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d,
       a-b
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR (e>a AND e<b)
 ORDER BY 7,4,1,2,6,5,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2,
       b,
       d-e,
       a,
       abs(b-c),
       d
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1,2,5,4,3,6
-- !query schema
struct<(a + (b * 2)):int,b:int,(d - e):int,a:int,abs((b - c)):int,d:int>
-- !query output
307	102	-3	103	2	101
319	106	4	107	2	109


-- !query
SELECT d
  FROM t1
 WHERE (e>a AND e<b)
    OR (e>c OR e<d)
 ORDER BY 1
-- !query schema
struct<d:int>
-- !query output
101
109


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(a),
       d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a,
       a+b*2
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND (a>b-2 AND a<b+2)
 ORDER BY 5,6,3,1,2,4,7
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d-e
  FROM t1
 WHERE b>c
   AND d>e
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 1,2
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(d - e):int>
-- !query output



-- !query
SELECT abs(a),
       a+b*2+c*3+d*4,
       a+b*2+c*3,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE b>c
    OR (e>a AND e<b)
 ORDER BY 2,4,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND c BETWEEN b-2 AND d+2
   AND b>c
 ORDER BY 1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int>
-- !query output



-- !query
SELECT d,
       abs(b-c),
       a-b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3,
       e,
       b
  FROM t1
 ORDER BY 2,6,3,5,7,4,1
-- !query schema
struct<d:int,abs((b - c)):int,(a - b):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,((a + (b * 2)) + (c * 3)):int,e:int,b:int>
-- !query output
101	2	1	333	607	104	102
109	2	1	333	643	105	106


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4,
       a+b*2+c*3
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
222	1079	643
444	1011	607


-- !query
SELECT c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(a),
       d-e,
       b,
       abs(b-c),
       a+b*2+c*3
  FROM t1
 ORDER BY 6,1,4,2,5,3,7
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(b-c),
       a+b*2+c*3+d*4+e*5,
       a+b*2+c*3,
       e
  FROM t1
 WHERE c>d
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,3,4,1
-- !query schema
struct<abs((b - c)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,((a + (b * 2)) + (c * 3)):int,e:int>
-- !query output
2	1604	643	105


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a,
       a+b*2+c*3,
       abs(b-c),
       c-d,
       a+b*2+c*3+d*4
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 3,2,6,4,5,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d-e,
       a+b*2+c*3+d*4,
       d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a-b,
       b
  FROM t1
 WHERE c>d
   AND a>b
 ORDER BY 2,4,3,6,1,5
-- !query schema
struct<(d - e):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,d:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(a - b):int,b:int>
-- !query output



-- !query
SELECT abs(b-c)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND c>d
 ORDER BY 1
-- !query schema
struct<abs((b - c)):int>
-- !query output



-- !query
SELECT c,
       c-d,
       a+b*2+c*3+d*4,
       a+b*2+c*3+d*4+e*5,
       abs(b-c),
       (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND a>b
   AND c>d
 ORDER BY 7,1,5,3,2,4,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b,
       a+b*2+c*3
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR d NOT BETWEEN 110 AND 150
    OR d>e
 ORDER BY 1,2
-- !query schema
struct<(a - b):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
1	607
1	643


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4,
       c-d,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 ORDER BY 2,3,4,5,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE a>b
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 1
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output



-- !query
SELECT d-e
  FROM t1
 WHERE a>b
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 1
-- !query schema
struct<(d - e):int>
-- !query output



-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR d NOT BETWEEN 110 AND 150
    OR b>c
 ORDER BY 1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
222
444


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR d>e
    OR (e>c OR e<d)
 ORDER BY 1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4+e*5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 2,4,5,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       abs(a),
       (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 3,1,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2,
       b,
       abs(b-c),
       c-d
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND d>e
   AND (a>b-2 AND a<b+2)
 ORDER BY 3,5,6,7,2,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a-b,
       abs(b-c)
  FROM t1
 WHERE c>d
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 2,1,3
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(a - b):int,abs((b - c)):int>
-- !query output



-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d,
       a+b*2+c*3
  FROM t1
 WHERE b>c
    OR c BETWEEN b-2 AND d+2
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 1,3,2
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,d:int,((a + (b * 2)) + (c * 3)):int>
-- !query output
214	109	643
1020	101	607


-- !query
SELECT (a+b+c+d+e)/5,
       a,
       b
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 3,2,1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,a:int,b:int>
-- !query output
102.0	103	102
107.0	107	106


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a-b,
       abs(a),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a
  FROM t1
 ORDER BY 2,4,5,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       a-b,
       a+b*2+c*3,
       abs(b-c),
       a+b*2+c*3+d*4
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
    OR d>e
    OR a>b
 ORDER BY 5,3,2,4,1
-- !query schema
struct<c:int,(a - b):int,((a + (b * 2)) + (c * 3)):int,abs((b - c)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
100	1	607	2	1011
108	1	643	2	1079


-- !query
SELECT (a+b+c+d+e)/5,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(b-c),
       b-c,
       a+b*2+c*3
  FROM t1
 WHERE (e>c OR e<d)
   AND (c<=d-2 OR c>=d+2)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 2,5,4,6,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       abs(b-c),
       a,
       abs(a),
       b,
       a+b*2
  FROM t1
 WHERE a>b
    OR (a>b-2 AND a<b+2)
 ORDER BY 1,6,3,5,4,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,abs((b - c)):int,a:int,abs(a):int,b:int,(a + (b * 2)):int>
-- !query output
1531	2	103	103	102	307
1604	2	107	107	106	319


-- !query
SELECT abs(b-c)
  FROM t1
 ORDER BY 1
-- !query schema
struct<abs((b - c)):int>
-- !query output
2
2


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       b-c,
       d-e,
       a+b*2+c*3+d*4,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d
  FROM t1
 WHERE (e>a AND e<b)
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 6,4,1,5,3,7,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       a+b*2+c*3,
       a+b*2+c*3+d*4+e*5,
       c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 2,4,5,6,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR (c<=d-2 OR c>=d+2)
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double>
-- !query output
102.0
107.0


-- !query
SELECT e
  FROM t1
 ORDER BY 1
-- !query schema
struct<e:int>
-- !query output
104
105


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a+b*2
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(a + (b * 2)):int>
-- !query output
1531	307
1604	319


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4
  FROM t1
 ORDER BY 2,3,1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1020	333	1011
214	333	1079


-- !query
SELECT c
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1
-- !query schema
struct<c:int>
-- !query output
100
108


-- !query
SELECT a+b*2,
       a,
       d,
       c,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 4,2,3,1,5
-- !query schema
struct<(a + (b * 2)):int,a:int,d:int,c:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
307	103	101	100	102.0
319	107	109	108	107.0


-- !query
SELECT a-b,
       a+b*2+c*3,
       a+b*2+c*3+d*4,
       d,
       (a+b+c+d+e)/5
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 4,5,3,2,1
-- !query schema
struct<(a - b):int,((a + (b * 2)) + (c * 3)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,d:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
1	643	1079	109	107.0


-- !query
SELECT d-e
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 1
-- !query schema
struct<(d - e):int>
-- !query output
-3
4


-- !query
SELECT abs(b-c),
       a+b*2+c*3,
       a+b*2
  FROM t1
 ORDER BY 1,3,2
-- !query schema
struct<abs((b - c)):int,((a + (b * 2)) + (c * 3)):int,(a + (b * 2)):int>
-- !query output
2	607	307
2	643	319


-- !query
SELECT d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a,
       d-e,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE d>e
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 4,3,5,1,2
-- !query schema
struct<d:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,a:int,(d - e):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
109	222	107	4	1604


-- !query
SELECT abs(a),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       e,
       a+b*2,
       a,
       a-b
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1,2,5,3,6,4
-- !query schema
struct<abs(a):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,e:int,(a + (b * 2)):int,a:int,(a - b):int>
-- !query output



-- !query
SELECT a-b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       b-c,
       a+b*2+c*3+d*4,
       b,
       abs(b-c)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND d NOT BETWEEN 110 AND 150
   AND (e>a AND e<b)
 ORDER BY 4,1,5,6,2,3
-- !query schema
struct<(a - b):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(b - c):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,b:int,abs((b - c)):int>
-- !query output



-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(b-c),
       b-c,
       c,
       a+b*2+c*3+d*4,
       (a+b+c+d+e)/5
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND b>c
   AND (a>b-2 AND a<b+2)
 ORDER BY 3,5,2,1,6,4
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,abs((b - c)):int,(b - c):int,c:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
333	2	2	100	1011	102.0


-- !query
SELECT b,
       a-b,
       a,
       abs(a)
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1,2,3,4
-- !query schema
struct<b:int,(a - b):int,a:int,abs(a):int>
-- !query output
102	1	103	103
106	1	107	107


-- !query
SELECT a+b*2+c*3,
       c,
       b-c,
       a+b*2+c*3+d*4,
       a,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       (a+b+c+d+e)/5
  FROM t1
 WHERE (e>c OR e<d)
   AND c BETWEEN b-2 AND d+2
   AND (e>a AND e<b)
 ORDER BY 7,5,3,2,6,4,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       b-c,
       d-e
  FROM t1
 ORDER BY 2,3,1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(b - c):int,(d - e):int>
-- !query output
1604	-2	4
1531	2	-3


-- !query
SELECT a+b*2+c*3,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND (a>b-2 AND a<b+2)
   AND c>d
 ORDER BY 1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       e,
       abs(a),
       c-d,
       a,
       b-c
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR (c<=d-2 OR c>=d+2)
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 7,1,5,3,4,6,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       a+b*2+c*3,
       a-b,
       abs(b-c),
       a+b*2
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR c BETWEEN b-2 AND d+2
 ORDER BY 2,1,5,4,3
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,((a + (b * 2)) + (c * 3)):int,(a - b):int,abs((b - c)):int,(a + (b * 2)):int>
-- !query output
102.0	607	1	2	307
107.0	643	1	2	319


-- !query
SELECT b-c,
       c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (a+b+c+d+e)/5
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR (a>b-2 AND a<b+2)
    OR d>e
 ORDER BY 1,3,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
1531
1604


-- !query
SELECT (a+b+c+d+e)/5,
       c
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 1,2
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,c:int>
-- !query output



-- !query
SELECT a+b*2+c*3,
       a+b*2+c*3+d*4+e*5,
       abs(b-c),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 3,2,1,6,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a-b,
       a,
       d-e
  FROM t1
 ORDER BY 1,2,3,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b,
       b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 ORDER BY 2,1,3
-- !query schema
struct<(a - b):int,b:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
1	102	333
1	106	333


-- !query
SELECT e,
       a+b*2,
       abs(a),
       b
  FROM t1
 ORDER BY 4,2,1,3
-- !query schema
struct<e:int,(a + (b * 2)):int,abs(a):int,b:int>
-- !query output
104	307	103	102
105	319	107	106


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4+e*5,
       b-c,
       d-e
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 5,3,2,1,4
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(b - c):int,(d - e):int>
-- !query output



-- !query
SELECT abs(a),
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4,
       b-c
  FROM t1
 ORDER BY 6,1,3,5,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d
  FROM t1
 ORDER BY 1
-- !query schema
struct<d:int>
-- !query output
101
109


-- !query
SELECT abs(b-c),
       a-b,
       (a+b+c+d+e)/5
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR (a>b-2 AND a<b+2)
 ORDER BY 2,1,3
-- !query schema
struct<abs((b - c)):int,(a - b):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
2	1	102.0
2	1	107.0


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       e,
       b-c
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND b>c
   AND c>d
 ORDER BY 2,1,3
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,e:int,(b - c):int>
-- !query output



-- !query
SELECT c-d,
       (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d,
       b-c
  FROM t1
 WHERE c>d
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND a>b
 ORDER BY 2,4,3,5,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE a>b
    OR (e>a AND e<b)
 ORDER BY 4,6,2,5,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4+e*5
  FROM t1
 ORDER BY 2,1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
444	1531
222	1604


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,b:int>
-- !query output
222	106
444	102


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       b,
       a,
       a+b*2+c*3+d*4+e*5,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3
  FROM t1
 WHERE a>b
   AND (e>c OR e<d)
 ORDER BY 3,7,2,5,6,4,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       a+b*2+c*3+d*4+e*5,
       b-c,
       a,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4,
       a-b
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND c>d
   AND b>c
 ORDER BY 6,5,7,4,3,1,2
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(b - c):int,a:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(a - b):int>
-- !query output



-- !query
SELECT b,
       c,
       abs(a),
       d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (a+b+c+d+e)/5
  FROM t1
 WHERE d>e
   AND c BETWEEN b-2 AND d+2
   AND (e>a AND e<b)
 ORDER BY 2,4,5,6,3,7,1
-- !query schema
struct<b:int,c:int,abs(a):int,d:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output



-- !query
SELECT a,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 4,5,3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE (e>a AND e<b)
   AND c BETWEEN b-2 AND d+2
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 1
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output



-- !query
SELECT d
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR d>e
    OR a>b
 ORDER BY 1
-- !query schema
struct<d:int>
-- !query output
101
109


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       b-c
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 2,1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(b - c):int>
-- !query output
1604	-2
1531	2


-- !query
SELECT a-b,
       a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(a),
       a+b*2+c*3,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE b>c
   AND (c<=d-2 OR c>=d+2)
   AND c>d
 ORDER BY 2,1,5,6,4,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       a-b
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<abs(a):int,(a - b):int>
-- !query output
103	1
107	1


-- !query
SELECT b-c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (a+b+c+d+e)/5,
       b,
       c-d,
       a+b*2,
       a+b*2+c*3
  FROM t1
 WHERE c>d
   AND (e>c OR e<d)
   AND d>e
 ORDER BY 4,7,5,2,1,6,3
-- !query schema
struct<(b - c):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((((a + b) + c) + d) + e) / 5):double,b:int,(c - d):int,(a + (b * 2)):int,((a + (b * 2)) + (c * 3)):int>
-- !query output



-- !query
SELECT c-d,
       a-b,
       b,
       b-c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c,
       a+b*2
  FROM t1
 ORDER BY 1,5,4,3,2,6,7
-- !query schema
struct<(c - d):int,(a - b):int,b:int,(b - c):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,c:int,(a + (b * 2)):int>
-- !query output
-1	1	106	-2	214	108	319
-1	1	102	2	1020	100	307


-- !query
SELECT a+b*2+c*3,
       a,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(a)
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR b>c
 ORDER BY 2,4,3,1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,a:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,abs(a):int>
-- !query output
607	103	333	103
643	107	333	107


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d,
       abs(a),
       e,
       a+b*2
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 3,4,2,1,5
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,d:int,abs(a):int,e:int,(a + (b * 2)):int>
-- !query output
1020	101	103	104	307
214	109	107	105	319


-- !query
SELECT b,
       abs(b-c),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b-c
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND e+d BETWEEN a+b-10 AND c+130
   AND (e>c OR e<d)
 ORDER BY 2,1,4,3
-- !query schema
struct<b:int,abs((b - c)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(b - c):int>
-- !query output



-- !query
SELECT b-c,
       e,
       c-d,
       a-b
  FROM t1
 WHERE b>c
    OR c BETWEEN b-2 AND d+2
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 4,1,2,3
-- !query schema
struct<(b - c):int,e:int,(c - d):int,(a - b):int>
-- !query output
-2	105	-1	1
2	104	-1	1


-- !query
SELECT a+b*2+c*3+d*4,
       (a+b+c+d+e)/5,
       b
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(((((a + b) + c) + d) + e) / 5):double,b:int>
-- !query output
1011	102.0	102
1079	107.0	106


-- !query
SELECT c-d,
       (a+b+c+d+e)/5,
       abs(b-c),
       c,
       d
  FROM t1
 WHERE c>d
    OR a>b
 ORDER BY 4,2,3,1,5
-- !query schema
struct<(c - d):int,(((((a + b) + c) + d) + e) / 5):double,abs((b - c)):int,c:int,d:int>
-- !query output
-1	102.0	2	100	101
-1	107.0	2	108	109


-- !query
SELECT a+b*2+c*3,
       d,
       abs(b-c)
  FROM t1
 ORDER BY 3,1,2
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,d:int,abs((b - c)):int>
-- !query output
607	101	2
643	109	2


-- !query
SELECT e,
       a+b*2+c*3,
       abs(b-c),
       d-e
  FROM t1
 ORDER BY 1,3,4,2
-- !query schema
struct<e:int,((a + (b * 2)) + (c * 3)):int,abs((b - c)):int,(d - e):int>
-- !query output
104	607	2	-3
105	643	2	4


-- !query
SELECT a,
       abs(a),
       d-e,
       e
  FROM t1
 ORDER BY 2,4,1,3
-- !query schema
struct<a:int,abs(a):int,(d - e):int,e:int>
-- !query output
103	103	-3	104
107	107	4	105


-- !query
SELECT b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (e>a AND e<b)
    OR c>d
 ORDER BY 1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       a-b,
       a+b*2
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<(b - c):int,(a - b):int,(a + (b * 2)):int>
-- !query output
-2	1	319
2	1	307


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       abs(b-c)
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,abs((b - c)):int>
-- !query output
1604	2


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(a),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND c>d
 ORDER BY 1,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
    OR d>e
 ORDER BY 1
-- !query schema
struct<(c - d):int>
-- !query output
-1
-1


-- !query
SELECT a-b,
       d,
       a+b*2+c*3,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       (a+b+c+d+e)/5,
       b,
       d-e
  FROM t1
 ORDER BY 1,5,3,7,4,6,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       a,
       c-d,
       abs(b-c),
       b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (e>c OR e<d)
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 4,3,2,5,1,6
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,a:int,(c - d):int,abs((b - c)):int,b:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
1011	103	-1	2	102	1020
1079	107	-1	2	106	214


-- !query
SELECT abs(b-c),
       (a+b+c+d+e)/5,
       d,
       b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c
  FROM t1
 ORDER BY 4,6,2,1,5,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       a+b*2+c*3+d*4+e*5,
       b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       e,
       a-b
  FROM t1
 ORDER BY 1,4,5,3,6,2
-- !query schema
struct<a:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,b:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,e:int,(a - b):int>
-- !query output
103	1531	102	1020	104	1
107	1604	106	214	105	1


-- !query
SELECT abs(a)
  FROM t1
 WHERE a>b
 ORDER BY 1
-- !query schema
struct<abs(a):int>
-- !query output
103
107


-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output



-- !query
SELECT e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a-b,
       b-c,
       (a+b+c+d+e)/5,
       a+b*2
  FROM t1
 WHERE (e>c OR e<d)
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR b>c
 ORDER BY 4,6,3,1,5,7,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3+d*4+e*5,
       b-c
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 3,4,5,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
1604


-- !query
SELECT a,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(b-c),
       c,
       a-b,
       abs(a)
  FROM t1
 ORDER BY 6,1,3,5,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c,
       a,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 2,3,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND d>e
   AND (e>a AND e<b)
 ORDER BY 1
-- !query schema
struct<abs(a):int>
-- !query output



-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4+e*5,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (a+b+c+d+e)/5,
       c-d
  FROM t1
 ORDER BY 2,4,5,1,3
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((((a + b) + c) + d) + e) / 5):double,(c - d):int>
-- !query output
333	1531	444	102.0	-1
333	1604	222	107.0	-1


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(b-c)
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR (a>b-2 AND a<b+2)
 ORDER BY 4,3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       d-e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2,
       a+b*2+c*3+d*4+e*5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3
  FROM t1
 ORDER BY 3,2,4,5,7,1,6
-- !query schema
struct<d:int,(d - e):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(a + (b * 2)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,((a + (b * 2)) + (c * 3)):int>
-- !query output
109	4	214	319	1604	333	643
101	-3	1020	307	1531	333	607


-- !query
SELECT b,
       abs(a),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b-c,
       a-b
  FROM t1
 ORDER BY 4,5,3,2,1
-- !query schema
struct<b:int,abs(a):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(b - c):int,(a - b):int>
-- !query output
106	107	222	-2	1
102	103	444	2	1


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d,
       (a+b+c+d+e)/5
  FROM t1
 WHERE (e>a AND e<b)
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 3,2,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c-d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c,
       d,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR c>d
 ORDER BY 1,2,4,5,6,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       (a+b+c+d+e)/5,
       d,
       e,
       a+b*2
  FROM t1
 ORDER BY 2,3,4,1,5
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(((((a + b) + c) + d) + e) / 5):double,d:int,e:int,(a + (b * 2)):int>
-- !query output
1011	102.0	101	104	307
1079	107.0	109	105	319


-- !query
SELECT b,
       e,
       b-c
  FROM t1
 ORDER BY 2,1,3
-- !query schema
struct<b:int,e:int,(b - c):int>
-- !query output
102	104	2
106	105	-2


-- !query
SELECT a+b*2+c*3,
       abs(a),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND (e>a AND e<b)
 ORDER BY 1,5,3,4,6,2,7
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND (e>c OR e<d)
   AND c>d
 ORDER BY 2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(b-c),
       a+b*2,
       d,
       b-c,
       a-b,
       d-e
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND c>d
 ORDER BY 3,1,2,5,6,4
-- !query schema
struct<abs((b - c)):int,(a + (b * 2)):int,d:int,(b - c):int,(a - b):int,(d - e):int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       b
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(b-c),
       e
  FROM t1
 ORDER BY 2,1
-- !query schema
struct<abs((b - c)):int,e:int>
-- !query output
2	104
2	105


-- !query
SELECT a+b*2+c*3,
       a+b*2+c*3+d*4,
       a-b,
       a+b*2
  FROM t1
 WHERE d>e
   AND c>d
   AND a>b
 ORDER BY 3,1,2,4
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(a - b):int,(a + (b * 2)):int>
-- !query output



-- !query
SELECT b,
       a+b*2+c*3,
       d-e
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 3,1,2
-- !query schema
struct<b:int,((a + (b * 2)) + (c * 3)):int,(d - e):int>
-- !query output
102	607	-3
106	643	4


-- !query
SELECT a-b,
       a,
       d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(b-c),
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 4,5,1,6,3,2
-- !query schema
struct<(a - b):int,a:int,d:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,abs((b - c)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output



-- !query
SELECT c-d,
       abs(a),
       a+b*2+c*3,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 4,2,5,1,3
-- !query schema
struct<(c - d):int,abs(a):int,((a + (b * 2)) + (c * 3)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
-1	103	607	333	1020
-1	107	643	333	214


-- !query
SELECT a+b*2
  FROM t1
 WHERE a>b
    OR (e>c OR e<d)
 ORDER BY 1
-- !query schema
struct<(a + (b * 2)):int>
-- !query output
307
319


-- !query
SELECT c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
    OR c BETWEEN b-2 AND d+2
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,1,3
-- !query schema
struct<(c - d):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
-1	222	1079
-1	444	1011


-- !query
SELECT a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3,
       b,
       d
  FROM t1
 WHERE a>b
 ORDER BY 1,5,4,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b,
       a+b*2
  FROM t1
 WHERE (e>a AND e<b)
    OR (a>b-2 AND a<b+2)
    OR (e>c OR e<d)
 ORDER BY 2,1
-- !query schema
struct<b:int,(a + (b * 2)):int>
-- !query output
102	307
106	319


-- !query
SELECT a+b*2,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a-b,
       d-e,
       a+b*2+c*3
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND e+d BETWEEN a+b-10 AND c+130
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 3,2,5,4,1
-- !query schema
struct<(a + (b * 2)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(a - b):int,(d - e):int,((a + (b * 2)) + (c * 3)):int>
-- !query output



-- !query
SELECT e,
       d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2,
       b,
       a+b*2+c*3
  FROM t1
 WHERE a>b
    OR (e>c OR e<d)
 ORDER BY 4,3,6,5,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       e,
       d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 4,2,5,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       a,
       d-e
  FROM t1
 ORDER BY 1,3,2
-- !query schema
struct<(b - c):int,a:int,(d - e):int>
-- !query output
-2	107	4
2	103	-3


-- !query
SELECT a,
       a+b*2+c*3+d*4+e*5,
       c-d
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND (e>a AND e<b)
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 3,2,1
-- !query schema
struct<a:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(c - d):int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b,
       c-d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (a+b+c+d+e)/5,
       a+b*2+c*3+d*4+e*5,
       b,
       abs(b-c)
  FROM t1
 WHERE b>c
 ORDER BY 5,2,1,7,3,4,6
-- !query schema
struct<(a - b):int,(c - d):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(((((a + b) + c) + d) + e) / 5):double,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,b:int,abs((b - c)):int>
-- !query output
1	-1	333	102.0	1531	102	2


-- !query
SELECT d,
       (a+b+c+d+e)/5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE b>c
 ORDER BY 1,3,2
-- !query schema
struct<d:int,(((((a + b) + c) + d) + e) / 5):double,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
101	102.0	333


-- !query
SELECT abs(a),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b,
       b-c
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 3,1,2,4
-- !query schema
struct<abs(a):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,b:int,(b - c):int>
-- !query output



-- !query
SELECT a-b,
       c-d,
       a+b*2+c*3+d*4+e*5,
       c,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 1,4,3,2,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       a-b,
       abs(a),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE b>c
    OR (a>b-2 AND a<b+2)
 ORDER BY 4,3,1,5,6,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4,
       b
  FROM t1
 WHERE c>d
    OR d>e
 ORDER BY 2,5,1,3,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b,
       a-b,
       b-c,
       d
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
    OR (c<=d-2 OR c>=d+2)
    OR (e>a AND e<b)
 ORDER BY 2,6,1,4,3,5
-- !query schema
struct<(a + (b * 2)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,b:int,(a - b):int,(b - c):int,d:int>
-- !query output
319	222	106	1	-2	109
307	444	102	1	2	101


-- !query
SELECT d,
       d-e,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4+e*5,
       e,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 6,5,1,7,2,3,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4
  FROM t1
 WHERE b>c
    OR (e>c OR e<d)
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 3,2,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       (a+b+c+d+e)/5,
       abs(b-c)
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 3,1,2
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(((((a + b) + c) + d) + e) / 5):double,abs((b - c)):int>
-- !query output



-- !query
SELECT a+b*2+c*3+d*4
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1011
1079


-- !query
SELECT a-b
  FROM t1
 WHERE c>d
 ORDER BY 1
-- !query schema
struct<(a - b):int>
-- !query output



-- !query
SELECT a+b*2+c*3,
       d,
       e,
       a+b*2+c*3+d*4+e*5,
       abs(a),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(b-c)
  FROM t1
 WHERE a>b
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 1,4,5,2,6,7,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a,
       abs(a),
       c,
       d-e
  FROM t1
 ORDER BY 5,4,1,2,3
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,a:int,abs(a):int,c:int,(d - e):int>
-- !query output
444	103	103	100	-3
222	107	107	108	4


-- !query
SELECT a+b*2+c*3+d*4,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a,
       d-e,
       e
  FROM t1
 ORDER BY 4,3,2,1,5,7,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
214
1020


-- !query
SELECT d,
       c
  FROM t1
 ORDER BY 2,1
-- !query schema
struct<d:int,c:int>
-- !query output
101	100
109	108


-- !query
SELECT d-e
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND a>b
 ORDER BY 1
-- !query schema
struct<(d - e):int>
-- !query output
4


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4+e*5,
       a+b*2,
       a+b*2+c*3,
       a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(b-c)
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 4,3,2,5,7,1,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d-e,
       b-c,
       a-b,
       a+b*2+c*3+d*4,
       abs(a)
  FROM t1
 ORDER BY 1,5,3,4,2
-- !query schema
struct<(d - e):int,(b - c):int,(a - b):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,abs(a):int>
-- !query output
-3	2	1	1011	103
4	-2	1	1079	107


-- !query
SELECT d-e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 1,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       (a+b+c+d+e)/5,
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c-d,
       d-e
  FROM t1
 WHERE b>c
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 2,3,6,7,4,1,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       a+b*2+c*3+d*4,
       c-d,
       a-b
  FROM t1
 ORDER BY 2,4,3,1
-- !query schema
struct<(b - c):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(c - d):int,(a - b):int>
-- !query output
2	1011	-1	1
-2	1079	-1	1


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 4,3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR c BETWEEN b-2 AND d+2
    OR (a>b-2 AND a<b+2)
 ORDER BY 2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b,
       b-c,
       a+b*2+c*3,
       abs(a),
       c-d,
       a,
       d-e
  FROM t1
 WHERE b>c
 ORDER BY 4,6,1,3,7,2,5
-- !query schema
struct<b:int,(b - c):int,((a + (b * 2)) + (c * 3)):int,abs(a):int,(c - d):int,a:int,(d - e):int>
-- !query output
102	2	607	103	-1	103	-3


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR c>d
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c
  FROM t1
 ORDER BY 1
-- !query schema
struct<c:int>
-- !query output
100
108


-- !query
SELECT a+b*2,
       a+b*2+c*3,
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 ORDER BY 4,1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       a,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       b-c,
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 6,4,5,1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d-e,
       a,
       abs(a)
  FROM t1
 ORDER BY 3,1,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND a>b
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3,
       c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b,
       b-c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 ORDER BY 5,3,1,2,6,4
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,c:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,b:int,(b - c):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
643	108	214	106	-2	333
607	100	1020	102	2	333


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(b-c),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a-b,
       abs(a)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR d>e
    OR c BETWEEN b-2 AND d+2
 ORDER BY 4,1,5,6,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (e>c OR e<d)
    OR (e>a AND e<b)
    OR c BETWEEN b-2 AND d+2
 ORDER BY 2,1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
1020	1531
214	1604


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a
  FROM t1
 WHERE b>c
   AND c BETWEEN b-2 AND d+2
   AND (e>c OR e<d)
 ORDER BY 1,2
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,a:int>
-- !query output
1020	103


-- !query
SELECT a,
       b,
       abs(a),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR a>b
 ORDER BY 2,3,4,1
-- !query schema
struct<a:int,b:int,abs(a):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
103	102	103	1020
107	106	107	214


-- !query
SELECT a+b*2+c*3,
       d-e,
       a+b*2+c*3+d*4,
       d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(a)
  FROM t1
 WHERE b>c
   AND (e>c OR e<d)
 ORDER BY 2,3,4,5,6,1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,(d - e):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,d:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,abs(a):int>
-- !query output
607	-3	1011	101	444	103


-- !query
SELECT a,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(b-c)
  FROM t1
 ORDER BY 3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3,
       a-b
  FROM t1
 WHERE a>b
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 1
-- !query schema
struct<b:int>
-- !query output
102
106


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d,
       a,
       a+b*2+c*3,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 2,5,3,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b,
       c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a
  FROM t1
 WHERE (e>a AND e<b)
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 5,3,2,1,4
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,b:int,c:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,a:int>
-- !query output



-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a-b,
       a+b*2+c*3
  FROM t1
 ORDER BY 2,3,1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(a - b):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
1531	1	607
1604	1	643


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE c>d
 ORDER BY 2,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<d:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
101	1020
109	214


-- !query
SELECT c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b-c,
       b
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 3,4,2,1
-- !query schema
struct<(c - d):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(b - c):int,b:int>
-- !query output
-1	222	-2	106
-1	444	2	102


-- !query
SELECT abs(b-c),
       c,
       b,
       (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d
  FROM t1
 WHERE d>e
 ORDER BY 6,5,3,1,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1
-- !query schema
struct<(b - c):int>
-- !query output
-2


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (a+b+c+d+e)/5,
       abs(a),
       abs(b-c),
       c-d
  FROM t1
 ORDER BY 3,7,1,4,6,2,5
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(a + (b * 2)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((((a + b) + c) + d) + e) / 5):double,abs(a):int,abs((b - c)):int,(c - d):int>
-- !query output
214	319	222	107.0	107	2	-1
1020	307	444	102.0	103	2	-1


-- !query
SELECT a,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       e
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b-c,
       a+b*2+c*3+d*4,
       (a+b+c+d+e)/5
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 5,1,2,4,3,6,7
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
222
444


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (e>c OR e<d)
   AND e+d BETWEEN a+b-10 AND c+130
   AND c>d
 ORDER BY 2,1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3,
       a,
       (a+b+c+d+e)/5,
       b
  FROM t1
 WHERE b>c
 ORDER BY 4,2,6,5,3,7,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2,
       a-b,
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 1,3,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (a+b+c+d+e)/5,
       d,
       d-e
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR d NOT BETWEEN 110 AND 150
    OR (e>c OR e<d)
 ORDER BY 5,4,2,3,1
-- !query schema
struct<e:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(((((a + b) + c) + d) + e) / 5):double,d:int,(d - e):int>
-- !query output
104	1020	102.0	101	-3
105	214	107.0	109	4


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c,
       d
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 4,5,2,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d,
       abs(b-c),
       a+b*2
  FROM t1
 WHERE d>e
   AND a>b
 ORDER BY 1,2,3
-- !query schema
struct<(c - d):int,abs((b - c)):int,(a + (b * 2)):int>
-- !query output
-1	2	319


-- !query
SELECT e,
       a+b*2+c*3
  FROM t1
 WHERE (e>a AND e<b)
    OR b>c
    OR (e>c OR e<d)
 ORDER BY 2,1
-- !query schema
struct<e:int,((a + (b * 2)) + (c * 3)):int>
-- !query output
104	607
105	643


-- !query
SELECT (a+b+c+d+e)/5
  FROM t1
 ORDER BY 1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double>
-- !query output
102.0
107.0


-- !query
SELECT a+b*2+c*3+d*4,
       a+b*2+c*3+d*4+e*5,
       a,
       b,
       a+b*2
  FROM t1
 WHERE b>c
   AND (e>a AND e<b)
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 5,1,2,3,4
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,a:int,b:int,(a + (b * 2)):int>
-- !query output



-- !query
SELECT e,
       a+b*2+c*3+d*4,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 2,3,1
-- !query schema
struct<e:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
104	1011	102.0
105	1079	107.0


-- !query
SELECT (a+b+c+d+e)/5,
       d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4,
       a,
       abs(a),
       a-b
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND e+d BETWEEN a+b-10 AND c+130
 ORDER BY 5,4,1,2,7,6,3
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,d:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,a:int,abs(a):int,(a - b):int>
-- !query output
107.0	109	214	1079	107	107	1


-- !query
SELECT c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b-c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 6,3,1,2,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d,
       d-e,
       d,
       a+b*2+c*3
  FROM t1
 ORDER BY 3,2,4,1
-- !query schema
struct<(c - d):int,(d - e):int,d:int,((a + (b * 2)) + (c * 3)):int>
-- !query output
-1	-3	101	607
-1	4	109	643


-- !query
SELECT abs(b-c)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 1
-- !query schema
struct<abs((b - c)):int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d-e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c
  FROM t1
 WHERE d>e
    OR a>b
 ORDER BY 4,3,2,1,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(a),
       a+b*2
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR c BETWEEN b-2 AND d+2
 ORDER BY 2,4,3,1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,abs(a):int,(a + (b * 2)):int>
-- !query output
107.0	214	107	319
102.0	1020	103	307


-- !query
SELECT a,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       b-c,
       a+b*2+c*3+d*4,
       c-d,
       d-e
  FROM t1
 WHERE c>d
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 7,3,6,5,2,1,4
-- !query schema
struct<a:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(b - c):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(c - d):int,(d - e):int>
-- !query output
103	1020	333	2	1011	-1	-3
107	214	333	-2	1079	-1	4


-- !query
SELECT abs(a),
       c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d-e
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND (a>b-2 AND a<b+2)
 ORDER BY 1,3,2,4
-- !query schema
struct<abs(a):int,c:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(d - e):int>
-- !query output
103	100	444	-3
107	108	222	4


-- !query
SELECT a+b*2+c*3,
       c-d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4,
       (a+b+c+d+e)/5,
       a+b*2+c*3+d*4+e*5
  FROM t1
 ORDER BY 1,6,5,3,4,2
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,(c - d):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(((((a + b) + c) + d) + e) / 5):double,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
607	-1	1020	1011	102.0	1531
643	-1	214	1079	107.0	1604


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (e>c OR e<d)
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
214
1020


-- !query
SELECT b,
       a,
       a+b*2+c*3+d*4
  FROM t1
 ORDER BY 3,1,2
-- !query schema
struct<b:int,a:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
102	103	1011
106	107	1079


-- !query
SELECT (a+b+c+d+e)/5,
       e,
       b
  FROM t1
 WHERE d>e
   AND (a>b-2 AND a<b+2)
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 1,3,2
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,e:int,b:int>
-- !query output
107.0	105	106


-- !query
SELECT abs(a),
       a+b*2+c*3,
       (a+b+c+d+e)/5,
       b-c
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1,3,2,4
-- !query schema
struct<abs(a):int,((a + (b * 2)) + (c * 3)):int,(((((a + b) + c) + d) + e) / 5):double,(b - c):int>
-- !query output
103	607	102.0	2
107	643	107.0	-2


-- !query
SELECT a-b
  FROM t1
 ORDER BY 1
-- !query schema
struct<(a - b):int>
-- !query output
1
1


-- !query
SELECT a-b,
       d-e,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 2,3,1
-- !query schema
struct<(a - b):int,(d - e):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
1	-3	333
1	4	333


-- !query
SELECT c
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 1
-- !query schema
struct<c:int>
-- !query output
100
108


-- !query
SELECT a+b*2+c*3+d*4,
       abs(b-c),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 ORDER BY 2,4,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a)
  FROM t1
 WHERE (e>c OR e<d)
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 1
-- !query schema
struct<abs(a):int>
-- !query output
103
107


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2
  FROM t1
 ORDER BY 1,3,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d,
       a+b*2+c*3+d*4+e*5,
       b,
       (a+b+c+d+e)/5,
       a,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE d>e
 ORDER BY 4,5,6,1,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(b-c),
       c-d
  FROM t1
 ORDER BY 2,1,3,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c-d,
       e,
       abs(a),
       d
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (e>a AND e<b)
 ORDER BY 6,1,5,2,4,7,3
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,a:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(c - d):int,e:int,abs(a):int,d:int>
-- !query output



-- !query
SELECT b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d
  FROM t1
 ORDER BY 3,2,1
-- !query schema
struct<b:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,d:int>
-- !query output
102	333	101
106	333	109


-- !query
SELECT c-d,
       a-b,
       a+b*2+c*3+d*4,
       a+b*2+c*3+d*4+e*5,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 3,2,4,5,1
-- !query schema
struct<(c - d):int,(a - b):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
-1	1	1011	1531	102.0
-1	1	1079	1604	107.0


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c-d
  FROM t1
 WHERE (e>c OR e<d)
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR (e>a AND e<b)
 ORDER BY 2,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       e
  FROM t1
 ORDER BY 3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c,
       a+b*2+c*3,
       d-e,
       a+b*2+c*3+d*4+e*5
  FROM t1
 ORDER BY 3,4,6,5,1,2
-- !query schema
struct<(c - d):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,c:int,((a + (b * 2)) + (c * 3)):int,(d - e):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
-1	444	100	607	-3	1531
-1	222	108	643	4	1604


-- !query
SELECT a+b*2,
       a-b,
       c,
       a,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4+e*5,
       a+b*2+c*3
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 5,3,2,7,4,6,1
-- !query schema
struct<(a + (b * 2)):int,(a - b):int,c:int,a:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
319	1	108	107	222	1604	643


-- !query
SELECT abs(b-c)
  FROM t1
 ORDER BY 1
-- !query schema
struct<abs((b - c)):int>
-- !query output
2
2


-- !query
SELECT b,
       c,
       abs(a),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       b-c,
       e
  FROM t1
 ORDER BY 4,5,1,6,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d-e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1,4,3,5,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       c
  FROM t1
 WHERE d>e
    OR b>c
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1,2
-- !query schema
struct<a:int,c:int>
-- !query output
103	100
107	108


-- !query
SELECT a+b*2+c*3+d*4,
       c-d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2,
       b,
       b-c,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 5,2,4,1,6,3,7
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a,
       b,
       abs(a),
       a+b*2,
       c-d
  FROM t1
 WHERE b>c
 ORDER BY 1,6,5,3,4,2
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,a:int,b:int,abs(a):int,(a + (b * 2)):int,(c - d):int>
-- !query output
333	103	102	103	307	-1


-- !query
SELECT a+b*2+c*3+d*4
  FROM t1
 ORDER BY 1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1011
1079


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4,
       e,
       a+b*2,
       a+b*2+c*3,
       d,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 2,1,5,3,6,4,7
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,e:int,(a + (b * 2)):int,((a + (b * 2)) + (c * 3)):int,d:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
333	1011	104	307	607	101	102.0
333	1079	105	319	643	109	107.0


-- !query
SELECT d-e,
       c-d,
       a
  FROM t1
 WHERE b>c
   AND (e>a AND e<b)
   AND c>d
 ORDER BY 1,2,3
-- !query schema
struct<(d - e):int,(c - d):int,a:int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b-c,
       a,
       abs(a)
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR (c<=d-2 OR c>=d+2)
    OR d>e
 ORDER BY 3,5,6,2,1,7,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       e,
       (a+b+c+d+e)/5,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR d NOT BETWEEN 110 AND 150
    OR d>e
 ORDER BY 1,4,2,3
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,e:int,(((((a + b) + c) + d) + e) / 5):double,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
333	105	107.0	214
333	104	102.0	1020


-- !query
SELECT b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c-d,
       a+b*2+c*3+d*4+e*5,
       b-c,
       a+b*2,
       d-e
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND (e>a AND e<b)
 ORDER BY 3,4,1,5,6,2,7
-- !query schema
struct<b:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(c - d):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(b - c):int,(a + (b * 2)):int,(d - e):int>
-- !query output



-- !query
SELECT (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3,
       a,
       a-b,
       d
  FROM t1
 WHERE (e>a AND e<b)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 6,1,2,3,5,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 1
-- !query schema
struct<(c - d):int>
-- !query output
-1
-1


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       d-e,
       abs(a),
       c-d
  FROM t1
 ORDER BY 2,3,4,1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(d - e):int,abs(a):int,(c - d):int>
-- !query output
1531	-3	103	-1
1604	4	107	-1


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       c
  FROM t1
 WHERE d>e
    OR (e>c OR e<d)
 ORDER BY 2,1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,c:int>
-- !query output
1531	100
1604	108


-- !query
SELECT a,
       a+b*2+c*3+d*4,
       d
  FROM t1
 ORDER BY 1,3,2
-- !query schema
struct<a:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,d:int>
-- !query output
103	1011	101
107	1079	109


-- !query
SELECT b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d-e,
       abs(a),
       (a+b+c+d+e)/5
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
    OR e+d BETWEEN a+b-10 AND c+130
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 3,2,1,5,4
-- !query schema
struct<b:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(d - e):int,abs(a):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
102	444	-3	103	102.0
106	222	4	107	107.0


-- !query
SELECT a-b,
       (a+b+c+d+e)/5,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(a),
       d-e,
       abs(b-c),
       a+b*2+c*3+d*4
  FROM t1
 ORDER BY 6,4,5,3,1,2,7
-- !query schema
struct<(a - b):int,(((((a + b) + c) + d) + e) / 5):double,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,abs(a):int,(d - e):int,abs((b - c)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1	102.0	444	103	-3	2	1011
1	107.0	222	107	4	2	1079


-- !query
SELECT d
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1
-- !query schema
struct<d:int>
-- !query output
101
109


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       d-e,
       abs(a),
       a-b,
       b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE c>d
 ORDER BY 5,4,3,2,1,6
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(d - e):int,abs(a):int,(a - b):int,b:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output



-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE c>d
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
1531
1604


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE d>e
    OR (e>a AND e<b)
 ORDER BY 1
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
333


-- !query
SELECT c-d,
       a+b*2+c*3,
       a
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<(c - d):int,((a + (b * 2)) + (c * 3)):int,a:int>
-- !query output
-1	607	103
-1	643	107


-- !query
SELECT (a+b+c+d+e)/5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE c>d
   AND b>c
   AND (a>b-2 AND a<b+2)
 ORDER BY 2,1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output



-- !query
SELECT a,
       abs(a),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR d NOT BETWEEN 110 AND 150
    OR (e>c OR e<d)
 ORDER BY 2,1,3
-- !query schema
struct<a:int,abs(a):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
103	103	333
107	107	333


-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR c BETWEEN b-2 AND d+2
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
1531
1604


-- !query
SELECT abs(b-c)
  FROM t1
 WHERE c>d
   AND d NOT BETWEEN 110 AND 150
   AND a>b
 ORDER BY 1
-- !query schema
struct<abs((b - c)):int>
-- !query output



-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a
  FROM t1
 ORDER BY 4,2,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT e,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4,
       a+b*2+c*3,
       c-d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE c>d
 ORDER BY 1,2,5,3,4,7,6
-- !query schema
struct<e:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((a + (b * 2)) + (c * 3)):int,(c - d):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output



-- !query
SELECT abs(a),
       a-b,
       a+b*2+c*3
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 3,1,2
-- !query schema
struct<abs(a):int,(a - b):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
103	1	607
107	1	643


-- !query
SELECT a-b,
       abs(a),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 3,2,4,1
-- !query schema
struct<(a - b):int,abs(a):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
1	107	222	214
1	103	444	1020


-- !query
SELECT b-c,
       c-d,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE a>b
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 1,2,3
-- !query schema
struct<(b - c):int,(c - d):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
-2	-1	1604
2	-1	1531


-- !query
SELECT b,
       a+b*2+c*3,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c-d
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR (e>c OR e<d)
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 1,3,2,4
-- !query schema
struct<b:int,((a + (b * 2)) + (c * 3)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(c - d):int>
-- !query output
102	607	1020	-1
106	643	214	-1


-- !query
SELECT a-b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE c>d
   AND b>c
 ORDER BY 2,1
-- !query schema
struct<(a - b):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output



-- !query
SELECT c-d,
       b-c,
       abs(b-c),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1,3,4,2
-- !query schema
struct<(c - d):int,(b - c):int,abs((b - c)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
-1	-2	2	214
-1	2	2	1020


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b,
       a+b*2+c*3
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 3,4,2,1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,b:int,((a + (b * 2)) + (c * 3)):int>
-- !query output
1531	1020	102	607
1604	214	106	643


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d,
       c,
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 4,2,3,1,5,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(b-c),
       abs(a),
       a+b*2,
       a,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       e
  FROM t1
 WHERE (e>a AND e<b)
   AND d NOT BETWEEN 110 AND 150
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 4,2,3,7,1,5,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(a),
       c,
       d
  FROM t1
 WHERE (e>a AND e<b)
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 2,1,5,3,4
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,abs(a):int,c:int,d:int>
-- !query output



-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a-b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c,
       e
  FROM t1
 WHERE d>e
 ORDER BY 2,5,1,4,3
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(a - b):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,c:int,e:int>
-- !query output
1604	1	333	108	105


-- !query
SELECT e,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4+e*5,
       b,
       d-e,
       c
  FROM t1
 WHERE c>d
   AND d>e
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,4,1,5,3,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       abs(b-c),
       a+b*2+c*3,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(a)
  FROM t1
 WHERE d>e
 ORDER BY 3,4,1,5,2
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,abs((b - c)):int,((a + (b * 2)) + (c * 3)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,abs(a):int>
-- !query output
1079	2	643	333	107


-- !query
SELECT b-c,
       d-e,
       abs(a)
  FROM t1
 ORDER BY 1,3,2
-- !query schema
struct<(b - c):int,(d - e):int,abs(a):int>
-- !query output
-2	4	107
2	-3	103


-- !query
SELECT e
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (c<=d-2 OR c>=d+2)
   AND (e>c OR e<d)
 ORDER BY 1
-- !query schema
struct<e:int>
-- !query output



-- !query
SELECT d
  FROM t1
 ORDER BY 1
-- !query schema
struct<d:int>
-- !query output
101
109


-- !query
SELECT a+b*2,
       abs(a),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3,
       c-d
  FROM t1
 ORDER BY 4,1,5,3,2
-- !query schema
struct<(a + (b * 2)):int,abs(a):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,((a + (b * 2)) + (c * 3)):int,(c - d):int>
-- !query output
307	103	1020	607	-1
319	107	214	643	-1


-- !query
SELECT c-d,
       e,
       a+b*2,
       b,
       abs(a)
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
    OR (e>c OR e<d)
 ORDER BY 2,5,3,1,4
-- !query schema
struct<(c - d):int,e:int,(a + (b * 2)):int,b:int,abs(a):int>
-- !query output
-1	104	307	102	103
-1	105	319	106	107


-- !query
SELECT e,
       abs(a),
       c-d,
       a,
       c,
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 2,7,6,5,3,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR e+d BETWEEN a+b-10 AND c+130
    OR (e>c OR e<d)
 ORDER BY 1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int>
-- !query output
607
643


-- !query
SELECT e,
       a-b,
       c,
       a
  FROM t1
 ORDER BY 1,4,2,3
-- !query schema
struct<e:int,(a - b):int,c:int,a:int>
-- !query output
104	1	100	103
105	1	108	107


-- !query
SELECT a+b*2,
       e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a-b,
       b-c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND d NOT BETWEEN 110 AND 150
   AND c>d
 ORDER BY 3,4,6,5,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       abs(b-c),
       e,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(a),
       a
  FROM t1
 WHERE d>e
   AND b>c
   AND c BETWEEN b-2 AND d+2
 ORDER BY 4,3,6,1,2,5
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,abs((b - c)):int,e:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,abs(a):int,a:int>
-- !query output



-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(b-c),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3+d*4,
       a-b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 ORDER BY 2,5,3,6,4,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(b-c),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d-e,
       a-b
  FROM t1
 ORDER BY 1,3,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4,
       d-e
  FROM t1
 ORDER BY 3,1,2
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(d - e):int>
-- !query output
333	1011	-3
333	1079	4


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b,
       a-b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 4,3,2,1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,b:int,(a - b):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
1020	102	1	333
214	106	1	333


-- !query
SELECT abs(a),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b,
       abs(a),
       a,
       e,
       b-c
  FROM t1
 ORDER BY 2,4,3,1,5
-- !query schema
struct<(a - b):int,abs(a):int,a:int,e:int,(b - c):int>
-- !query output
1	103	103	104	2
1	107	107	105	-2


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR b>c
    OR d>e
 ORDER BY 3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a-b,
       d-e
  FROM t1
 ORDER BY 1,4,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 3,2,1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,c:int>
-- !query output
102.0	333	100
107.0	333	108


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a-b,
       (a+b+c+d+e)/5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 4,1,3,5,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       e,
       a-b
  FROM t1
 ORDER BY 3,1,2
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,e:int,(a - b):int>
-- !query output
102.0	104	1
107.0	105	1


-- !query
SELECT b-c,
       c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR (e>c OR e<d)
 ORDER BY 1,2,3
-- !query schema
struct<(b - c):int,c:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
-2	108	222
2	100	444


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       e,
       d
  FROM t1
 WHERE b>c
 ORDER BY 6,2,5,4,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d
  FROM t1
 ORDER BY 1
-- !query schema
struct<d:int>
-- !query output
101
109


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (e>a AND e<b)
   AND (a>b-2 AND a<b+2)
   AND b>c
 ORDER BY 1,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c-d,
       b-c,
       b,
       (a+b+c+d+e)/5
  FROM t1
 WHERE b>c
   AND c BETWEEN b-2 AND d+2
 ORDER BY 4,2,5,6,1,3
-- !query schema
struct<abs(a):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(c - d):int,(b - c):int,b:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
103	1020	-1	2	102	102.0


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a+b*2,
       a+b*2+c*3+d*4,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(b-c),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR b>c
    OR (e>a AND e<b)
 ORDER BY 6,5,4,2,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(b-c)
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND c>d
   AND (a>b-2 AND a<b+2)
 ORDER BY 1
-- !query schema
struct<abs((b - c)):int>
-- !query output



-- !query
SELECT a-b,
       d-e
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 2,1
-- !query schema
struct<(a - b):int,(d - e):int>
-- !query output
1	-3
1	4


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b,
       b-c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE b>c
    OR a>b
    OR (a>b-2 AND a<b+2)
 ORDER BY 3,2,4,1,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3,
       d-e,
       c,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1,2,4,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 ORDER BY 2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND c>d
   AND d>e
 ORDER BY 1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c-d,
       c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b,
       a+b*2+c*3
  FROM t1
 ORDER BY 4,2,1,3,5,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a-b,
       abs(a),
       d,
       c,
       abs(b-c)
  FROM t1
 WHERE a>b
    OR b>c
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 2,1,3,6,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       c-d
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<a:int,(c - d):int>
-- !query output
103	-1
107	-1


-- !query
SELECT (a+b+c+d+e)/5
  FROM t1
 ORDER BY 1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double>
-- !query output
102.0
107.0


-- !query
SELECT a+b*2+c*3,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND a>b
 ORDER BY 1,2
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
607	444
643	222


-- !query
SELECT abs(b-c)
  FROM t1
 WHERE b>c
 ORDER BY 1
-- !query schema
struct<abs((b - c)):int>
-- !query output
2


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b-c
  FROM t1
 WHERE b>c
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 2,1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(b - c):int>
-- !query output
214	-2
1020	2


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       abs(a)
  FROM t1
 WHERE d>e
   AND b>c
 ORDER BY 2,1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,abs(a):int>
-- !query output



-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       e,
       a,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (e>c OR e<d)
   AND c>d
 ORDER BY 1,5,2,6,3,4
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(a + (b * 2)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,e:int,a:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output



-- !query
SELECT a,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b,
       a-b
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR (a>b-2 AND a<b+2)
 ORDER BY 1,3,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       a+b*2+c*3,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR c>d
 ORDER BY 1,2,3
-- !query schema
struct<a:int,((a + (b * 2)) + (c * 3)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
103	607	1531
107	643	1604


-- !query
SELECT a+b*2+c*3+d*4
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1011
1079


-- !query
SELECT c-d,
       abs(a),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4,
       d
  FROM t1
 WHERE c>d
   AND (e>c OR e<d)
 ORDER BY 3,1,4,5,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d,
       a+b*2+c*3+d*4+e*5,
       abs(b-c),
       d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND (a>b-2 AND a<b+2)
   AND (e>c OR e<d)
 ORDER BY 4,1,3,2,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       a+b*2+c*3,
       c-d,
       abs(b-c),
       d-e
  FROM t1
 ORDER BY 3,4,1,2,5
-- !query schema
struct<c:int,((a + (b * 2)) + (c * 3)):int,(c - d):int,abs((b - c)):int,(d - e):int>
-- !query output
100	607	-1	2	-3
108	643	-1	2	4


-- !query
SELECT (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 1,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT e,
       d-e
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR d>e
    OR (e>a AND e<b)
 ORDER BY 1,2
-- !query schema
struct<e:int,(d - e):int>
-- !query output
104	-3
105	4


-- !query
SELECT c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (a+b+c+d+e)/5,
       b-c,
       e,
       c-d
  FROM t1
 ORDER BY 5,4,6,2,1,3
-- !query schema
struct<c:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(((((a + b) + c) + d) + e) / 5):double,(b - c):int,e:int,(c - d):int>
-- !query output
100	333	102.0	2	104	-1
108	333	107.0	-2	105	-1


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c,
       b
  FROM t1
 WHERE (e>a AND e<b)
    OR d>e
    OR a>b
 ORDER BY 2,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3,
       c,
       abs(a),
       a+b*2+c*3+d*4+e*5,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (e>a AND e<b)
    OR d>e
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 3,4,2,5,1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,c:int,abs(a):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
607	100	103	1531	1020
643	108	107	1604	214


-- !query
SELECT a-b,
       c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b-c,
       e,
       c
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 3,5,1,4,6,2
-- !query schema
struct<(a - b):int,(c - d):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(b - c):int,e:int,c:int>
-- !query output



-- !query
SELECT c,
       a+b*2+c*3,
       c-d,
       abs(a),
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE d>e
    OR (c<=d-2 OR c>=d+2)
    OR (e>c OR e<d)
 ORDER BY 1,3,5,2,4
-- !query schema
struct<c:int,((a + (b * 2)) + (c * 3)):int,(c - d):int,abs(a):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
100	607	-1	103	1531
108	643	-1	107	1604


-- !query
SELECT c,
       a+b*2
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR c>d
    OR c BETWEEN b-2 AND d+2
 ORDER BY 1,2
-- !query schema
struct<c:int,(a + (b * 2)):int>
-- !query output
100	307
108	319


-- !query
SELECT a+b*2+c*3+d*4,
       (a+b+c+d+e)/5
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 2,1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
1011	102.0
1079	107.0


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(a),
       abs(b-c),
       b-c
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR d>e
    OR (a>b-2 AND a<b+2)
 ORDER BY 3,4,2,1,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d,
       a+b*2+c*3+d*4,
       d,
       a-b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 ORDER BY 2,1,5,3,4
-- !query schema
struct<(c - d):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,d:int,(a - b):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
-1	1011	101	1	444
-1	1079	109	1	222


-- !query
SELECT abs(b-c),
       a,
       a+b*2+c*3+d*4,
       c-d,
       c,
       (a+b+c+d+e)/5
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 6,3,1,4,5,2
-- !query schema
struct<abs((b - c)):int,a:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(c - d):int,c:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
2	103	1011	-1	100	102.0
2	107	1079	-1	108	107.0


-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
1531
1604


-- !query
SELECT b-c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       e,
       a+b*2,
       abs(b-c)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR c>d
    OR (a>b-2 AND a<b+2)
 ORDER BY 1,5,3,2,4
-- !query schema
struct<(b - c):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,e:int,(a + (b * 2)):int,abs((b - c)):int>
-- !query output
-2	214	105	319	2
2	1020	104	307	2


-- !query
SELECT abs(a),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a-b,
       b,
       a,
       b-c
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 3,2,4,6,1,5
-- !query schema
struct<abs(a):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(a - b):int,b:int,a:int,(b - c):int>
-- !query output
103	333	1	102	103	2
107	333	1	106	107	-2


-- !query
SELECT a+b*2+c*3,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR a>b
 ORDER BY 2,1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
607	1531
643	1604


-- !query
SELECT a-b
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 1
-- !query schema
struct<(a - b):int>
-- !query output
1


-- !query
SELECT abs(b-c)
  FROM t1
 ORDER BY 1
-- !query schema
struct<abs((b - c)):int>
-- !query output
2
2


-- !query
SELECT a+b*2+c*3,
       c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a,
       (a+b+c+d+e)/5,
       a+b*2,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 3,2,5,7,1,6,4
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,(c - d):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,a:int,(((((a + b) + c) + d) + e) / 5):double,(a + (b * 2)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
643	-1	222	107	107.0	319	214
607	-1	444	103	102.0	307	1020


-- !query
SELECT d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a-b,
       c-d,
       (a+b+c+d+e)/5,
       b-c
  FROM t1
 ORDER BY 3,1,4,2,6,5
-- !query schema
struct<d:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(a - b):int,(c - d):int,(((((a + b) + c) + d) + e) / 5):double,(b - c):int>
-- !query output
101	333	1	-1	102.0	2
109	333	1	-1	107.0	-2


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3+d*4+e*5,
       abs(b-c),
       d
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 4,2,1,6,5,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       b,
       (a+b+c+d+e)/5
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 1,3,2
-- !query schema
struct<d:int,b:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
101	102	102.0
109	106	107.0


-- !query
SELECT a+b*2+c*3+d*4,
       d-e,
       c-d,
       abs(a),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (e>a AND e<b)
 ORDER BY 3,1,5,2,4
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(d - e):int,(c - d):int,abs(a):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output



-- !query
SELECT abs(a),
       c-d,
       abs(b-c),
       a+b*2+c*3
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 3,2,4,1
-- !query schema
struct<abs(a):int,(c - d):int,abs((b - c)):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
103	-1	2	607
107	-1	2	643


-- !query
SELECT c,
       e,
       b,
       abs(a),
       d,
       a
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR c BETWEEN b-2 AND d+2
 ORDER BY 5,3,2,1,4,6
-- !query schema
struct<c:int,e:int,b:int,abs(a):int,d:int,a:int>
-- !query output
100	104	102	103	101	103
108	105	106	107	109	107


-- !query
SELECT a-b,
       a+b*2
  FROM t1
 WHERE b>c
    OR c>d
 ORDER BY 2,1
-- !query schema
struct<(a - b):int,(a + (b * 2)):int>
-- !query output
1	307


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       abs(b-c)
  FROM t1
 ORDER BY 2,1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,abs((b - c)):int>
-- !query output
1531	2
1604	2


-- !query
SELECT d-e,
       a+b*2+c*3,
       a-b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE d>e
    OR (e>a AND e<b)
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 3,4,1,2
-- !query schema
struct<(d - e):int,((a + (b * 2)) + (c * 3)):int,(a - b):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
4	643	1	214


-- !query
SELECT d,
       d-e,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       b,
       c,
       a+b*2+c*3
  FROM t1
 WHERE a>b
    OR b>c
 ORDER BY 3,1,5,6,4,2
-- !query schema
struct<d:int,(d - e):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,b:int,c:int,((a + (b * 2)) + (c * 3)):int>
-- !query output
101	-3	333	102	100	607
109	4	333	106	108	643


-- !query
SELECT abs(b-c),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 ORDER BY 1,3,2
-- !query schema
struct<abs((b - c)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
2	333	222
2	333	444


-- !query
SELECT c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c-d,
       a,
       b
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR c>d
 ORDER BY 1,2,5,3,4
-- !query schema
struct<c:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(c - d):int,a:int,b:int>
-- !query output



-- !query
SELECT abs(b-c),
       c-d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND d>e
   AND c BETWEEN b-2 AND d+2
 ORDER BY 1,2,5,3,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (a+b+c+d+e)/5
  FROM t1
 WHERE d>e
    OR (a>b-2 AND a<b+2)
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b,
       b-c,
       a+b*2+c*3+d*4+e*5,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b
  FROM t1
 ORDER BY 3,1,2,5,4
-- !query schema
struct<(a - b):int,(b - c):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,b:int>
-- !query output
1	2	1531	1020	102
1	-2	1604	214	106


-- !query
SELECT a+b*2,
       a+b*2+c*3+d*4,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       b,
       c-d,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (e>c OR e<d)
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 3,5,2,1,4,6
-- !query schema
struct<(a + (b * 2)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,b:int,(c - d):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
307	1011	333	102	-1	1531
319	1079	333	106	-1	1604


-- !query
SELECT e,
       a+b*2+c*3+d*4,
       a,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c,
       b-c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE a>b
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 1,4,7,6,5,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4+e*5,
       a+b*2+c*3,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE c>d
   AND c BETWEEN b-2 AND d+2
   AND (e>c OR e<d)
 ORDER BY 6,2,5,4,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3,
       abs(a),
       e,
       c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d
  FROM t1
 WHERE (e>c OR e<d)
    OR c BETWEEN b-2 AND d+2
    OR a>b
 ORDER BY 5,2,4,1,3,6
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,abs(a):int,e:int,c:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,d:int>
-- !query output
643	107	105	108	214	109
607	103	104	100	1020	101


-- !query
SELECT a+b*2,
       abs(a),
       d,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b-c
  FROM t1
 WHERE b>c
 ORDER BY 5,1,3,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(b-c),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 3,1,6,4,2,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       a+b*2,
       b
  FROM t1
 ORDER BY 2,3,1
-- !query schema
struct<(b - c):int,(a + (b * 2)):int,b:int>
-- !query output
2	307	102
-2	319	106


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d
  FROM t1
 WHERE a>b
   AND e+d BETWEEN a+b-10 AND c+130
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 1
-- !query schema
struct<a:int>
-- !query output
103
107


-- !query
SELECT abs(b-c),
       a+b*2+c*3+d*4,
       c-d,
       a+b*2+c*3+d*4+e*5
  FROM t1
 ORDER BY 4,1,3,2
-- !query schema
struct<abs((b - c)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(c - d):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
2	1011	-1	1531
2	1079	-1	1604


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(b-c),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       b-c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       a+b*2+c*3,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 ORDER BY 2,1,3
-- !query schema
struct<d:int,((a + (b * 2)) + (c * 3)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
101	607	444
109	643	222


-- !query
SELECT e,
       abs(b-c),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c
  FROM t1
 ORDER BY 1
-- !query schema
struct<c:int>
-- !query output
100
108


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE d>e
   AND (c<=d-2 OR c>=d+2)
   AND (e>a AND e<b)
 ORDER BY 1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output



-- !query
SELECT c,
       a+b*2+c*3+d*4
  FROM t1
 WHERE b>c
   AND (a>b-2 AND a<b+2)
   AND (e>a AND e<b)
 ORDER BY 2,1
-- !query schema
struct<c:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output



-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(a)
  FROM t1
 WHERE c>d
   AND b>c
 ORDER BY 2,1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,abs(a):int>
-- !query output



-- !query
SELECT e,
       a+b*2+c*3+d*4+e*5,
       d-e,
       b-c,
       a+b*2+c*3+d*4,
       abs(b-c)
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 2,4,6,1,5,3
-- !query schema
struct<e:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(d - e):int,(b - c):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,abs((b - c)):int>
-- !query output



-- !query
SELECT a
  FROM t1
 WHERE d>e
 ORDER BY 1
-- !query schema
struct<a:int>
-- !query output
107


-- !query
SELECT a+b*2+c*3+d*4
  FROM t1
 WHERE b>c
 ORDER BY 1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1011


-- !query
SELECT d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3+d*4,
       abs(b-c),
       e
  FROM t1
 ORDER BY 3,4,5,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT e,
       b-c,
       abs(b-c),
       a+b*2+c*3+d*4+e*5,
       c-d,
       abs(a)
  FROM t1
 WHERE b>c
 ORDER BY 3,6,2,1,5,4
-- !query schema
struct<e:int,(b - c):int,abs((b - c)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(c - d):int,abs(a):int>
-- !query output
104	2	2	1531	-1	103


-- !query
SELECT b-c
  FROM t1
 ORDER BY 1
-- !query schema
struct<(b - c):int>
-- !query output
-2
2


-- !query
SELECT abs(b-c),
       (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(a),
       c,
       a+b*2+c*3
  FROM t1
 WHERE a>b
 ORDER BY 3,4,6,1,2,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       abs(b-c)
  FROM t1
 WHERE (e>c OR e<d)
   AND b>c
 ORDER BY 2,1
-- !query schema
struct<d:int,abs((b - c)):int>
-- !query output
101	2


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d,
       a+b*2+c*3+d*4,
       a+b*2+c*3
  FROM t1
 WHERE d>e
    OR c BETWEEN b-2 AND d+2
 ORDER BY 1,4,3,2
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,d:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
333	101	1011	607
333	109	1079	643


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       abs(a),
       b-c
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 1,3,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,abs(a):int,(b - c):int>
-- !query output



-- !query
SELECT c
  FROM t1
 WHERE b>c
 ORDER BY 1
-- !query schema
struct<c:int>
-- !query output
100


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a,
       a+b*2,
       c,
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND b>c
 ORDER BY 6,1,5,7,4,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a-b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 3,4,7,5,2,6,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d-e,
       a+b*2+c*3,
       a-b,
       a+b*2+c*3+d*4+e*5,
       b-c
  FROM t1
 WHERE b>c
   AND a>b
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 5,1,3,6,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       a-b,
       a+b*2,
       abs(a),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3
  FROM t1
 ORDER BY 1,5,4,2,6,3
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(a - b):int,(a + (b * 2)):int,abs(a):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,((a + (b * 2)) + (c * 3)):int>
-- !query output
1011	1	307	103	444	607
1079	1	319	107	222	643


-- !query
SELECT a+b*2+c*3+d*4,
       abs(b-c),
       b-c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE d>e
 ORDER BY 3,1,2,4
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,abs((b - c)):int,(b - c):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
1079	2	-2	222


-- !query
SELECT abs(b-c),
       b-c
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND (a>b-2 AND a<b+2)
 ORDER BY 1,2
-- !query schema
struct<abs((b - c)):int,(b - c):int>
-- !query output
2	-2
2	2


-- !query
SELECT a-b,
       c,
       a+b*2,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       e,
       b-c,
       d-e
  FROM t1
 ORDER BY 7,2,5,4,1,3,6
-- !query schema
struct<(a - b):int,c:int,(a + (b * 2)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,e:int,(b - c):int,(d - e):int>
-- !query output
1	100	307	333	104	2	-3
1	108	319	333	105	-2	4


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(a),
       b-c,
       a-b,
       a,
       c-d
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 3,6,1,2,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       d
  FROM t1
 WHERE (e>a AND e<b)
   AND a>b
   AND c>d
 ORDER BY 2,1
-- !query schema
struct<abs(a):int,d:int>
-- !query output



-- !query
SELECT a+b*2+c*3+d*4+e*5,
       c,
       e,
       a+b*2+c*3,
       abs(b-c),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND d>e
   AND (e>c OR e<d)
 ORDER BY 1,5,3,6,4,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,c:int,e:int,((a + (b * 2)) + (c * 3)):int,abs((b - c)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
1604	108	105	643	2	214


-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
1604


-- !query
SELECT e,
       abs(a)
  FROM t1
 ORDER BY 2,1
-- !query schema
struct<e:int,abs(a):int>
-- !query output
104	103
105	107


-- !query
SELECT abs(a),
       b
  FROM t1
 WHERE b>c
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,1
-- !query schema
struct<abs(a):int,b:int>
-- !query output
103	102
107	106


-- !query
SELECT d-e,
       b,
       b-c,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE d>e
    OR d NOT BETWEEN 110 AND 150
    OR c BETWEEN b-2 AND d+2
 ORDER BY 3,4,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE b>c
    OR c BETWEEN b-2 AND d+2
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 1
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
333
333


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d,
       c-d,
       a
  FROM t1
 ORDER BY 3,4,2,5,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 ORDER BY 1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
222
444


-- !query
SELECT c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND a>b
   AND (e>a AND e<b)
 ORDER BY 2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       abs(b-c),
       d,
       a+b*2+c*3+d*4
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 2,3,4,1
-- !query schema
struct<abs(a):int,abs((b - c)):int,d:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
103	2	101	1011
107	2	109	1079


-- !query
SELECT abs(a),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b,
       a+b*2+c*3+d*4
  FROM t1
 WHERE d>e
    OR b>c
    OR (a>b-2 AND a<b+2)
 ORDER BY 1,5,6,4,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3,
       a+b*2+c*3+d*4+e*5,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE b>c
    OR d NOT BETWEEN 110 AND 150
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 3,2,1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
643	1604	214
607	1531	1020


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       e,
       d-e,
       b,
       c,
       b-c
  FROM t1
 ORDER BY 3,5,6,2,4,1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,e:int,(d - e):int,b:int,c:int,(b - c):int>
-- !query output
444	104	-3	102	100	2
222	105	4	106	108	-2


-- !query
SELECT a+b*2,
       b
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<(a + (b * 2)):int,b:int>
-- !query output
307	102
319	106


-- !query
SELECT a+b*2+c*3+d*4
  FROM t1
 ORDER BY 1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1011
1079


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3+d*4+e*5,
       abs(b-c),
       d
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 4,3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       e,
       a+b*2,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4+e*5,
       a+b*2+c*3,
       c-d
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 4,2,6,1,7,3,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(a),
       e,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d-e
  FROM t1
 WHERE a>b
   AND (e>a AND e<b)
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 3,1,5,4,2
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,abs(a):int,e:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(d - e):int>
-- !query output



-- !query
SELECT b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(b-c)
  FROM t1
 ORDER BY 2,1,3
-- !query schema
struct<b:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,abs((b - c)):int>
-- !query output
102	333	2
106	333	2


-- !query
SELECT (a+b+c+d+e)/5
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND d>e
 ORDER BY 1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double>
-- !query output
107.0


-- !query
SELECT c,
       (a+b+c+d+e)/5,
       a-b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE b>c
   AND (a>b-2 AND a<b+2)
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 1,3,4,2,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       a+b*2+c*3+d*4+e*5,
       a+b*2,
       abs(a)
  FROM t1
 WHERE (e>c OR e<d)
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,1,3,4
-- !query schema
struct<a:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(a + (b * 2)):int,abs(a):int>
-- !query output
107	1604	319	107


-- !query
SELECT d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a-b
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR b>c
    OR a>b
 ORDER BY 1,3,2
-- !query schema
struct<d:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(a - b):int>
-- !query output
101	1020	1
109	214	1


-- !query
SELECT a+b*2+c*3+d*4,
       d-e,
       a,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (a+b+c+d+e)/5,
       abs(b-c)
  FROM t1
 ORDER BY 2,4,3,1,5,6
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(d - e):int,a:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((((a + b) + c) + d) + e) / 5):double,abs((b - c)):int>
-- !query output
1011	-3	103	444	102.0	2
1079	4	107	222	107.0	2


-- !query
SELECT a+b*2+c*3+d*4,
       a+b*2,
       e,
       (a+b+c+d+e)/5
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND (e>c OR e<d)
 ORDER BY 2,4,3,1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(a + (b * 2)):int,e:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
1011	307	104	102.0
1079	319	105	107.0


-- !query
SELECT b-c,
       a+b*2+c*3+d*4+e*5,
       d
  FROM t1
 WHERE a>b
   AND (a>b-2 AND a<b+2)
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 3,2,1
-- !query schema
struct<(b - c):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,d:int>
-- !query output
-2	1604	109


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(a),
       a+b*2+c*3+d*4,
       (a+b+c+d+e)/5,
       e,
       b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR (a>b-2 AND a<b+2)
    OR b>c
 ORDER BY 2,1,3,7,5,4,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE a>b
 ORDER BY 4,1,5,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       b,
       a+b*2+c*3+d*4+e*5,
       c,
       d-e
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR c>d
 ORDER BY 2,5,3,4,1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,b:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,c:int,(d - e):int>
-- !query output
102.0	102	1531	100	-3
107.0	106	1604	108	4


-- !query
SELECT abs(b-c),
       c-d
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1,2
-- !query schema
struct<abs((b - c)):int,(c - d):int>
-- !query output
2	-1
2	-1


-- !query
SELECT c,
       a+b*2+c*3+d*4+e*5,
       abs(a)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND (e>a AND e<b)
 ORDER BY 1,3,2
-- !query schema
struct<c:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,abs(a):int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d-e,
       b,
       a+b*2+c*3+d*4
  FROM t1
 ORDER BY 1,3,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d,
       a,
       abs(b-c)
  FROM t1
 WHERE b>c
    OR d NOT BETWEEN 110 AND 150
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 3,1,2
-- !query schema
struct<(c - d):int,a:int,abs((b - c)):int>
-- !query output
-1	103	2
-1	107	2


-- !query
SELECT a,
       (a+b+c+d+e)/5,
       a+b*2+c*3+d*4
  FROM t1
 WHERE c>d
   AND (c<=d-2 OR c>=d+2)
   AND (e>c OR e<d)
 ORDER BY 3,2,1
-- !query schema
struct<a:int,(((((a + b) + c) + d) + e) / 5):double,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output



-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(b-c),
       c-d,
       a
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND (e>c OR e<d)
   AND c>d
 ORDER BY 3,4,2,1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,abs((b - c)):int,(c - d):int,a:int>
-- !query output



-- !query
SELECT (a+b+c+d+e)/5,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE (e>a AND e<b)
    OR c>d
 ORDER BY 2,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2,
       a
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR (e>c OR e<d)
    OR (e>a AND e<b)
 ORDER BY 2,1
-- !query schema
struct<(a + (b * 2)):int,a:int>
-- !query output
307	103
319	107


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d,
       abs(b-c)
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND (e>a AND e<b)
 ORDER BY 1,3,5,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d-e,
       b,
       a+b*2+c*3+d*4,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b-c
  FROM t1
 WHERE (e>c OR e<d)
   AND b>c
 ORDER BY 2,3,1,4,5
-- !query schema
struct<(d - e):int,b:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(b - c):int>
-- !query output
-3	102	1011	444	2


-- !query
SELECT d-e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(b-c),
       (a+b+c+d+e)/5,
       c-d
  FROM t1
 WHERE a>b
 ORDER BY 1,3,2,4,5
-- !query schema
struct<(d - e):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,abs((b - c)):int,(((((a + b) + c) + d) + e) / 5):double,(c - d):int>
-- !query output
-3	1020	2	102.0	-1
4	214	2	107.0	-1


-- !query
SELECT b,
       a,
       abs(b-c),
       a+b*2+c*3+d*4+e*5,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(a),
       a+b*2
  FROM t1
 ORDER BY 4,1,2,7,5,3,6
-- !query schema
struct<b:int,a:int,abs((b - c)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,abs(a):int,(a + (b * 2)):int>
-- !query output
102	103	2	1531	444	103	307
106	107	2	1604	222	107	319


-- !query
SELECT e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 2,1
-- !query schema
struct<e:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
105	214
104	1020


-- !query
SELECT b,
       c-d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (e>c OR e<d)
    OR c>d
    OR (e>a AND e<b)
 ORDER BY 4,1,5,2,3
-- !query schema
struct<b:int,(c - d):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,((a + (b * 2)) + (c * 3)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
102	-1	333	607	1020
106	-1	333	643	214


-- !query
SELECT a+b*2,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3,
       a+b*2+c*3+d*4
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 2,4,3,1
-- !query schema
struct<(a + (b * 2)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,((a + (b * 2)) + (c * 3)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output



-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b-c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE c>d
 ORDER BY 2,1,3
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(b - c):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output



-- !query
SELECT a+b*2+c*3,
       d,
       a,
       a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 2,3,5,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d,
       abs(b-c),
       e,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE a>b
   AND e+d BETWEEN a+b-10 AND c+130
   AND (e>a AND e<b)
 ORDER BY 3,4,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4,
       c-d
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
    OR (e>c OR e<d)
    OR (e>a AND e<b)
 ORDER BY 3,1,2,4
-- !query schema
struct<c:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(c - d):int>
-- !query output
100	1020	1011	-1
108	214	1079	-1


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
222
444


-- !query
SELECT b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       b-c,
       c,
       abs(b-c)
  FROM t1
 WHERE c>d
   AND (e>c OR e<d)
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1,3,2,5,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d-e,
       c-d,
       a+b*2+c*3+d*4+e*5,
       a+b*2+c*3+d*4,
       a
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 1,2,5,3,4
-- !query schema
struct<(d - e):int,(c - d):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,a:int>
-- !query output



-- !query
SELECT abs(b-c),
       a+b*2,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c-d
  FROM t1
 ORDER BY 6,2,1,3,4,7,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c-d,
       a+b*2+c*3+d*4+e*5,
       d
  FROM t1
 WHERE a>b
   AND c BETWEEN b-2 AND d+2
 ORDER BY 5,6,3,7,2,4,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       e,
       abs(a)
  FROM t1
 ORDER BY 3,1,2
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,e:int,abs(a):int>
-- !query output
444	104	103
222	105	107


-- !query
SELECT e
  FROM t1
 WHERE c>d
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 1
-- !query schema
struct<e:int>
-- !query output
104
105


-- !query
SELECT a+b*2+c*3,
       b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(a),
       a+b*2,
       a
  FROM t1
 WHERE d>e
    OR c>d
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 6,2,1,7,5,4,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       (a+b+c+d+e)/5,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE b>c
 ORDER BY 1,2,3
-- !query schema
struct<(b - c):int,(((((a + b) + c) + d) + e) / 5):double,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
2	102.0	1020


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       d-e,
       b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a-b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND (e>a AND e<b)
   AND d>e
 ORDER BY 3,4,1,5,7,6,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(d - e):int,b:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(a - b):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output



-- !query
SELECT e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c,
       abs(a),
       d,
       d-e
  FROM t1
 WHERE b>c
   AND d>e
 ORDER BY 1,6,2,4,3,7,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (c<=d-2 OR c>=d+2)
   AND (e>c OR e<d)
 ORDER BY 3,4,2,1,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2,
       abs(b-c),
       a+b*2+c*3,
       c,
       e,
       d
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR b>c
 ORDER BY 6,3,5,2,1,4
-- !query schema
struct<(a + (b * 2)):int,abs((b - c)):int,((a + (b * 2)) + (c * 3)):int,c:int,e:int,d:int>
-- !query output
307	2	607	100	104	101
319	2	643	108	105	109


-- !query
SELECT c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR (a>b-2 AND a<b+2)
    OR c>d
 ORDER BY 2,1
-- !query schema
struct<c:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
108	214
100	1020


-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE a>b
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
1531
1604


-- !query
SELECT (a+b+c+d+e)/5,
       a+b*2+c*3+d*4,
       d-e,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
    OR a>b
    OR c BETWEEN b-2 AND d+2
 ORDER BY 1,4,2,3
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(d - e):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
102.0	1011	-3	444
107.0	1079	4	222


-- !query
SELECT b-c
  FROM t1
 WHERE d>e
 ORDER BY 1
-- !query schema
struct<(b - c):int>
-- !query output
-2


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR b>c
 ORDER BY 1
-- !query schema
struct<b:int>
-- !query output
102
106


-- !query
SELECT e,
       b,
       a+b*2+c*3+d*4+e*5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(b-c),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4
  FROM t1
 WHERE d>e
    OR d NOT BETWEEN 110 AND 150
    OR c BETWEEN b-2 AND d+2
 ORDER BY 2,5,3,1,7,6,4
-- !query schema
struct<e:int,b:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,abs((b - c)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
104	102	1531	333	2	444	1011
105	106	1604	333	2	222	1079


-- !query
SELECT a+b*2+c*3,
       d-e,
       a-b
  FROM t1
 WHERE (e>a AND e<b)
    OR d>e
    OR (e>c OR e<d)
 ORDER BY 2,3,1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,(d - e):int,(a - b):int>
-- !query output
607	-3	1
643	4	1


-- !query
SELECT a+b*2+c*3,
       a+b*2+c*3+d*4+e*5,
       d-e,
       (a+b+c+d+e)/5,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 2,5,4,3,1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(d - e):int,(((((a + b) + c) + d) + e) / 5):double,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
607	1531	-3	102.0	1020
643	1604	4	107.0	214


-- !query
SELECT a,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2
  FROM t1
 WHERE b>c
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,3,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       a-b,
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 4,2,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d,
       b,
       e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE a>b
 ORDER BY 4,3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       c,
       a
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND d>e
   AND a>b
 ORDER BY 3,2,1
-- !query schema
struct<d:int,c:int,a:int>
-- !query output
109	108	107


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE b>c
 ORDER BY 1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
1020


-- !query
SELECT c-d,
       b-c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 ORDER BY 4,3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3,
       a-b
  FROM t1
 WHERE a>b
   AND (a>b-2 AND a<b+2)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 3,4,1,2
-- !query schema
struct<(a + (b * 2)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,((a + (b * 2)) + (c * 3)):int,(a - b):int>
-- !query output
307	444	607	1
319	222	643	1


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d,
       b
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR (e>a AND e<b)
 ORDER BY 6,3,1,5,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 1
-- !query schema
struct<(a - b):int>
-- !query output
1
1


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE c>d
    OR c BETWEEN b-2 AND d+2
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a-b,
       a+b*2,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (e>a AND e<b)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 5,1,3,6,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR b>c
 ORDER BY 2,1
-- !query schema
struct<abs(a):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
103	1531
107	1604


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (e>c OR e<d)
   AND e+d BETWEEN a+b-10 AND c+130
   AND d>e
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
    OR c>d
 ORDER BY 1,3,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(b-c),
       c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2,
       d
  FROM t1
 ORDER BY 3,1,2,5,4,6
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,abs((b - c)):int,c:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(a + (b * 2)):int,d:int>
-- !query output
444	2	100	1020	307	101
222	2	108	214	319	109


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b-c,
       b,
       d-e,
       d,
       a-b
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 6,3,2,1,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE a>b
    OR (e>a AND e<b)
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       b-c,
       a+b*2+c*3+d*4+e*5,
       a,
       abs(b-c),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE d>e
    OR e+d BETWEEN a+b-10 AND c+130
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1,3,6,2,4,5
-- !query schema
struct<d:int,(b - c):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,a:int,abs((b - c)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
101	2	1531	103	2	444
109	-2	1604	107	2	222


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4+e*5,
       d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b-c,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 1,3,6,2,5,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c-d,
       abs(b-c),
       a+b*2+c*3,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND a>b
 ORDER BY 4,1,5,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b,
       a,
       (a+b+c+d+e)/5,
       b-c,
       e
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR a>b
 ORDER BY 3,1,2,5,4
-- !query schema
struct<b:int,a:int,(((((a + b) + c) + d) + e) / 5):double,(b - c):int,e:int>
-- !query output
102	103	102.0	2	104
106	107	107.0	-2	105


-- !query
SELECT b,
       d-e,
       (a+b+c+d+e)/5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 2,3,5,4,1
-- !query schema
struct<b:int,(d - e):int,(((((a + b) + c) + d) + e) / 5):double,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,a:int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d-e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b-c,
       c,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,5,6,3,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       e,
       d,
       a-b
  FROM t1
 ORDER BY 2,3,4,5,6,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int>
-- !query output
607
643


-- !query
SELECT b-c,
       a+b*2+c*3+d*4+e*5,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE b>c
 ORDER BY 5,4,3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d-e,
       abs(a)
  FROM t1
 WHERE b>c
    OR a>b
 ORDER BY 1,2
-- !query schema
struct<(d - e):int,abs(a):int>
-- !query output
-3	103
4	107


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4
  FROM t1
 WHERE c>d
 ORDER BY 2,1,4,3
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,c:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output



-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
1531
1604


-- !query
SELECT a,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<a:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
103	102.0
107	107.0


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4+e*5,
       abs(a),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 5,3,1,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND c>d
 ORDER BY 1,2
-- !query schema
struct<c:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output



-- !query
SELECT a+b*2,
       a-b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (e>a AND e<b)
   AND d NOT BETWEEN 110 AND 150
   AND d>e
 ORDER BY 3,1,2
-- !query schema
struct<(a + (b * 2)):int,(a - b):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output



-- !query
SELECT c,
       d-e,
       (a+b+c+d+e)/5
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR d NOT BETWEEN 110 AND 150
    OR (e>c OR e<d)
 ORDER BY 3,1,2
-- !query schema
struct<c:int,(d - e):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
100	-3	102.0
108	4	107.0


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(b-c)
  FROM t1
 WHERE d>e
 ORDER BY 2,3,1
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,abs((b - c)):int>
-- !query output
333	214	2


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a,
       (a+b+c+d+e)/5,
       c,
       a+b*2+c*3+d*4
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 3,5,1,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(a)
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2,
       abs(b-c),
       b-c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 ORDER BY 3,2,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a+b*2+c*3+d*4,
       e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a,
       (a+b+c+d+e)/5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 ORDER BY 6,7,4,1,5,3,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,e:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,a:int,(((((a + b) + c) + d) + e) / 5):double,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
1531	1011	104	1020	103	102.0	333
1604	1079	105	214	107	107.0	333


-- !query
SELECT abs(a),
       d-e
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<abs(a):int,(d - e):int>
-- !query output
103	-3
107	4


-- !query
SELECT abs(b-c),
       b-c,
       a+b*2+c*3,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a
  FROM t1
 ORDER BY 3,4,2,1,5
-- !query schema
struct<abs((b - c)):int,(b - c):int,((a + (b * 2)) + (c * 3)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,a:int>
-- !query output
2	2	607	1020	103
2	-2	643	214	107


-- !query
SELECT a+b*2+c*3,
       a+b*2+c*3+d*4
  FROM t1
 WHERE b>c
   AND a>b
 ORDER BY 1,2
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
607	1011


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3+d*4+e*5,
       d-e,
       c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(b-c)
  FROM t1
 WHERE b>c
 ORDER BY 6,5,3,2,4,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a-b
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR d>e
 ORDER BY 1,2
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(a - b):int>
-- !query output
214	1


-- !query
SELECT a-b
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1
-- !query schema
struct<(a - b):int>
-- !query output
1


-- !query
SELECT a+b*2+c*3,
       d,
       b-c,
       a,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2
  FROM t1
 ORDER BY 4,3,6,1,2,5
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,d:int,(b - c):int,a:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(a + (b * 2)):int>
-- !query output
607	101	2	103	333	307
643	109	-2	107	333	319


-- !query
SELECT a-b,
       d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3,
       a+b*2+c*3+d*4+e*5,
       (a+b+c+d+e)/5
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR b>c
 ORDER BY 1,4,2,5,6,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4,
       a-b,
       e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND (a>b-2 AND a<b+2)
   AND e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1,3,4,5,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       abs(a),
       d,
       b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a
  FROM t1
 ORDER BY 1,4,3,5,6,7,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c,
       a+b*2+c*3,
       b
  FROM t1
 WHERE b>c
    OR c>d
 ORDER BY 3,5,6,4,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a,
       (a+b+c+d+e)/5
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 3,1,2
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,a:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
222	107	107.0


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       e
  FROM t1
 WHERE b>c
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND c>d
 ORDER BY 1,2
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,e:int>
-- !query output



-- !query
SELECT abs(a),
       a-b
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND c BETWEEN b-2 AND d+2
   AND (e>a AND e<b)
 ORDER BY 1,2
-- !query schema
struct<abs(a):int,(a - b):int>
-- !query output



-- !query
SELECT abs(a),
       c-d
  FROM t1
 WHERE d>e
    OR b>c
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 2,1
-- !query schema
struct<abs(a):int,(c - d):int>
-- !query output
103	-1
107	-1


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c,
       a+b*2+c*3+d*4+e*5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d
  FROM t1
 WHERE b>c
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (e>c OR e<d)
 ORDER BY 6,2,1,3,5,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a+b*2+c*3
  FROM t1
 WHERE b>c
    OR c BETWEEN b-2 AND d+2
    OR (e>c OR e<d)
 ORDER BY 2,1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
1531	607
1604	643


-- !query
SELECT b,
       a+b*2+c*3,
       abs(b-c),
       a-b
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 3,1,2,4
-- !query schema
struct<b:int,((a + (b * 2)) + (c * 3)):int,abs((b - c)):int,(a - b):int>
-- !query output
102	607	2	1
106	643	2	1


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3,
       d,
       b
  FROM t1
 ORDER BY 2,1,3,4
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,((a + (b * 2)) + (c * 3)):int,d:int,b:int>
-- !query output
1020	607	101	102
214	643	109	106


-- !query
SELECT c-d
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 1
-- !query schema
struct<(c - d):int>
-- !query output
-1
-1


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       e,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(b-c)
  FROM t1
 WHERE c>d
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND e+d BETWEEN a+b-10 AND c+130
 ORDER BY 4,3,5,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1,2
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
222	333
444	333


-- !query
SELECT a+b*2+c*3,
       a-b,
       c-d
  FROM t1
 WHERE a>b
 ORDER BY 1,3,2
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,(a - b):int,(c - d):int>
-- !query output
607	1	-1
643	1	-1


-- !query
SELECT d,
       a+b*2+c*3,
       a+b*2,
       (a+b+c+d+e)/5,
       a+b*2+c*3+d*4
  FROM t1
 WHERE (e>a AND e<b)
   AND d>e
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 1,2,3,5,4
-- !query schema
struct<d:int,((a + (b * 2)) + (c * 3)):int,(a + (b * 2)):int,(((((a + b) + c) + d) + e) / 5):double,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output



-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3,
       c,
       d-e,
       a+b*2+c*3+d*4+e*5,
       d,
       a-b
  FROM t1
 ORDER BY 3,1,7,6,4,2,5
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,((a + (b * 2)) + (c * 3)):int,c:int,(d - e):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,d:int,(a - b):int>
-- !query output
333	607	100	-3	1531	101	1
333	643	108	4	1604	109	1


-- !query
SELECT c-d,
       e,
       (a+b+c+d+e)/5,
       a+b*2+c*3+d*4+e*5
  FROM t1
 ORDER BY 4,1,3,2
-- !query schema
struct<(c - d):int,e:int,(((((a + b) + c) + d) + e) / 5):double,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
-1	104	102.0	1531
-1	105	107.0	1604


-- !query
SELECT a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(b-c),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(a),
       c
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND b>c
   AND (e>a AND e<b)
 ORDER BY 4,6,2,5,7,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE (e>a AND e<b)
   AND b>c
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 1,2
-- !query schema
struct<c:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output



-- !query
SELECT b-c,
       c
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<(b - c):int,c:int>
-- !query output
-2	108
2	100


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4+e*5,
       a+b*2+c*3+d*4,
       a+b*2+c*3,
       c-d
  FROM t1
 WHERE (e>a AND e<b)
    OR (e>c OR e<d)
    OR c>d
 ORDER BY 3,2,6,5,4,1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((a + (b * 2)) + (c * 3)):int,(c - d):int>
-- !query output
444	1020	1531	1011	607	-1
222	214	1604	1079	643	-1


-- !query
SELECT d
  FROM t1
 WHERE d>e
 ORDER BY 1
-- !query schema
struct<d:int>
-- !query output
109


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a-b
  FROM t1
 ORDER BY 4,3,2,1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,a:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(a - b):int>
-- !query output
1604	107	222	1
1531	103	444	1


-- !query
SELECT abs(a),
       e,
       c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND b>c
 ORDER BY 5,3,6,1,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       b-c,
       abs(a)
  FROM t1
 ORDER BY 4,1,3,2
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(b - c):int,abs(a):int>
-- !query output
1020	333	2	103
214	333	-2	107


-- !query
SELECT d,
       abs(a),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a
  FROM t1
 WHERE a>b
 ORDER BY 1,3,4,2
-- !query schema
struct<d:int,abs(a):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,a:int>
-- !query output
101	103	444	103
109	107	222	107


-- !query
SELECT abs(a),
       a+b*2+c*3,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 3,1,2
-- !query schema
struct<abs(a):int,((a + (b * 2)) + (c * 3)):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
103	607	102.0
107	643	107.0


-- !query
SELECT c-d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3,
       c,
       abs(a)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR (e>a AND e<b)
 ORDER BY 2,4,1,3,5,6
-- !query schema
struct<(c - d):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,((a + (b * 2)) + (c * 3)):int,c:int,abs(a):int>
-- !query output
-1	333	444	607	100	103
-1	333	222	643	108	107


-- !query
SELECT d,
       a+b*2
  FROM t1
 WHERE b>c
    OR c BETWEEN b-2 AND d+2
    OR (a>b-2 AND a<b+2)
 ORDER BY 1,2
-- !query schema
struct<d:int,(a + (b * 2)):int>
-- !query output
101	307
109	319


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE a>b
    OR c BETWEEN b-2 AND d+2
    OR (a>b-2 AND a<b+2)
 ORDER BY 2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b
  FROM t1
 WHERE d>e
    OR (e>a AND e<b)
    OR (a>b-2 AND a<b+2)
 ORDER BY 1
-- !query schema
struct<b:int>
-- !query output
102
106


-- !query
SELECT (a+b+c+d+e)/5,
       b-c,
       a
  FROM t1
 ORDER BY 3,1,2
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,(b - c):int,a:int>
-- !query output
102.0	2	103
107.0	-2	107


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(a)
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c,
       e
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR (e>c OR e<d)
 ORDER BY 3,2,4,1
-- !query schema
struct<abs(a):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,c:int,e:int>
-- !query output
103	1020	100	104
107	214	108	105


-- !query
SELECT a+b*2+c*3+d*4,
       d-e,
       a+b*2+c*3,
       abs(b-c),
       d,
       b-c,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 3,7,1,6,5,2,4
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(d - e):int,((a + (b * 2)) + (c * 3)):int,abs((b - c)):int,d:int,(b - c):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
1011	-3	607	2	101	2	1531
1079	4	643	2	109	-2	1604


-- !query
SELECT c-d,
       b-c,
       abs(b-c)
  FROM t1
 WHERE d>e
 ORDER BY 1,2,3
-- !query schema
struct<(c - d):int,(b - c):int,abs((b - c)):int>
-- !query output
-1	-2	2


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c-d
  FROM t1
 WHERE a>b
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 5,3,1,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d,
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b
  FROM t1
 ORDER BY 2,6,3,1,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT e,
       a+b*2+c*3,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE a>b
 ORDER BY 1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(b-c)
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 2,1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,abs((b - c)):int>
-- !query output
222	2
444	2


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a,
       a+b*2
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 2,1,3
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,a:int,(a + (b * 2)):int>
-- !query output



-- !query
SELECT b
  FROM t1
 WHERE a>b
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR (e>c OR e<d)
 ORDER BY 1
-- !query schema
struct<b:int>
-- !query output
102
106


-- !query
SELECT a+b*2+c*3,
       c-d,
       d,
       a
  FROM t1
 ORDER BY 3,2,1,4
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,(c - d):int,d:int,a:int>
-- !query output
607	-1	101	103
643	-1	109	107


-- !query
SELECT b-c,
       a+b*2+c*3+d*4,
       c-d,
       a,
       d-e,
       c
  FROM t1
 WHERE d>e
 ORDER BY 3,4,1,5,6,2
-- !query schema
struct<(b - c):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(c - d):int,a:int,(d - e):int,c:int>
-- !query output
-2	1079	-1	107	4	108


-- !query
SELECT c-d,
       c,
       abs(a),
       a+b*2+c*3
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND (e>c OR e<d)
 ORDER BY 1,4,2,3
-- !query schema
struct<(c - d):int,c:int,abs(a):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
-1	100	103	607
-1	108	107	643


-- !query
SELECT d-e,
       abs(b-c),
       (a+b+c+d+e)/5
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND (e>a AND e<b)
 ORDER BY 2,3,1
-- !query schema
struct<(d - e):int,abs((b - c)):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output



-- !query
SELECT b-c,
       d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 2,3,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       a,
       c,
       d-e,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 ORDER BY 1,6,3,5,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b,
       c,
       a+b*2+c*3,
       b,
       d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c-d
  FROM t1
 ORDER BY 4,3,5,6,2,1,7
-- !query schema
struct<(a - b):int,c:int,((a + (b * 2)) + (c * 3)):int,b:int,d:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(c - d):int>
-- !query output
1	100	607	102	101	1020	-1
1	108	643	106	109	214	-1


-- !query
SELECT a,
       d-e,
       c,
       a+b*2,
       e
  FROM t1
 WHERE a>b
    OR c>d
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 2,3,5,4,1
-- !query schema
struct<a:int,(d - e):int,c:int,(a + (b * 2)):int,e:int>
-- !query output
103	-3	100	307	104
107	4	108	319	105


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b-c,
       e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       c,
       a,
       a+b*2
  FROM t1
 WHERE (e>a AND e<b)
   AND (e>c OR e<d)
 ORDER BY 3,6,2,1,5,7,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3+d*4+e*5,
       a+b*2+c*3+d*4
  FROM t1
 ORDER BY 2,3,1,5,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d-e,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b,
       a+b*2+c*3
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 3,5,4,6,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a+b*2+c*3,
       (a+b+c+d+e)/5,
       b,
       c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a-b
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 3,5,7,2,4,6,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b,
       a-b,
       a+b*2+c*3+d*4+e*5,
       a+b*2+c*3,
       c,
       c-d
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 5,3,4,6,1,2
-- !query schema
struct<b:int,(a - b):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,((a + (b * 2)) + (c * 3)):int,c:int,(c - d):int>
-- !query output



-- !query
SELECT a-b,
       b,
       a+b*2+c*3+d*4+e*5,
       d-e,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c-d
  FROM t1
 ORDER BY 5,2,1,4,3,6
-- !query schema
struct<(a - b):int,b:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(d - e):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(c - d):int>
-- !query output
1	106	1604	4	222	-1
1	102	1531	-3	444	-1


-- !query
SELECT abs(b-c),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b-c,
       a+b*2+c*3+d*4
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND (e>a AND e<b)
   AND d>e
 ORDER BY 2,1,4,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a-b,
       a+b*2+c*3+d*4,
       a,
       a+b*2+c*3+d*4+e*5,
       c-d
  FROM t1
 WHERE d>e
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 7,3,2,4,6,1,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       (a+b+c+d+e)/5,
       d-e,
       a,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (e>a AND e<b)
   AND (c<=d-2 OR c>=d+2)
   AND a>b
 ORDER BY 5,2,1,4,3
-- !query schema
struct<d:int,(((((a + b) + c) + d) + e) / 5):double,(d - e):int,a:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d-e,
       c-d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND c>d
 ORDER BY 1,2,3,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (a+b+c+d+e)/5,
       b
  FROM t1
 ORDER BY 3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a
  FROM t1
 WHERE d>e
 ORDER BY 1
-- !query schema
struct<a:int>
-- !query output
107


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 ORDER BY 1,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3+d*4+e*5,
       a-b
  FROM t1
 ORDER BY 3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2,
       b-c,
       a+b*2+c*3
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 2,3,1
-- !query schema
struct<(a + (b * 2)):int,(b - c):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
319	-2	643
307	2	607


-- !query
SELECT c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (a+b+c+d+e)/5,
       a+b*2+c*3+d*4,
       abs(b-c),
       a+b*2,
       d-e
  FROM t1
 ORDER BY 4,3,1,7,2,5,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a,
       abs(b-c),
       e
  FROM t1
 ORDER BY 2,3,1,4
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,a:int,abs((b - c)):int,e:int>
-- !query output
333	103	2	104
333	107	2	105


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR c BETWEEN b-2 AND d+2
 ORDER BY 1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
222
444


-- !query
SELECT a+b*2
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1
-- !query schema
struct<(a + (b * 2)):int>
-- !query output
319


-- !query
SELECT (a+b+c+d+e)/5,
       a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       abs(a)
  FROM t1
 WHERE (e>a AND e<b)
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 4,3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b,
       c,
       e,
       a+b*2+c*3+d*4+e*5,
       (a+b+c+d+e)/5,
       b-c
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND a>b
   AND e+d BETWEEN a+b-10 AND c+130
 ORDER BY 5,6,1,2,4,3
-- !query schema
struct<b:int,c:int,e:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(((((a + b) + c) + d) + e) / 5):double,(b - c):int>
-- !query output
106	108	105	1604	107.0	-2


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       e
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 4,3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND d>e
   AND b>c
 ORDER BY 2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       (a+b+c+d+e)/5,
       c-d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d,
       a+b*2+c*3+d*4,
       abs(a)
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 2,5,1,3,7,6,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a-b,
       a+b*2+c*3+d*4
  FROM t1
 WHERE b>c
   AND a>b
 ORDER BY 1,3,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(a - b):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1531	1	1011


-- !query
SELECT b,
       d,
       b-c
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 3,1,2
-- !query schema
struct<b:int,d:int,(b - c):int>
-- !query output
106	109	-2
102	101	2


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2,
       a+b*2+c*3,
       e,
       abs(b-c),
       abs(a)
  FROM t1
 WHERE (e>a AND e<b)
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 4,3,1,5,6,2
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(a + (b * 2)):int,((a + (b * 2)) + (c * 3)):int,e:int,abs((b - c)):int,abs(a):int>
-- !query output



-- !query
SELECT (a+b+c+d+e)/5
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND (e>a AND e<b)
   AND e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double>
-- !query output



-- !query
SELECT d,
       a+b*2+c*3+d*4+e*5,
       a+b*2,
       abs(a),
       d-e
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND (a>b-2 AND a<b+2)
 ORDER BY 2,5,4,3,1
-- !query schema
struct<d:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(a + (b * 2)):int,abs(a):int,(d - e):int>
-- !query output



-- !query
SELECT b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2,
       abs(b-c),
       a+b*2+c*3,
       c-d,
       a
  FROM t1
 ORDER BY 1,4,2,7,3,6,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE a>b
   AND b>c
   AND (e>c OR e<d)
 ORDER BY 2,1
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
333	1531


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b-c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d-e
  FROM t1
 ORDER BY 3,1,4,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       d-e,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE b>c
    OR d NOT BETWEEN 110 AND 150
    OR (e>a AND e<b)
 ORDER BY 4,3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 1
-- !query schema
struct<c:int>
-- !query output
100
108


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3,
       a-b,
       c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR d>e
    OR b>c
 ORDER BY 4,2,1,6,5,3
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,((a + (b * 2)) + (c * 3)):int,(a - b):int,c:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
214	333	643	1	108	222
1020	333	607	1	100	444


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (a+b+c+d+e)/5,
       abs(a),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c,
       a+b*2+c*3+d*4
  FROM t1
 WHERE c>d
    OR e+d BETWEEN a+b-10 AND c+130
    OR (e>a AND e<b)
 ORDER BY 2,1,4,3,5,6,7
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(((((a + b) + c) + d) + e) / 5):double,abs(a):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,c:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1531	333	102.0	103	444	100	1011
1604	333	107.0	107	222	108	1079


-- !query
SELECT (a+b+c+d+e)/5
  FROM t1
 ORDER BY 1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double>
-- !query output
102.0
107.0


-- !query
SELECT c-d
  FROM t1
 WHERE d>e
   AND e+d BETWEEN a+b-10 AND c+130
   AND a>b
 ORDER BY 1
-- !query schema
struct<(c - d):int>
-- !query output
-1


-- !query
SELECT a+b*2+c*3,
       d,
       e,
       a+b*2+c*3+d*4
  FROM t1
 WHERE d>e
   AND c BETWEEN b-2 AND d+2
   AND (a>b-2 AND a<b+2)
 ORDER BY 2,1,3,4
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,d:int,e:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
643	109	105	1079


-- !query
SELECT d-e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       e,
       a+b*2+c*3+d*4,
       a,
       a+b*2+c*3,
       (a+b+c+d+e)/5
  FROM t1
 WHERE b>c
 ORDER BY 7,4,2,6,5,3,1
-- !query schema
struct<(d - e):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,e:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,a:int,((a + (b * 2)) + (c * 3)):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
-3	1020	104	1011	103	607	102.0


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b-c,
       a,
       (a+b+c+d+e)/5,
       c,
       a+b*2
  FROM t1
 WHERE d>e
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 6,1,4,2,5,3
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(b - c):int,a:int,(((((a + b) + c) + d) + e) / 5):double,c:int,(a + (b * 2)):int>
-- !query output
214	-2	107	107.0	108	319


-- !query
SELECT a+b*2,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4,
       a+b*2+c*3,
       abs(a),
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE a>b
   AND (e>a AND e<b)
 ORDER BY 6,3,1,5,2,4
-- !query schema
struct<(a + (b * 2)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((a + (b * 2)) + (c * 3)):int,abs(a):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output



-- !query
SELECT c
  FROM t1
 WHERE d>e
   AND (a>b-2 AND a<b+2)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 1
-- !query schema
struct<c:int>
-- !query output
108


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c,
       a+b*2+c*3
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b
  FROM t1
 WHERE (e>c OR e<d)
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR (e>a AND e<b)
 ORDER BY 1
-- !query schema
struct<(a - b):int>
-- !query output
1
1


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c-d
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND (e>c OR e<d)
 ORDER BY 1,2
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(c - d):int>
-- !query output



-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
   AND a>b
   AND (e>c OR e<d)
 ORDER BY 2,5,3,4,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT e,
       c-d
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR a>b
 ORDER BY 2,1
-- !query schema
struct<e:int,(c - d):int>
-- !query output
104	-1
105	-1


-- !query
SELECT abs(b-c),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       e,
       b-c,
       c-d
  FROM t1
 WHERE (e>c OR e<d)
    OR e+d BETWEEN a+b-10 AND c+130
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 5,6,2,4,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a),
       (a+b+c+d+e)/5
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND c BETWEEN b-2 AND d+2
   AND d>e
 ORDER BY 2,1
-- !query schema
struct<abs(a):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
107	107.0


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4+e*5,
       a+b*2+c*3+d*4
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 1,2,3
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
214	1604	1079
1020	1531	1011


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a-b,
       a+b*2
  FROM t1
 ORDER BY 2,3,1
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(a - b):int,(a + (b * 2)):int>
-- !query output
333	1	307
333	1	319


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR (e>c OR e<d)
    OR a>b
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 2,3,1,5,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a-b,
       b-c,
       a+b*2+c*3+d*4
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 1,4,3,2
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(a - b):int,(b - c):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
333	1	2	1011
333	1	-2	1079


-- !query
SELECT d-e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4,
       a+b*2
  FROM t1
 ORDER BY 6,2,5,1,4,7,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5
  FROM t1
 WHERE b>c
 ORDER BY 1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double>
-- !query output
102.0


-- !query
SELECT b-c,
       a,
       a+b*2+c*3+d*4,
       d
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND c>d
   AND d>e
 ORDER BY 4,2,3,1
-- !query schema
struct<(b - c):int,a:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,d:int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d-e,
       a+b*2+c*3+d*4+e*5,
       a+b*2+c*3,
       a+b*2,
       abs(b-c),
       d
  FROM t1
 WHERE d>e
 ORDER BY 3,4,2,6,5,7,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (a+b+c+d+e)/5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 4,2,3,6,1,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a+b*2+c*3,
       e,
       a,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b-c
  FROM t1
 ORDER BY 6,4,3,1,2,5
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,((a + (b * 2)) + (c * 3)):int,e:int,a:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(b - c):int>
-- !query output
1604	643	105	107	222	-2
1531	607	104	103	444	2


-- !query
SELECT c-d,
       d,
       e
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND d NOT BETWEEN 110 AND 150
 ORDER BY 1,2,3
-- !query schema
struct<(c - d):int,d:int,e:int>
-- !query output
-1	109	105


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2,
       c,
       a+b*2+c*3+d*4+e*5,
       d-e
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR c>d
    OR b>c
 ORDER BY 4,2,3,5,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d,
       a+b*2+c*3+d*4+e*5,
       e
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 3,5,1,2,4
-- !query schema
struct<(b - c):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,d:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,e:int>
-- !query output
2	333	101	1531	104
-2	333	109	1604	105


-- !query
SELECT a,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       c-d,
       b
  FROM t1
 ORDER BY 4,3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       e,
       a+b*2,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3,
       abs(a)
  FROM t1
 ORDER BY 1,2,7,6,4,3,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b,
       e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 2,3,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a+b*2+c*3,
       a+b*2+c*3+d*4
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR c>d
 ORDER BY 3,1,2
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,((a + (b * 2)) + (c * 3)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1604	643	1079


-- !query
SELECT a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (a+b+c+d+e)/5,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR b>c
 ORDER BY 3,1,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4+e*5,
       a+b*2,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND a>b
 ORDER BY 3,4,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT e,
       d-e,
       a+b*2+c*3
  FROM t1
 ORDER BY 2,3,1
-- !query schema
struct<e:int,(d - e):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
104	-3	607
105	4	643


-- !query
SELECT a-b,
       e,
       a,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c-d,
       abs(a),
       a+b*2+c*3
  FROM t1
 WHERE (e>c OR e<d)
 ORDER BY 1,5,7,2,6,4,3
-- !query schema
struct<(a - b):int,e:int,a:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(c - d):int,abs(a):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
1	104	103	444	-1	103	607
1	105	107	222	-1	107	643


-- !query
SELECT a+b*2+c*3,
       c-d,
       d-e
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR (e>a AND e<b)
 ORDER BY 2,3,1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,(c - d):int,(d - e):int>
-- !query output



-- !query
SELECT (a+b+c+d+e)/5,
       a+b*2+c*3,
       a,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3+d*4,
       e,
       d
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 6,4,7,5,2,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 3,4,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE (e>c OR e<d)
   AND (a>b-2 AND a<b+2)
 ORDER BY 1
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
333
333


-- !query
SELECT (a+b+c+d+e)/5
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR (a>b-2 AND a<b+2)
    OR d>e
 ORDER BY 1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double>
-- !query output
102.0
107.0


-- !query
SELECT abs(b-c),
       a+b*2,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 ORDER BY 2,3,1,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c-d,
       a+b*2+c*3+d*4
  FROM t1
 WHERE a>b
 ORDER BY 2,4,1,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       d,
       a-b,
       abs(b-c)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1,5,3,2,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       a,
       a+b*2,
       a-b,
       abs(a),
       a+b*2+c*3
  FROM t1
 ORDER BY 2,3,1,6,4,5
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,a:int,(a + (b * 2)):int,(a - b):int,abs(a):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
1011	103	307	1	103	607
1079	107	319	1	107	643


-- !query
SELECT d-e,
       c,
       a+b*2+c*3,
       b,
       abs(a),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE (e>c OR e<d)
   AND d>e
   AND c>d
 ORDER BY 3,5,1,2,4,6,7
-- !query schema
struct<(d - e):int,c:int,((a + (b * 2)) + (c * 3)):int,b:int,abs(a):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output



-- !query
SELECT d-e,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c,
       a+b*2+c*3,
       b,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE b>c
 ORDER BY 1,4,6,3,5,2
-- !query schema
struct<(d - e):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,c:int,((a + (b * 2)) + (c * 3)):int,b:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
-3	333	100	607	102	1531


-- !query
SELECT (a+b+c+d+e)/5,
       c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a-b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE d>e
 ORDER BY 1,6,2,5,4,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3+d*4,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 2,4,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE c>d
 ORDER BY 2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (a+b+c+d+e)/5,
       abs(b-c),
       a+b*2+c*3+d*4,
       d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d-e,
       abs(a)
  FROM t1
 WHERE a>b
    OR b>c
    OR c>d
 ORDER BY 1,4,5,2,6,7,3
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,abs((b - c)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,d:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(d - e):int,abs(a):int>
-- !query output
102.0	2	1011	101	333	-3	103
107.0	2	1079	109	333	4	107


-- !query
SELECT abs(a),
       c,
       a+b*2,
       a+b*2+c*3+d*4,
       d,
       a
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 5,3,4,1,6,2
-- !query schema
struct<abs(a):int,c:int,(a + (b * 2)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,d:int,a:int>
-- !query output
107	108	319	1079	109	107


-- !query
SELECT b-c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (e>a AND e<b)
   AND c BETWEEN b-2 AND d+2
   AND d>e
 ORDER BY 1,2
-- !query schema
struct<(b - c):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output



-- !query
SELECT a-b,
       c-d,
       b
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 3,1,2
-- !query schema
struct<(a - b):int,(c - d):int,b:int>
-- !query output



-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       b
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 6,1,2,3,7,4,5
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d,
       a-b,
       b
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 3,1,2
-- !query schema
struct<(c - d):int,(a - b):int,b:int>
-- !query output
-1	1	102
-1	1	106


-- !query
SELECT b-c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       e,
       (a+b+c+d+e)/5,
       a+b*2+c*3+d*4
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 3,4,2,5,1
-- !query schema
struct<(b - c):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,e:int,(((((a + b) + c) + d) + e) / 5):double,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
2	1020	104	102.0	1011
-2	214	105	107.0	1079


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d-e
  FROM t1
 WHERE d>e
   AND (a>b-2 AND a<b+2)
 ORDER BY 2,1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(d - e):int>
-- !query output
222	4


-- !query
SELECT e,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(a),
       c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       b,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 6,7,5,4,1,3,2
-- !query schema
struct<e:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,abs(a):int,(c - d):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,b:int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
104	333	103	-1	444	102	102.0
105	333	107	-1	222	106	107.0


-- !query
SELECT d-e
  FROM t1
 ORDER BY 1
-- !query schema
struct<(d - e):int>
-- !query output
-3
4


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND (e>a AND e<b)
   AND (a>b-2 AND a<b+2)
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2,
       e
  FROM t1
 ORDER BY 2,1
-- !query schema
struct<(a + (b * 2)):int,e:int>
-- !query output
307	104
319	105


-- !query
SELECT (a+b+c+d+e)/5,
       a,
       b-c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE c>d
   AND (e>c OR e<d)
 ORDER BY 3,1,2,5,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       a+b*2+c*3,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(a),
       d,
       b-c
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND (e>a AND e<b)
   AND c>d
 ORDER BY 1,5,4,6,3,2,7
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((a + (b * 2)) + (c * 3)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,abs(a):int,d:int,(b - c):int>
-- !query output



-- !query
SELECT (a+b+c+d+e)/5,
       a+b*2,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b-c,
       d-e,
       b
  FROM t1
 ORDER BY 6,1,4,3,5,2
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,(a + (b * 2)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(b - c):int,(d - e):int,b:int>
-- !query output
102.0	307	1020	2	-3	102
107.0	319	214	-2	4	106


-- !query
SELECT d,
       c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a,
       c-d,
       a-b
  FROM t1
 ORDER BY 6,4,3,2,5,1
-- !query schema
struct<d:int,c:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,a:int,(c - d):int,(a - b):int>
-- !query output
101	100	1020	103	-1	1
109	108	214	107	-1	1


-- !query
SELECT a,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       abs(b-c),
       a+b*2+c*3
  FROM t1
 WHERE b>c
    OR (e>c OR e<d)
 ORDER BY 2,1,3,4
-- !query schema
struct<a:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,abs((b - c)):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
103	333	2	607
107	333	2	643


-- !query
SELECT a+b*2,
       (a+b+c+d+e)/5
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 1,2
-- !query schema
struct<(a + (b * 2)):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
307	102.0
319	107.0


-- !query
SELECT abs(b-c),
       a-b,
       a+b*2
  FROM t1
 WHERE (e>c OR e<d)
    OR d>e
 ORDER BY 3,2,1
-- !query schema
struct<abs((b - c)):int,(a - b):int,(a + (b * 2)):int>
-- !query output
2	1	307
2	1	319


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2+c*3,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 ORDER BY 3,5,1,4,2,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(a)
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (a+b+c+d+e)/5,
       a+b*2+c*3+d*4,
       a+b*2+c*3
  FROM t1
 WHERE d>e
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 4,5,3,1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b,
       a+b*2+c*3+d*4+e*5,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE a>b
   AND (e>a AND e<b)
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 1,2,3
-- !query schema
struct<(a - b):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output



-- !query
SELECT e,
       (a+b+c+d+e)/5,
       a+b*2,
       a,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(b-c),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 6,7,3,4,5,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4,
       c-d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c
  FROM t1
 WHERE c>d
 ORDER BY 1,3,4,2
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(c - d):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,c:int>
-- !query output



-- !query
SELECT b,
       abs(b-c),
       d,
       a-b,
       d-e,
       c
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 2,5,1,4,6,3
-- !query schema
struct<b:int,abs((b - c)):int,d:int,(a - b):int,(d - e):int,c:int>
-- !query output
102	2	101	1	-3	100
106	2	109	1	4	108


-- !query
SELECT b-c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a,
       d
  FROM t1
 WHERE (a>b-2 AND a<b+2)
 ORDER BY 4,2,3,1
-- !query schema
struct<(b - c):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,a:int,d:int>
-- !query output
2	1020	103	101
-2	214	107	109


-- !query
SELECT a+b*2+c*3+d*4
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1011
1079


-- !query
SELECT a-b,
       a+b*2
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
    OR (c<=d-2 OR c>=d+2)
    OR a>b
 ORDER BY 1,2
-- !query schema
struct<(a - b):int,(a + (b * 2)):int>
-- !query output
1	307
1	319


-- !query
SELECT a,
       b,
       abs(b-c),
       e,
       a+b*2,
       d-e,
       (a+b+c+d+e)/5
  FROM t1
 WHERE b>c
   AND c>d
 ORDER BY 6,1,7,2,5,4,3
-- !query schema
struct<a:int,b:int,abs((b - c)):int,e:int,(a + (b * 2)):int,(d - e):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output



-- !query
SELECT b,
       a-b,
       e,
       d,
       abs(a),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND d>e
 ORDER BY 2,1,5,3,6,4,7
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c-d
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
 ORDER BY 2,1
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(c - d):int>
-- !query output



-- !query
SELECT abs(b-c),
       e,
       a-b,
       d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a,
       b
  FROM t1
 WHERE b>c
    OR c>d
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 6,5,7,2,3,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c-d,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d,
       a+b*2+c*3,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND b>c
   AND c>d
 ORDER BY 3,4,1,2,5
-- !query schema
struct<(c - d):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,d:int,((a + (b * 2)) + (c * 3)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output



-- !query
SELECT b,
       a-b,
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       d
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND c>d
 ORDER BY 1,2,3,5,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b,
       a+b*2+c*3,
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a+b*2+c*3+d*4
  FROM t1
 ORDER BY 4,3,5,2,7,1,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d-e,
       b,
       abs(b-c),
       c,
       a+b*2+c*3,
       a+b*2+c*3+d*4,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 4,6,7,2,5,3,1
-- !query schema
struct<(d - e):int,b:int,abs((b - c)):int,c:int,((a + (b * 2)) + (c * 3)):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
-3	102	2	100	607	1011	1531
4	106	2	108	643	1079	1604


-- !query
SELECT a+b*2,
       c,
       abs(a),
       b,
       d-e
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR c>d
 ORDER BY 5,2,3,1,4
-- !query schema
struct<(a + (b * 2)):int,c:int,abs(a):int,b:int,(d - e):int>
-- !query output
307	100	103	102	-3
319	108	107	106	4


-- !query
SELECT a+b*2
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND b>c
 ORDER BY 1
-- !query schema
struct<(a + (b * 2)):int>
-- !query output
307


-- !query
SELECT abs(b-c),
       d-e,
       a+b*2,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR d NOT BETWEEN 110 AND 150
    OR c>d
 ORDER BY 4,2,3,1
-- !query schema
struct<abs((b - c)):int,(d - e):int,(a + (b * 2)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
2	4	319	222
2	-3	307	444


-- !query
SELECT b-c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 1,2,3,4
-- !query schema
struct<(b - c):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,d:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 2,3,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3+d*4
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d-e,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a
  FROM t1
 ORDER BY 6,4,5,3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d-e,
       a-b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 2,1,3
-- !query schema
struct<(d - e):int,(a - b):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
-3	1	333
4	1	333


-- !query
SELECT a+b*2+c*3,
       e,
       d-e
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND c BETWEEN b-2 AND d+2
   AND d>e
 ORDER BY 3,2,1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,e:int,(d - e):int>
-- !query output
643	105	4


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c-d,
       e
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 2,3,1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(c - d):int,e:int>
-- !query output



-- !query
SELECT a+b*2+c*3,
       (a+b+c+d+e)/5
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
   AND (e>c OR e<d)
 ORDER BY 2,1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
643	107.0


-- !query
SELECT a,
       a+b*2+c*3,
       abs(a),
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE (e>a AND e<b)
   AND e+d BETWEEN a+b-10 AND c+130
   AND (e>c OR e<d)
 ORDER BY 4,2,5,1,3,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b,
       (a+b+c+d+e)/5,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d-e,
       a,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 1,5,3,6,4,2
-- !query schema
struct<(a - b):int,(((((a + b) + c) + d) + e) / 5):double,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(d - e):int,a:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output
1	102.0	444	-3	103	1020
1	107.0	222	4	107	214


-- !query
SELECT a+b*2,
       d,
       abs(a),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE b>c
    OR (c<=d-2 OR c>=d+2)
    OR (e>c OR e<d)
 ORDER BY 2,3,1,4
-- !query schema
struct<(a + (b * 2)):int,d:int,abs(a):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
307	101	103	444
319	109	107	222


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3+d*4+e*5,
       abs(b-c),
       (a+b+c+d+e)/5
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 4,3,2,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b,
       c-d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 ORDER BY 3,1,2
-- !query schema
struct<(a - b):int,(c - d):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
1	-1	333
1	-1	333


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(b-c),
       abs(a)
  FROM t1
 WHERE (e>c OR e<d)
   AND d>e
   AND c BETWEEN b-2 AND d+2
 ORDER BY 3,1,2
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,abs((b - c)):int,abs(a):int>
-- !query output
214	2	107


-- !query
SELECT c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d-e,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE b>c
   AND a>b
 ORDER BY 3,4,2,5,1
-- !query schema
struct<c:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(d - e):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
100	1020	-3	444	333


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 WHERE a>b
   AND c>d
   AND d>e
 ORDER BY 1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int>
-- !query output



-- !query
SELECT d,
       c
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND d>e
 ORDER BY 1,2
-- !query schema
struct<d:int,c:int>
-- !query output
109	108


-- !query
SELECT a,
       c-d,
       c,
       (a+b+c+d+e)/5,
       abs(b-c),
       b
  FROM t1
 ORDER BY 1,2,5,4,6,3
-- !query schema
struct<a:int,(c - d):int,c:int,(((((a + b) + c) + d) + e) / 5):double,abs((b - c)):int,b:int>
-- !query output
103	-1	100	102.0	2	102
107	-1	108	107.0	2	106


-- !query
SELECT a+b*2+c*3+d*4,
       d,
       abs(a),
       c-d,
       a
  FROM t1
 ORDER BY 1,3,4,2,5
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int,d:int,abs(a):int,(c - d):int,a:int>
-- !query output
1011	101	103	-1	103
1079	109	107	-1	107


-- !query
SELECT c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       e,
       a,
       d-e,
       b-c,
       d
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
 ORDER BY 1,7,6,2,3,4,5
-- !query schema
struct<c:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,e:int,a:int,(d - e):int,(b - c):int,d:int>
-- !query output
100	444	104	103	-3	2	101
108	222	105	107	4	-2	109


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d,
       b-c,
       c
  FROM t1
 ORDER BY 3,1,2,4
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,d:int,(b - c):int,c:int>
-- !query output
222	109	-2	108
444	101	2	100


-- !query
SELECT c
  FROM t1
 WHERE b>c
    OR (e>c OR e<d)
 ORDER BY 1
-- !query schema
struct<c:int>
-- !query output
100
108


-- !query
SELECT a-b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       e
  FROM t1
 WHERE (e>c OR e<d)
    OR (c<=d-2 OR c>=d+2)
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 3,1,2
-- !query schema
struct<(a - b):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,e:int>
-- !query output
1	333	104
1	333	105


-- !query
SELECT a+b*2+c*3,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d-e,
       c,
       abs(a)
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 4,1,3,5,2
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(d - e):int,c:int,abs(a):int>
-- !query output



-- !query
SELECT (a+b+c+d+e)/5,
       e,
       c-d,
       a+b*2+c*3,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a-b
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR e+d BETWEEN a+b-10 AND c+130
    OR c BETWEEN b-2 AND d+2
 ORDER BY 5,4,3,1,2,6
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,e:int,(c - d):int,((a + (b * 2)) + (c * 3)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(a - b):int>
-- !query output
102.0	104	-1	607	333	1
107.0	105	-1	643	333	1


-- !query
SELECT b,
       c
  FROM t1
 ORDER BY 2,1
-- !query schema
struct<b:int,c:int>
-- !query output
102	100
106	108


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       a-b,
       b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       e
  FROM t1
 ORDER BY 1,5,4,3,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3,
       e,
       d,
       b-c,
       a
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR (a>b-2 AND a<b+2)
 ORDER BY 2,4,5,6,1,3
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,((a + (b * 2)) + (c * 3)):int,e:int,d:int,(b - c):int,a:int>
-- !query output
1020	607	104	101	2	103
214	643	105	109	-2	107


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a,
       d-e
  FROM t1
 ORDER BY 1,3,2
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,a:int,(d - e):int>
-- !query output
333	103	-3
333	107	4


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       e,
       d,
       b-c,
       (a+b+c+d+e)/5,
       abs(b-c),
       a+b*2+c*3
  FROM t1
 ORDER BY 4,3,5,1,7,2,6
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,e:int,d:int,(b - c):int,(((((a + b) + c) + d) + e) / 5):double,abs((b - c)):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
222	105	109	-2	107.0	2	643
444	104	101	2	102.0	2	607


-- !query
SELECT (a+b+c+d+e)/5,
       c-d,
       a+b*2+c*3+d*4,
       d-e,
       b-c,
       e,
       a+b*2+c*3+d*4+e*5
  FROM t1
 ORDER BY 7,1,2,4,6,5,3
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,(c - d):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,(d - e):int,(b - c):int,e:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output
102.0	-1	1011	-3	2	104	1531
107.0	-1	1079	4	-2	105	1604


-- !query
SELECT c,
       b
  FROM t1
 WHERE a>b
    OR b>c
 ORDER BY 1,2
-- !query schema
struct<c:int,b:int>
-- !query output
100	102
108	106


-- !query
SELECT b-c,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       a,
       a+b*2,
       a+b*2+c*3,
       e
  FROM t1
 WHERE (e>c OR e<d)
    OR c BETWEEN b-2 AND d+2
 ORDER BY 1,5,2,4,6,3
-- !query schema
struct<(b - c):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,a:int,(a + (b * 2)):int,((a + (b * 2)) + (c * 3)):int,e:int>
-- !query output
-2	222	107	319	643	105
2	444	103	307	607	104


-- !query
SELECT a+b*2+c*3
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int>
-- !query output
607
643


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(b-c),
       abs(a),
       b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND d>e
 ORDER BY 1,5,3,2,4
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,abs((b - c)):int,abs(a):int,b:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
214	2	107	106	333


-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       d-e,
       a+b*2+c*3+d*4
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 1,3,4,2
-- !query schema
struct<CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(d - e):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output



-- !query
SELECT CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       (a+b+c+d+e)/5
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
    OR d>e
    OR a>b
 ORDER BY 2,3,1,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       abs(b-c),
       a-b,
       abs(a),
       (a+b+c+d+e)/5
  FROM t1
 WHERE (e>a AND e<b)
   AND d NOT BETWEEN 110 AND 150
   AND c>d
 ORDER BY 5,4,2,3,1,6
-- !query schema
struct<b:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,abs((b - c)):int,(a - b):int,abs(a):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output



-- !query
SELECT e
  FROM t1
 WHERE (e>c OR e<d)
    OR (c<=d-2 OR c>=d+2)
    OR (e>a AND e<b)
 ORDER BY 1
-- !query schema
struct<e:int>
-- !query output
104
105


-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b)
  FROM t1
 WHERE (a>b-2 AND a<b+2)
   AND (e>c OR e<d)
 ORDER BY 1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(a)
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR d>e
    OR (e>c OR e<d)
 ORDER BY 1
-- !query schema
struct<abs(a):int>
-- !query output
103
107


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       c,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       c-d,
       a-b,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 4,2,3,6,1,5
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,c:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(c - d):int,(a - b):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
1531	100	333	-1	1	102.0
1604	108	333	-1	1	107.0


-- !query
SELECT a+b*2+c*3+d*4
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR d NOT BETWEEN 110 AND 150
 ORDER BY 1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1011
1079


-- !query
SELECT (a+b+c+d+e)/5,
       d,
       a+b*2,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b-c,
       c-d,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 6,7,2,4,1,5,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       (a+b+c+d+e)/5,
       b,
       a,
       a+b*2,
       d-e
  FROM t1
 ORDER BY 5,1,6,7,2,3,4
-- !query schema
struct<d:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(((((a + b) + c) + d) + e) / 5):double,b:int,a:int,(a + (b * 2)):int,(d - e):int>
-- !query output
101	333	102.0	102	103	307	-3
109	333	107.0	106	107	319	4


-- !query
SELECT c,
       a-b,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<c:int,(a - b):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
100	1	333
108	1	333


-- !query
SELECT abs(a),
       e,
       a-b,
       a,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       d-e
  FROM t1
 WHERE a>b
    OR d NOT BETWEEN 110 AND 150
    OR b>c
 ORDER BY 4,6,1,2,3,5
-- !query schema
struct<abs(a):int,e:int,(a - b):int,a:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int,(d - e):int>
-- !query output
103	104	1	103	444	-3
107	105	1	107	222	4


-- !query
SELECT e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       b,
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND (c<=d-2 OR c>=d+2)
 ORDER BY 4,2,1,6,5,3
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT b-c,
       a+b*2+c*3,
       a+b*2,
       c-d,
       (a+b+c+d+e)/5,
       a-b
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND d NOT BETWEEN 110 AND 150
   AND d>e
 ORDER BY 6,1,5,3,2,4
-- !query schema
struct<(b - c):int,((a + (b * 2)) + (c * 3)):int,(a + (b * 2)):int,(c - d):int,(((((a + b) + c) + d) + e) / 5):double,(a - b):int>
-- !query output
-2	643	319	-1	107.0	1


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(a),
       a+b*2,
       a,
       d-e
  FROM t1
 WHERE (e>c OR e<d)
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 4,2,3,5,1
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,abs(a):int,(a + (b * 2)):int,a:int,(d - e):int>
-- !query output
1020	103	307	103	-3
214	107	319	107	4


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       b,
       a-b
  FROM t1
 ORDER BY 1,2,3
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,b:int,(a - b):int>
-- !query output
1531	102	1
1604	106	1


-- !query
SELECT (a+b+c+d+e)/5,
       c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       abs(b-c),
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       b-c
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR (c<=d-2 OR c>=d+2)
    OR d>e
 ORDER BY 2,1,3,5,6,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT d,
       a+b*2+c*3+d*4
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<d:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
101	1011
109	1079


-- !query
SELECT abs(a),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3+d*4,
       e,
       d,
       a,
       b-c
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR (e>c OR e<d)
 ORDER BY 5,1,7,2,3,6,4
-- !query schema
struct<abs(a):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,e:int,d:int,a:int,(b - c):int>
-- !query output
103	1020	1011	104	101	103	2
107	214	1079	105	109	107	-2


-- !query
SELECT abs(a),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE a>b
    OR b>c
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 2,1
-- !query schema
struct<abs(a):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
107	222
103	444


-- !query
SELECT a-b
  FROM t1
 WHERE d NOT BETWEEN 110 AND 150
   AND (e>c OR e<d)
   AND a>b
 ORDER BY 1
-- !query schema
struct<(a - b):int>
-- !query output
1
1


-- !query
SELECT a,
       (a+b+c+d+e)/5,
       c
  FROM t1
 WHERE a>b
    OR c BETWEEN b-2 AND d+2
    OR (e>c OR e<d)
 ORDER BY 1,2,3
-- !query schema
struct<a:int,(((((a + b) + c) + d) + e) / 5):double,c:int>
-- !query output
103	102.0	100
107	107.0	108


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       a-b,
       b,
       a+b*2+c*3+d*4,
       a+b*2+c*3,
       d-e,
       abs(b-c)
  FROM t1
 WHERE b>c
   AND a>b
   AND c>d
 ORDER BY 4,2,1,7,5,6,3
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,(a - b):int,b:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,((a + (b * 2)) + (c * 3)):int,(d - e):int,abs((b - c)):int>
-- !query output



-- !query
SELECT a+b*2
  FROM t1
 WHERE a>b
 ORDER BY 1
-- !query schema
struct<(a + (b * 2)):int>
-- !query output
307
319


-- !query
SELECT (a+b+c+d+e)/5,
       d-e
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 2,1
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,(d - e):int>
-- !query output
102.0	-3
107.0	4


-- !query
SELECT d
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR (e>a AND e<b)
 ORDER BY 1
-- !query schema
struct<d:int>
-- !query output
101
109


-- !query
SELECT d-e,
       c-d,
       b,
       b-c,
       abs(b-c),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR e+d BETWEEN a+b-10 AND c+130
 ORDER BY 5,3,4,2,6,1
-- !query schema
struct<(d - e):int,(c - d):int,b:int,(b - c):int,abs((b - c)):int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
-3	-1	102	2	2	444
4	-1	106	-2	2	222


-- !query
SELECT a+b*2+c*3+d*4,
       d,
       c-d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       a+b*2+c*3
  FROM t1
 ORDER BY 6,3,7,2,1,5,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND (e>a AND e<b)
   AND e+d BETWEEN a+b-10 AND c+130
 ORDER BY 1
-- !query schema
struct<((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int>
-- !query output



-- !query
SELECT a+b*2,
       a+b*2+c*3
  FROM t1
 WHERE b>c
 ORDER BY 1,2
-- !query schema
struct<(a + (b * 2)):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
307	607


-- !query
SELECT b-c,
       a+b*2+c*3+d*4
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
   AND EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 2,1
-- !query schema
struct<(b - c):int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
-2	1079


-- !query
SELECT e,
       a+b*2+c*3+d*4+e*5,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
  FROM t1
 ORDER BY 2,3,4,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT abs(b-c)
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 1
-- !query schema
struct<abs((b - c)):int>
-- !query output
2
2


-- !query
SELECT a+b*2+c*3,
       a+b*2+c*3+d*4+e*5,
       b,
       abs(a),
       (a+b+c+d+e)/5,
       abs(b-c)
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 6,5,4,1,3,2
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,b:int,abs(a):int,(((((a + b) + c) + d) + e) / 5):double,abs((b - c)):int>
-- !query output



-- !query
SELECT c,
       a-b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2,
       d
  FROM t1
 WHERE (a>b-2 AND a<b+2)
    OR a>b
 ORDER BY 1,3,4,5,2
-- !query schema
struct<c:int,(a - b):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(a + (b * 2)):int,d:int>
-- !query output
100	1	1020	307	101
108	1	214	319	109


-- !query
SELECT d-e,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END,
       c-d,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d),
       b,
       abs(a),
       a+b*2+c*3
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 2,3,6,7,1,5,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3+d*4
  FROM t1
 WHERE (e>c OR e<d)
   AND c BETWEEN b-2 AND d+2
 ORDER BY 1
-- !query schema
struct<(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
1011
1079


-- !query
SELECT b,
       e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       c-d,
       d-e
  FROM t1
 WHERE d>e
   AND (e>c OR e<d)
 ORDER BY 2,1,3,4,5
-- !query schema
struct<b:int,e:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(c - d):int,(d - e):int>
-- !query output
106	105	214	-1	4


-- !query
SELECT d-e,
       c,
       d
  FROM t1
 ORDER BY 3,2,1
-- !query schema
struct<(d - e):int,c:int,d:int>
-- !query output
-3	100	101
4	108	109


-- !query
SELECT d-e,
       c
  FROM t1
 WHERE (e>a AND e<b)
 ORDER BY 1,2
-- !query schema
struct<(d - e):int,c:int>
-- !query output



-- !query
SELECT (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       b-c,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       abs(b-c),
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE d>e
    OR EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1,3,2,5,4
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a+b*2+c*3,
       a+b*2+c*3+d*4+e*5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
    OR c>d
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 2,3,1
-- !query schema
struct<((a + (b * 2)) + (c * 3)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int>
-- !query output
643	1604	333


-- !query
SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2
  FROM t1
 WHERE (e>c OR e<d)
    OR (e>a AND e<b)
 ORDER BY 1,2
-- !query schema
struct<CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(a + (b * 2)):int>
-- !query output
214	319
1020	307


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       e,
       a-b,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       (a+b+c+d+e)/5,
       abs(b-c)
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
   AND c>d
 ORDER BY 1,3,5,2,6,4
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,e:int,(a - b):int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,(((((a + b) + c) + d) + e) / 5):double,abs((b - c)):int>
-- !query output



-- !query
SELECT a+b*2
  FROM t1
 WHERE c>d
    OR e+d BETWEEN a+b-10 AND c+130
    OR (c<=d-2 OR c>=d+2)
 ORDER BY 1
-- !query schema
struct<(a + (b * 2)):int>
-- !query output
307
319


-- !query
SELECT c,
       (SELECT count(*) FROM t1 AS x WHERE x.c>t1.c AND x.d<t1.d)
  FROM t1
 WHERE b>c
   AND (e>a AND e<b)
   AND d>e
 ORDER BY 1,2
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.c > outer(spark_catalog.mydb1.t1.c))(x.d < outer(spark_catalog.mydb1.t1.d)):
Aggregate [count(1) AS count(1)#xL]
+- Filter ((c#x > outer(c#x)) AND (d#x < outer(d#x)))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a-b,
       d,
       d-e,
       a,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       CASE a+1 WHEN b THEN 111 WHEN c THEN 222
        WHEN d THEN 333  WHEN e THEN 444 ELSE 555 END
  FROM t1
 WHERE a>b
 ORDER BY 3,5,4,2,1,6
-- !query schema
struct<(a - b):int,d:int,(d - e):int,a:int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,CASE WHEN ((a + 1) = b) THEN 111 WHEN ((a + 1) = c) THEN 222 WHEN ((a + 1) = d) THEN 333 WHEN ((a + 1) = e) THEN 444 ELSE 555 END:int>
-- !query output
1	101	-3	103	333	444
1	109	4	107	333	222


-- !query
SELECT a+b*2+c*3+d*4+e*5,
       b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       e
  FROM t1
 ORDER BY 2,3,4,1
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT c,
       a+b*2+c*3+d*4,
       a
  FROM t1
 WHERE (e>a AND e<b)
    OR c BETWEEN b-2 AND d+2
 ORDER BY 1,2,3
-- !query schema
struct<c:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int,a:int>
-- !query output
100	1011	103
108	1079	107


-- !query
SELECT (a+b+c+d+e)/5,
       b,
       a+b*2+c*3+d*4+e*5,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       e,
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 1,3,2,5,4,7,6
-- !query schema
struct<(((((a + b) + c) + d) + e) / 5):double,b:int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,e:int,CASE WHEN (c > scalarsubquery()) THEN (a * 2) ELSE (b * 10) END:int,((a + (b * 2)) + (c * 3)):int>
-- !query output
102.0	102	1531	333	104	1020	607
107.0	106	1604	333	105	214	643


-- !query
SELECT d-e,
       a+b*2+c*3
  FROM t1
 ORDER BY 2,1
-- !query schema
struct<(d - e):int,((a + (b * 2)) + (c * 3)):int>
-- !query output
-3	607
4	643


-- !query
SELECT CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a
  FROM t1
 ORDER BY 1,2
-- !query schema
struct<CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,a:int>
-- !query output
333	103
333	107


-- !query
SELECT abs(b-c),
       a+b*2+c*3+d*4+e*5,
       b,
       d-e
  FROM t1
 WHERE (c<=d-2 OR c>=d+2)
    OR d>e
 ORDER BY 3,1,2,4
-- !query schema
struct<abs((b - c)):int,((((a + (b * 2)) + (c * 3)) + (d * 4)) + (e * 5)):int,b:int,(d - e):int>
-- !query output
2	1604	106	4


-- !query
SELECT c-d,
       CASE WHEN a<b-3 THEN 111 WHEN a<=b THEN 222
        WHEN a<b+3 THEN 333 ELSE 444 END,
       a+b*2,
       e,
       c,
       a+b*2+c*3+d*4
  FROM t1
 WHERE e+d BETWEEN a+b-10 AND c+130
    OR (e>c OR e<d)
 ORDER BY 2,4,6,5,3,1
-- !query schema
struct<(c - d):int,CASE WHEN (a < (b - 3)) THEN 111 WHEN (a <= b) THEN 222 WHEN (a < (b + 3)) THEN 333 ELSE 444 END:int,(a + (b * 2)):int,e:int,c:int,(((a + (b * 2)) + (c * 3)) + (d * 4)):int>
-- !query output
-1	333	307	104	100	1011
-1	333	319	105	108	1079


-- !query
SELECT b,
       a-b,
       (SELECT count(*) FROM t1 AS x WHERE x.b<t1.b),
       CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END,
       a+b*2+c*3,
       a+b*2+c*3+d*4+e*5
  FROM t1
 WHERE c BETWEEN b-2 AND d+2
 ORDER BY 5,2,4,1,3,6
-- !query schema
struct<>
-- !query output
org.apache.spark.sql.AnalysisException
Correlated column is not allowed in predicate (x.b < outer(spark_catalog.mydb1.t1.b)):
Aggregate [count(1) AS count(1)#xL]
+- Filter (b#x < outer(b#x))
   +- SubqueryAlias x
      +- SubqueryAlias spark_catalog.mydb1.t1
         +- Relation mydb1.t1[a#x,b#x,c#x,d#x,e#x] parquet


-- !query
SELECT a,
       a+b*2+c*3,
       (a+b+c+d+e)/5
  FROM t1
 ORDER BY 2,3,1
-- !query schema
struct<a:int,((a + (b * 2)) + (c * 3)):int,(((((a + b) + c) + d) + e) / 5):double>
-- !query output
103	607	102.0
107	643	107.0


-- !query
SELECT c
  FROM t1
 WHERE EXISTS(SELECT 1 FROM t1 AS x WHERE x.b<t1.b)
 ORDER BY 1
-- !query schema
struct<c:int>
-- !query output
108
